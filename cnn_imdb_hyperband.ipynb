{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-imdb-hyperband.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import sys\n",
        "import os\n",
        "prefix = '/content/gdrive/My Drive/'\n",
        "# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n",
        "customized_path_to_your_homework = 'IDLSProject-main'\n",
        "sys_path = os.path.join(prefix, customized_path_to_your_homework)\n",
        "sys.path.append(sys_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3MrpZjClY6w",
        "outputId": "97243d2a-7166-4496-b5c7-333e54ded168"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/IDLSProject-main'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMp4Ucf2lZag",
        "outputId": "5352a401-f686-4bbf-bd71-57cdbf7189bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/IDLSProject-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RGDrpagXgeXC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "data_dir = './data/pytorch'\n",
        "with open(os.path.join(data_dir, 'word_dict_qrnn.pkl'), \"rb\") as f:\n",
        "    word_dict = pickle.load(f)\n",
        "\n",
        "train = pd.read_csv(os.path.join(data_dir, 'train_qrnn.csv'), header=None, names=None)\n",
        "test_sample = pd.read_csv(os.path.join(data_dir, 'test_qrnn.csv'), header=None, names=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test, val = train_test_split(test_sample, test_size=0.5)\n",
        "train.shape, test.shape, val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggddluK9gkch",
        "outputId": "ec0f2ffa-a604-4fe0-e3e2-8b78871a9ab9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30000, 502), (10000, 502), (10000, 502))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "train_y = torch.from_numpy(train[[0]].values).float()\n",
        "train_X = torch.from_numpy(train.drop([0, 1], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
        "# Build the dataloader\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
        "\n",
        "######val data\n",
        "# Turn the input pandas dataframe into tensors\n",
        "val_y = torch.from_numpy(val[[0]].values).float()\n",
        "val_X = torch.from_numpy(val.drop([0, 1], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "val_ds = torch.utils.data.TensorDataset(val_X, val_y)\n",
        "# Build the dataloader\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=50)\n",
        "\n",
        "\n",
        "#### Test data\n",
        "# Turn the input pandas dataframe into tensors\n",
        "test_y = torch.from_numpy(test[[0]].values).float()\n",
        "test_X = torch.from_numpy(test.drop([0, 1], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "test_ds = torch.utils.data.TensorDataset(test_X, test_y)\n",
        "# Build the dataloader\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=50)\n",
        "print(test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjAqxKl2go6R",
        "outputId": "be34f9af-0db5-4470-ccbe-79a2005d6e3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self,trial,vocab_size,embed_size,filter_size,kernel_size,dropout,seq_len):\n",
        "        super(CNN, self).__init__()\n",
        "        filter_size = trial.suggest_int(\"filter_size\",32,256)\n",
        "        dropout = trial.suggest_uniform(\"dropout\",0.1, 0.6)\n",
        "        embed_size = trial.suggest_int(\"embed_size\",32,100)\n",
        "        self.embedding = torch.nn.Embedding(vocab_size,embed_size)\n",
        "        self.conv1 = torch.nn.Conv2d(1,filter_size,kernel_size=[kernel_size[0],embed_size])\n",
        "        self.conv2 = torch.nn.Conv2d(1,filter_size,kernel_size=[kernel_size[1],embed_size])\n",
        "        self.conv3 = torch.nn.Conv2d(1,filter_size,kernel_size=[kernel_size[2],embed_size])\n",
        "        self.mp1 = torch.nn.MaxPool1d(seq_len+1-kernel_size[0])\n",
        "        self.mp2 = torch.nn.MaxPool1d(seq_len+1-kernel_size[1])\n",
        "        self.mp3 = torch.nn.MaxPool1d(seq_len+1-kernel_size[2])\n",
        "        self.dense = torch.nn.Linear(filter_size*3,1)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, x, target):\n",
        "        embed_input = self.embedding(x)\n",
        "        embed_input.unsqueeze_(1)\n",
        "        x1 = torch.tanh(self.dropout(self.conv1(embed_input))).squeeze(3)\n",
        "        x2 = torch.tanh(self.dropout(self.conv2(embed_input))).squeeze(3)\n",
        "        x3 = torch.tanh(self.dropout(self.conv3(embed_input))).squeeze(3)\n",
        "        f1 = self.mp1(x1).squeeze(2)\n",
        "        f2 = self.mp2(x2).squeeze(2)\n",
        "        f3 = self.mp3(x3).squeeze(2)\n",
        "        hidden = torch.cat([f1,f2,f3],dim=1)\n",
        "        logits = self.dense(hidden)\n",
        "        prediction = torch.sigmoid(logits)\n",
        "        target = target.view([-1,1])\n",
        "        correct_pred = torch.eq(torch.round(prediction).type(target.type()),target)\n",
        "        accuracy = torch.sum(correct_pred)\n",
        "        return prediction, accuracy"
      ],
      "metadata": {
        "id": "04HhjUswgr8T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_to_csv(trail_num,epochs, train_loss, val_loss, val_acc, time_train):\n",
        "    epoch = [i for i in range(epochs)]\n",
        "    df_metrics = pd.DataFrame(list(zip(epoch, train_loss, val_loss, val_acc, time_train)), columns =['Epoch', 'train_loss', 'val_loss', 'val_acc', 'train_time'])\n",
        "    df_metrics.to_csv(\"./cnn-imdb-hyperband-trails/\"+str(trail_num)+\".csv\")\n",
        "    \n",
        "# def append_to_csv(epochs, accuracy):\n",
        "#     acc = [accuracy for i in range(epochs)]\n",
        "#     df_csv = pd.read_csv(filename)\n",
        "#     df_csv['Test_Accuracy']  = acc\n",
        "#     df_csv.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "bfLIDMU5gueE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 10\n",
        "batch_size = 50\n",
        "learning_rate = 0.001\n",
        "embed_size = 300\n",
        "seq_len = 500\n",
        "dropout = 0.5\n",
        "filter_size = 100\n",
        "vocab_size = 5000\n",
        "embed_dims = 32\n",
        "kernel_size = [3,4,5]"
      ],
      "metadata": {
        "id": "vYypV9KTgw20"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def objective(trial):\n",
        "  import torch.optim as optim\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "  #epochs = trial.suggest_int(\"epochs\",5,15)\n",
        "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-0)\n",
        "  #momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = CNN(trial,vocab_size, embed_dims, filter_size, kernel_size, dropout, seq_len).to(device)\n",
        "  trial.set_user_attr(key=\"best_model\", value=model)\n",
        "  optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "  criterion = torch.nn.BCELoss().to(device)\n",
        "  counter = 0\n",
        "  CNN_acc = []\n",
        "  CNN_valacc = []\n",
        "  train_loss_epoch = []\n",
        "  train_acc_epoch = []\n",
        "  val_loss_epoch = []\n",
        "  val_acc_epoch = []\n",
        "  time_epoch = []\n",
        "  val_acc = 0\n",
        "  model.train()\n",
        "  for e in range(epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    for inputs, labels in train_dl:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        model.zero_grad()\n",
        "        logits, accuracy = model(inputs,labels)\n",
        "        loss = criterion(logits,labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.item())\n",
        "        train_acc.append(accuracy.item()*100/batch_size)\n",
        "        if counter%100==0:\n",
        "            print(\"Epoch: {}/{}\".format(e,epochs),\n",
        "                         \"\\tIteration: {}\".format(counter),\n",
        "                         \"\\t\\tTrain Loss: {:.3f}\".format(loss.item()),\n",
        "                         \"\\tTrain Accuracy: {:.2f}\".format(accuracy.item()*100/batch_size))\n",
        "            CNN_acc.append(accuracy.item()*100/batch_size)\n",
        "        counter += 1\n",
        "    train_loss_epoch.append(np.round(np.mean(train_loss), 3))\n",
        "    train_acc_epoch.append(np.round(np.mean(train_acc), 3))\n",
        "    print(\"\\tTrain Loss: {:.3f}\".format(np.mean(train_loss)), \"\\tTrain Acc: {:.3f}\".format(np.mean(train_acc)))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_acc = []\n",
        "        val_loss = []\n",
        "        for inputs, labels in val_dl:\n",
        "            inputs_val, labels_val = inputs.cuda(), labels.cuda()\n",
        "            logits_val,accuracy_val = model(inputs_val,labels_val)\n",
        "            loss_val = criterion(logits_val,labels_val.float())\n",
        "            val_acc.append(accuracy_val.item()*100/batch_size)\n",
        "            val_loss.append(loss_val.item())\n",
        "        val_loss_epoch.append(np.round(np.mean(val_loss), 3))\n",
        "        val_acc_epoch.append(np.round(np.mean(val_acc), 3))\n",
        "        print(\"\\t\\tVal Loss: {:.3f}\".format(np.mean(val_loss)), \"\\t\\tVal Acc: {:.3f}\".format(np.mean(val_acc)))\n",
        "        CNN_valacc.append(np.mean(val_acc))\n",
        "        model.train()\n",
        "        val_acc = np.mean(val_acc)\n",
        "    end_time = time.time()-start_time\n",
        "    print(\"Time to train epoch: {0} s\".format(end_time))\n",
        "    time_epoch.append(np.round(end_time, 3))\n",
        "  write_to_csv(trial.number,epochs, train_loss_epoch, train_acc_epoch, val_loss_epoch, val_acc_epoch, time_epoch)\n",
        "  return np.mean(val_acc)\n"
      ],
      "metadata": {
        "id": "GcgPZsC_g33c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def callback(study, trial):\n",
        "    if study.best_trial.number == trial.number:\n",
        "        study.set_user_attr(key=\"best_model\", value=trial.user_attrs[\"best_model\"])"
      ],
      "metadata": {
        "id": "hIwT9Av4jg9X"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAmV9OBbmAd-",
        "outputId": "bc255e6a-7987-4a9d-dde5-b890ace557d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 42.0 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 43.7 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 44.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 30.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 62.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 10.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 59.5 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=12b1705f0b14f95d925d4dea744078262357b41a829fa7bc9133a5518cc0270a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "study = optuna.create_study(direction=\"maximize\",pruner=optuna.pruners.HyperbandPruner(\n",
        "        min_resource=1, max_resource=epochs, reduction_factor=3\n",
        "    ),)\n",
        "study.optimize(objective, n_trials=10,callbacks=[callback])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "best_model=study.user_attrs[\"best_model\"]\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LOWw69rijjA1",
        "outputId": "cfcd2a92-b016-491b-d7e0-c0ede5b1c1d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-05-14 08:05:53,385]\u001b[0m A new study created in memory with name: no-name-3e938c55-7361-4b89-8643-5ad0b3c25783\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/10 \tIteration: 0 \t\tTrain Loss: 0.713 \tTrain Accuracy: 50.00\n",
            "Epoch: 0/10 \tIteration: 100 \t\tTrain Loss: 0.691 \tTrain Accuracy: 50.00\n",
            "Epoch: 0/10 \tIteration: 200 \t\tTrain Loss: 0.696 \tTrain Accuracy: 48.00\n",
            "Epoch: 0/10 \tIteration: 300 \t\tTrain Loss: 0.692 \tTrain Accuracy: 52.00\n",
            "Epoch: 0/10 \tIteration: 400 \t\tTrain Loss: 0.691 \tTrain Accuracy: 50.00\n",
            "Epoch: 0/10 \tIteration: 500 \t\tTrain Loss: 0.689 \tTrain Accuracy: 54.00\n",
            "\tTrain Loss: 0.694 \tTrain Acc: 50.303\n",
            "\t\tVal Loss: 0.693 \t\tVal Acc: 50.350\n",
            "Time to train epoch: 12.108055114746094 s\n",
            "Epoch: 1/10 \tIteration: 600 \t\tTrain Loss: 0.693 \tTrain Accuracy: 50.00\n",
            "Epoch: 1/10 \tIteration: 700 \t\tTrain Loss: 0.692 \tTrain Accuracy: 48.00\n",
            "Epoch: 1/10 \tIteration: 800 \t\tTrain Loss: 0.693 \tTrain Accuracy: 48.00\n",
            "Epoch: 1/10 \tIteration: 900 \t\tTrain Loss: 0.691 \tTrain Accuracy: 58.00\n",
            "Epoch: 1/10 \tIteration: 1000 \t\tTrain Loss: 0.690 \tTrain Accuracy: 48.00\n",
            "Epoch: 1/10 \tIteration: 1100 \t\tTrain Loss: 0.692 \tTrain Accuracy: 50.00\n",
            "\tTrain Loss: 0.693 \tTrain Acc: 50.190\n",
            "\t\tVal Loss: 0.693 \t\tVal Acc: 50.360\n",
            "Time to train epoch: 11.636689186096191 s\n",
            "Epoch: 2/10 \tIteration: 1200 \t\tTrain Loss: 0.693 \tTrain Accuracy: 42.00\n",
            "Epoch: 2/10 \tIteration: 1300 \t\tTrain Loss: 0.690 \tTrain Accuracy: 58.00\n",
            "Epoch: 2/10 \tIteration: 1400 \t\tTrain Loss: 0.694 \tTrain Accuracy: 50.00\n",
            "Epoch: 2/10 \tIteration: 1500 \t\tTrain Loss: 0.691 \tTrain Accuracy: 56.00\n",
            "Epoch: 2/10 \tIteration: 1600 \t\tTrain Loss: 0.694 \tTrain Accuracy: 54.00\n",
            "Epoch: 2/10 \tIteration: 1700 \t\tTrain Loss: 0.692 \tTrain Accuracy: 56.00\n",
            "\tTrain Loss: 0.693 \tTrain Acc: 50.327\n",
            "\t\tVal Loss: 0.693 \t\tVal Acc: 50.480\n",
            "Time to train epoch: 11.728548526763916 s\n",
            "Epoch: 3/10 \tIteration: 1800 \t\tTrain Loss: 0.692 \tTrain Accuracy: 40.00\n",
            "Epoch: 3/10 \tIteration: 1900 \t\tTrain Loss: 0.692 \tTrain Accuracy: 58.00\n",
            "Epoch: 3/10 \tIteration: 2000 \t\tTrain Loss: 0.696 \tTrain Accuracy: 50.00\n",
            "Epoch: 3/10 \tIteration: 2100 \t\tTrain Loss: 0.690 \tTrain Accuracy: 60.00\n",
            "Epoch: 3/10 \tIteration: 2200 \t\tTrain Loss: 0.692 \tTrain Accuracy: 54.00\n",
            "Epoch: 3/10 \tIteration: 2300 \t\tTrain Loss: 0.694 \tTrain Accuracy: 52.00\n",
            "\tTrain Loss: 0.693 \tTrain Acc: 50.480\n",
            "\t\tVal Loss: 0.693 \t\tVal Acc: 50.520\n",
            "Time to train epoch: 11.836130380630493 s\n",
            "Epoch: 4/10 \tIteration: 2400 \t\tTrain Loss: 0.693 \tTrain Accuracy: 44.00\n",
            "Epoch: 4/10 \tIteration: 2500 \t\tTrain Loss: 0.691 \tTrain Accuracy: 52.00\n",
            "Epoch: 4/10 \tIteration: 2600 \t\tTrain Loss: 0.695 \tTrain Accuracy: 48.00\n",
            "Epoch: 4/10 \tIteration: 2700 \t\tTrain Loss: 0.692 \tTrain Accuracy: 56.00\n",
            "Epoch: 4/10 \tIteration: 2800 \t\tTrain Loss: 0.693 \tTrain Accuracy: 50.00\n",
            "Epoch: 4/10 \tIteration: 2900 \t\tTrain Loss: 0.693 \tTrain Accuracy: 54.00\n",
            "\tTrain Loss: 0.693 \tTrain Acc: 50.583\n",
            "\t\tVal Loss: 0.693 \t\tVal Acc: 50.590\n",
            "Time to train epoch: 12.312614440917969 s\n",
            "Epoch: 5/10 \tIteration: 3000 \t\tTrain Loss: 0.691 \tTrain Accuracy: 56.00\n",
            "Epoch: 5/10 \tIteration: 3100 \t\tTrain Loss: 0.692 \tTrain Accuracy: 54.00\n",
            "Epoch: 5/10 \tIteration: 3200 \t\tTrain Loss: 0.692 \tTrain Accuracy: 50.00\n",
            "Epoch: 5/10 \tIteration: 3300 \t\tTrain Loss: 0.690 \tTrain Accuracy: 62.00\n",
            "Epoch: 5/10 \tIteration: 3400 \t\tTrain Loss: 0.693 \tTrain Accuracy: 50.00\n",
            "Epoch: 5/10 \tIteration: 3500 \t\tTrain Loss: 0.692 \tTrain Accuracy: 54.00\n",
            "\tTrain Loss: 0.693 \tTrain Acc: 50.107\n",
            "\t\tVal Loss: 0.693 \t\tVal Acc: 50.620\n",
            "Time to train epoch: 12.085888147354126 s\n",
            "Epoch: 6/10 \tIteration: 3600 \t\tTrain Loss: 0.693 \tTrain Accuracy: 42.00\n",
            "Epoch: 6/10 \tIteration: 3700 \t\tTrain Loss: 0.692 \tTrain Accuracy: 54.00\n",
            "Epoch: 6/10 \tIteration: 3800 \t\tTrain Loss: 0.695 \tTrain Accuracy: 48.00\n",
            "Epoch: 6/10 \tIteration: 3900 \t\tTrain Loss: 0.692 \tTrain Accuracy: 54.00\n",
            "Epoch: 6/10 \tIteration: 4000 \t\tTrain Loss: 0.693 \tTrain Accuracy: 56.00\n",
            "Epoch: 6/10 \tIteration: 4100 \t\tTrain Loss: 0.691 \tTrain Accuracy: 56.00\n",
            "\tTrain Loss: 0.693 \tTrain Acc: 50.420\n",
            "\t\tVal Loss: 0.693 \t\tVal Acc: 50.760\n",
            "Time to train epoch: 12.183359861373901 s\n",
            "Epoch: 7/10 \tIteration: 4200 \t\tTrain Loss: 0.691 \tTrain Accuracy: 58.00\n",
            "Epoch: 7/10 \tIteration: 4300 \t\tTrain Loss: 0.690 \tTrain Accuracy: 54.00\n",
            "Epoch: 7/10 \tIteration: 4400 \t\tTrain Loss: 0.695 \tTrain Accuracy: 48.00\n",
            "Epoch: 7/10 \tIteration: 4500 \t\tTrain Loss: 0.691 \tTrain Accuracy: 54.00\n",
            "Epoch: 7/10 \tIteration: 4600 \t\tTrain Loss: 0.693 \tTrain Accuracy: 52.00\n",
            "Epoch: 7/10 \tIteration: 4700 \t\tTrain Loss: 0.695 \tTrain Accuracy: 48.00\n",
            "\tTrain Loss: 0.693 \tTrain Acc: 50.410\n",
            "\t\tVal Loss: 0.693 \t\tVal Acc: 50.860\n",
            "Time to train epoch: 12.29807162284851 s\n",
            "Epoch: 8/10 \tIteration: 4800 \t\tTrain Loss: 0.693 \tTrain Accuracy: 48.00\n",
            "Epoch: 8/10 \tIteration: 4900 \t\tTrain Loss: 0.692 \tTrain Accuracy: 52.00\n",
            "Epoch: 8/10 \tIteration: 5000 \t\tTrain Loss: 0.696 \tTrain Accuracy: 50.00\n",
            "Epoch: 8/10 \tIteration: 5100 \t\tTrain Loss: 0.691 \tTrain Accuracy: 54.00\n",
            "Epoch: 8/10 \tIteration: 5200 \t\tTrain Loss: 0.689 \tTrain Accuracy: 54.00\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0bb9a6d4bff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmin_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     ),)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Study statistics: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b281743ab064>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, args)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;31m# Stores underlying RecordFunction as a tensor. TODO: move to custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;31m# class (https://github.com/pytorch/pytorch/issues/35026).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(best_model.state_dict(),\"./cnn-imdb-hyperband/\")"
      ],
      "metadata": {
        "id": "tFxUHQlLjnJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_dl, epochs):\n",
        "    with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_acc = []\n",
        "    test_loss = []\n",
        "    for inputs, labels in test_dl:\n",
        "        input_test, labels_test = inputs.cuda(), labels.cuda()\n",
        "        logits_test,accuracy_test = model(input_test,labels_test)\n",
        "        loss_test = criterion(logits_test,labels_test.float())\n",
        "        test_acc.append(accuracy_test.item()*100/batch_size)\n",
        "        test_loss.append(loss_test.item())\n",
        "    print(\"Test Loss: {:.3f}\".format(np.mean(test_loss)), \"\\tTest Acc: {:.3f}\".format(np.mean(test_acc)))\n",
        "    append_to_csv(epochs, np.round(np.mean(test_acc),3))"
      ],
      "metadata": {
        "id": "TB7FDyu1jrD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(best_model, test_dl, epochs)"
      ],
      "metadata": {
        "id": "fA14sQYgjtCQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}