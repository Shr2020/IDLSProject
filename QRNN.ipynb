{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "cache_dir = os.path.join(\"./cache\", \"sentiment_analysis\")  # where to store cache files\n",
    "os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
    "\n",
    "def preprocess_data(cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
    "    \"\"\"Convert each review to words; read from cache if available.\"\"\"\n",
    "\n",
    "    # If cache_file is not None, try to read from it first\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "        except:\n",
    "            pass  # unable to read from cache, but that's okay\n",
    "    \n",
    "    # If cache is missing, then do the heavy lifting\n",
    "    if cache_data is None:\n",
    "        print(\"CACHE NOT FOUND\")\n",
    "        words_train = [review_to_words(review) for review in data_train]\n",
    "        words_test = [review_to_words(review) for review in data_test]\n",
    "        \n",
    "        # Write to cache file for future runs\n",
    "        if cache_file is not None:\n",
    "            cache_data = dict(words_train=words_train, words_test=words_test,\n",
    "                              labels_train=labels_train, labels_test=labels_test)\n",
    "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
    "    else:\n",
    "        # Unpack data loaded from cache file\n",
    "        words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
    "                cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
    "    \n",
    "    return words_train, words_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read preprocessed data from cache file: preprocessed_data.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 50000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = preprocess_data()\n",
    "type(train_X), type(train_y)\n",
    "train_X.extend(test_X)\n",
    "train_y.extend(test_y)\n",
    "len(train_X), len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "type(train_X), type(train_y)\n",
    "temp = list(zip(train_X, train_y))\n",
    "random.shuffle(temp)\n",
    "train_X, train_y = zip(*temp)\n",
    "# res1 and res2 come out as tuples, and so must be converted to lists.\n",
    "train_X, train_y = list(train_X), list(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "30000 30000 20000 20000\n",
      "['basic', 'like', 'verhoeven', 'film', 'film', 'enjoy', 'brilliant', 'pscychosexu', 'stori', 'seen', 'basic', 'instinct', 'realli', 'wonder', 'thriller', 'enjoy', 'much', 'obvious', 'watch', 'anoth', 'verhoeven', 'movi', 'well', 'previou', 'direct', 'block', 'buster', 'hit', 'basic', 'instinct', 'much', 'curiou', 'watch', 'movi', 'yeah', 'movi', 'fulfil', 'hope', 'expect', 'movi', 'fourth', 'man', 'brilliant', 'pscychosexu', 'drama', 'lit', 'bit', 'complex', 'audienc', 'stori', 'movi', 'gay', 'writer', 'name', 'reve', 'krabb', 'alcohol', 'person', 'live', 'moral', 'valu', 'see', 'mani', 'vision', 'may', 'warn', 'futur', 'accid', 'end', 'lectur', 'introduc', 'seduct', 'woman', 'name', 'christin', 'mysteri', 'past', 'want', 'reveal', 'reve', 'sex', 'hous', 'boy', 'next', 'morn', 'watch', 'sexi', 'macho', 'boyfriend', 'pictur', 'tabl', 'person', 'met', 'station', 'curiou', 'meet', 'tell', 'christin', 'invit', 'hous', 'want', 'reveal', 'entir', 'stori', 'verhoeven', 'movi', 'end', 'film', 'realli', 'surpris', 'especi', 'like', 'charact', 'reve', 'brilliantli', 'play', 'krabb', 'basic', 'like', 'act', 'gay', 'person', 'pure', 'identifi', 'charact', 'yeah', 'like', 'charm', 'face', 'would', 'like', 'thank', 'mr', 'verhoeven', 'make', 'black', 'comedi', 'rate', 'movi', '10', '10'] ['7', 'kid', '6', 'claim', 'adult', 'semi', 'sequel', 'lion', 'king', 'see', 'spin', 'side', 'charact', 'timon', 'pumba', 'retel', 'origin', 'stori', 'eye', 'includ', 'stori', 'met', 'grand', 'tradit', 'disney', 'inferior', 'sequel', 'made', 'occasion', 'tv', 'seri', 'featur', 'adventur', 'minor', 'charact', 'biggest', 'hit', 'sceptic', 'want', 'kid', 'fan', 'seri', 'like', 'care', 'enough', 'joke', 'song', 'interest', 'thing', 'ensur', 'one', 'averag', 'sequel', 'work', 'charm', 'much', 'love', 'central', 'charact', 'quick', 'pace', 'joke', 'involv', 'first', 'film', 'older', 'viewer', 'funni', 'gag', 'anim', 'good', 'ever', 'littl', 'less', 'flamboy', 'origin', 'plot', 'take', 'easi', 'hakuna', 'matata', 'timon', 'pumba', 'decid', 'watch', 'event', 'first', 'film', 'frequent', 'stop', 'mid', 'film', 'joke', 'part', 'like', 'real', 'audienc', 'see', 'timon', 'near', 'outcast', 'feel', 'fit', 'decid', 'go', 'look', 'beyond', 'see', 'find', 'ideal', 'home', 'way', 'meet', 'pumba', 'anoth', 'outcast', 'becom', 'friend', 'soon', 'meet', 'simba', 'lion', 'cub', 'natur', 'predat', 'p', 'form', 'trio', 'howev', 'simba', 'realis', 'must', 'follow', 'destini', 'leav', 'group', 'other', 'decid', 'whether', 'help', 'cours', 'usual', 'disney', 'element', 'theme', 'friendship', 'good', 'versu', 'evil', 'etc', 'plot', 'simpl', 'work', 'mani', 'level', 'make', 'smarter', 'averag', 'anim', 'movi', 'cg', 'movi', 'appear', 'disney', 'tradit', 'form', 'must', 'becom', 'smarter', 'forget', 'root', 'made', 'popular', 'toy', 'stori', 'come', 'sinc', 'clever', 'joke', 'suit', 'age', 'seem', 'way', 'market', 'shift', 'howev', 'alway', 'place', 'film', 'like', 'cannot', 'go', 'wrong', 'buy', 'youngster', '7', '10'] 1 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "type(train_X), type(train_y)\n",
    "print(len(train_X))\n",
    "train_list = train_X[:30000]\n",
    "train_labels_list = train_y[:30000]\n",
    "test_list = train_X[30000:]\n",
    "test_labels_list = train_y[30000:]\n",
    "print(len(train_list), len(train_labels_list), len(test_list), len(test_labels_list))\n",
    "print(train_list[0], test_list[0], train_labels_list[0], test_labels_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_dict(data, vocab_size = 5000):\n",
    "    word_count = {} # A dict storing the words that appear in the reviews along with how often they occur\n",
    "    for sentence in data:\n",
    "        for word in sentence:\n",
    "            if word in word_count.keys():\n",
    "                word_count[word] = word_count[word] + 1\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "   \n",
    "    sorted_words = {k: v for k, v in sorted(word_count.items(), key=lambda item: item[1], reverse=True)}\n",
    "    sorted_words = [word for word in sorted_words.keys()]\n",
    "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
    "\n",
    "    for idx, word in enumerate(sorted_words[:vocab_size - 2]): # The -2 is so that we save room for the 'no word'\n",
    "        word_dict[word] = idx + 2                              # 'infrequent' labels\n",
    "        \n",
    "    return word_dict\n",
    "\n",
    "def convert_and_pad(word_dict, sentence, pad=500):\n",
    "    NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
    "    INFREQ = 1 # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
    "    \n",
    "    working_sentence = [NOWORD] * pad\n",
    "    \n",
    "    for word_index, word in enumerate(sentence[:pad]):\n",
    "        if word in word_dict:\n",
    "            working_sentence[word_index] = word_dict[word]\n",
    "        else:\n",
    "            working_sentence[word_index] = INFREQ\n",
    "            \n",
    "    return working_sentence, min(len(sentence), pad)\n",
    "\n",
    "def convert_and_pad_data(word_dict, data, pad=500):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "        \n",
    "    return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = build_dict(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/pytorch' # The folder we will use for storing data\n",
    "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'word_dict_qrnn.pkl'), \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_X_len = convert_and_pad_data(word_dict, train_list)\n",
    "test_X, test_X_len = convert_and_pad_data(word_dict, test_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 500) 30000\n",
      "(20000, 500) 20000\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, len(train_X_len))\n",
    "print(test_X.shape, len(test_X_len))\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.concat([pd.DataFrame(train_labels_list), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1).to_csv(os.path.join(data_dir, 'train_qrnn.csv'), header=False, index=False)\n",
    "pd.concat([pd.DataFrame(test_labels_list), pd.DataFrame(test_X_len), pd.DataFrame(test_X)], axis=1).to_csv(os.path.join(data_dir, 'test_qrnn.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If Files present start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "data_dir = './data/pytorch'\n",
    "with open(os.path.join(data_dir, 'word_dict_qrnn.pkl'), \"rb\") as f:\n",
    "    word_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 502) (20000, 502)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "train = pd.read_csv(os.path.join(data_dir, 'train_qrnn.csv'), header=None, names=None)\n",
    "test_sample = pd.read_csv(os.path.join(data_dir, 'test_qrnn.csv'), header=None, names=None)\n",
    "print(train.shape, test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 502), (10000, 502), (10000, 502))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test, val = train_test_split(test_sample, test_size=0.5)\n",
    "train.shape, test.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_y = torch.from_numpy(train[[0]].values).float()\n",
    "train_X = torch.from_numpy(train.drop([0, 1], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
    "# Build the dataloader\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
    "\n",
    "######val data\n",
    "# Turn the input pandas dataframe into tensors\n",
    "val_y = torch.from_numpy(val[[0]].values).float()\n",
    "val_X = torch.from_numpy(val.drop([0, 1], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "val_ds = torch.utils.data.TensorDataset(val_X, val_y)\n",
    "# Build the dataloader\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=50)\n",
    "\n",
    "\n",
    "#### Test data\n",
    "# Turn the input pandas dataframe into tensors\n",
    "test_y = torch.from_numpy(test[[0]].values).float()\n",
    "test_X = torch.from_numpy(test.drop([0, 1], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "test_ds = torch.utils.data.TensorDataset(test_X, test_y)\n",
    "# Build the dataloader\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=50)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QRNNLayer(nn.Module):\n",
    "    def __init__(self,batch_size,input_size,n_filters,kernel_size,embed_size,device,dropout):\n",
    "        super(QRNNLayer,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.embed_size = embed_size\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.device = device\n",
    "        self.conv1 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
    "        self.conv2 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
    "        self.conv3 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
    "    \n",
    "    def forward(self,masked_input, h, c):\n",
    "        Z,F,O = self.masked_conv(masked_input)\n",
    "        h, c = self.pool(c,Z,F,O)\n",
    "        masked_input = h\n",
    "        return masked_input,h,c\n",
    "    \n",
    "    def masked_conv(self,x):\n",
    "        pad = torch.zeros([self.batch_size,1,self.input_size],device=self.device)\n",
    "        x = torch.cat([pad,x],1).permute(0,2,1)\n",
    "        Z = torch.tanh((self.conv1(x)))\n",
    "        F = torch.sigmoid((self.conv2(x)))\n",
    "        O = torch.sigmoid((self.conv3(x)))\n",
    "        one_mask = torch.ones_like(F,device=self.device) - F\n",
    "        F = 1 - self.dropout(one_mask)\n",
    "        return Z.permute(0,2,1), F.permute(0,2,1), O.permute(0,2,1)\n",
    "    \n",
    "    def pool(self, prev_c,Z,F,O):\n",
    "        c = torch.mul(F,prev_c) + torch.mul(1-F,Z)\n",
    "        h = torch.mul(O,c)\n",
    "        return h,c\n",
    "\n",
    "class QRNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,n_filters,kernel_size,batch_size,seq_len,layers,device,dropout):\n",
    "        super(QRNN,self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.num_layer = layers\n",
    "        self.device = device\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_size)\n",
    "        self.dense = torch.nn.Linear(self.seq_len*self.n_filters,1)\n",
    "        self.QRNN_layers = torch.nn.ModuleList([QRNNLayer(self.batch_size,embed_size if l==0 else n_filters,\n",
    "                                                         self.n_filters,self.kernel_size,self.embed_size,self.device,\n",
    "                                                         dropout,) for l in range(self.num_layer)])\n",
    "        \n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        x = self.embedding(x)\n",
    "        h = torch.zeros([self.batch_size,self.seq_len,self.n_filters],device=self.device)\n",
    "        c = torch.zeros_like(h,device=self.device)\n",
    "        \n",
    "        masked_input = x\n",
    "        for l,layer in enumerate(self.QRNN_layers):\n",
    "            masked_input,h,c = layer(masked_input,h,c)\n",
    "        dense_input = h.reshape([self.batch_size,-1])\n",
    "        logits = self.dense(dense_input)\n",
    "        prediction = torch.sigmoid(logits)\n",
    "        target = target.view([-1,1])\n",
    "        correct_pred = torch.eq(torch.round(prediction).type(target.type()),target)\n",
    "        accuracy = torch.sum(correct_pred)\n",
    "        return prediction, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4998\n",
      "5000\n",
      "Epoch: 0/10 \tIteration: 0 \tTrain Loss: 0.696 \tTrain Accuracy: 46.00\n",
      "Val Loss: 0.726 \tVal Acc: 50.610\n",
      "Epoch: 0/10 \tIteration: 10 \tTrain Loss: 0.698 \tTrain Accuracy: 48.00\n",
      "Epoch: 0/10 \tIteration: 20 \tTrain Loss: 0.715 \tTrain Accuracy: 48.00\n",
      "Epoch: 0/10 \tIteration: 30 \tTrain Loss: 0.669 \tTrain Accuracy: 56.00\n",
      "Epoch: 0/10 \tIteration: 40 \tTrain Loss: 0.675 \tTrain Accuracy: 62.00\n",
      "Epoch: 0/10 \tIteration: 50 \tTrain Loss: 0.698 \tTrain Accuracy: 56.00\n",
      "Epoch: 0/10 \tIteration: 60 \tTrain Loss: 0.691 \tTrain Accuracy: 48.00\n",
      "Epoch: 0/10 \tIteration: 70 \tTrain Loss: 0.710 \tTrain Accuracy: 48.00\n",
      "Epoch: 0/10 \tIteration: 80 \tTrain Loss: 0.681 \tTrain Accuracy: 64.00\n",
      "Epoch: 0/10 \tIteration: 90 \tTrain Loss: 0.703 \tTrain Accuracy: 52.00\n",
      "Epoch: 0/10 \tIteration: 100 \tTrain Loss: 0.676 \tTrain Accuracy: 52.00\n",
      "Epoch: 0/10 \tIteration: 110 \tTrain Loss: 0.700 \tTrain Accuracy: 54.00\n",
      "Epoch: 0/10 \tIteration: 120 \tTrain Loss: 0.686 \tTrain Accuracy: 60.00\n",
      "Epoch: 0/10 \tIteration: 130 \tTrain Loss: 0.695 \tTrain Accuracy: 54.00\n",
      "Epoch: 0/10 \tIteration: 140 \tTrain Loss: 0.641 \tTrain Accuracy: 60.00\n",
      "Epoch: 0/10 \tIteration: 150 \tTrain Loss: 0.670 \tTrain Accuracy: 60.00\n",
      "Epoch: 0/10 \tIteration: 160 \tTrain Loss: 0.679 \tTrain Accuracy: 54.00\n",
      "Epoch: 0/10 \tIteration: 170 \tTrain Loss: 0.663 \tTrain Accuracy: 50.00\n",
      "Epoch: 0/10 \tIteration: 180 \tTrain Loss: 0.697 \tTrain Accuracy: 54.00\n",
      "Epoch: 0/10 \tIteration: 190 \tTrain Loss: 0.592 \tTrain Accuracy: 64.00\n",
      "Epoch: 0/10 \tIteration: 200 \tTrain Loss: 0.657 \tTrain Accuracy: 68.00\n",
      "Epoch: 0/10 \tIteration: 210 \tTrain Loss: 0.588 \tTrain Accuracy: 76.00\n",
      "Epoch: 0/10 \tIteration: 220 \tTrain Loss: 0.642 \tTrain Accuracy: 64.00\n",
      "Epoch: 0/10 \tIteration: 230 \tTrain Loss: 0.511 \tTrain Accuracy: 76.00\n",
      "Epoch: 0/10 \tIteration: 240 \tTrain Loss: 0.685 \tTrain Accuracy: 66.00\n",
      "Epoch: 0/10 \tIteration: 250 \tTrain Loss: 0.594 \tTrain Accuracy: 64.00\n",
      "Epoch: 0/10 \tIteration: 260 \tTrain Loss: 0.537 \tTrain Accuracy: 72.00\n",
      "Epoch: 0/10 \tIteration: 270 \tTrain Loss: 0.466 \tTrain Accuracy: 80.00\n",
      "Epoch: 0/10 \tIteration: 280 \tTrain Loss: 0.559 \tTrain Accuracy: 68.00\n",
      "Epoch: 0/10 \tIteration: 290 \tTrain Loss: 0.575 \tTrain Accuracy: 70.00\n",
      "Epoch: 0/10 \tIteration: 300 \tTrain Loss: 0.604 \tTrain Accuracy: 64.00\n",
      "Epoch: 0/10 \tIteration: 310 \tTrain Loss: 0.458 \tTrain Accuracy: 78.00\n",
      "Epoch: 0/10 \tIteration: 320 \tTrain Loss: 0.565 \tTrain Accuracy: 72.00\n",
      "Epoch: 0/10 \tIteration: 330 \tTrain Loss: 0.384 \tTrain Accuracy: 86.00\n",
      "Epoch: 0/10 \tIteration: 340 \tTrain Loss: 0.518 \tTrain Accuracy: 68.00\n",
      "Epoch: 0/10 \tIteration: 350 \tTrain Loss: 0.406 \tTrain Accuracy: 82.00\n",
      "Epoch: 0/10 \tIteration: 360 \tTrain Loss: 0.501 \tTrain Accuracy: 78.00\n",
      "Epoch: 0/10 \tIteration: 370 \tTrain Loss: 0.603 \tTrain Accuracy: 68.00\n",
      "Epoch: 0/10 \tIteration: 380 \tTrain Loss: 0.506 \tTrain Accuracy: 80.00\n",
      "Epoch: 0/10 \tIteration: 390 \tTrain Loss: 0.380 \tTrain Accuracy: 88.00\n",
      "Epoch: 0/10 \tIteration: 400 \tTrain Loss: 0.489 \tTrain Accuracy: 78.00\n",
      "Epoch: 0/10 \tIteration: 410 \tTrain Loss: 0.453 \tTrain Accuracy: 76.00\n",
      "Epoch: 0/10 \tIteration: 420 \tTrain Loss: 0.466 \tTrain Accuracy: 80.00\n",
      "Epoch: 0/10 \tIteration: 430 \tTrain Loss: 0.507 \tTrain Accuracy: 72.00\n",
      "Epoch: 0/10 \tIteration: 440 \tTrain Loss: 0.367 \tTrain Accuracy: 90.00\n",
      "Epoch: 0/10 \tIteration: 450 \tTrain Loss: 0.571 \tTrain Accuracy: 72.00\n",
      "Epoch: 0/10 \tIteration: 460 \tTrain Loss: 0.431 \tTrain Accuracy: 82.00\n",
      "Epoch: 0/10 \tIteration: 470 \tTrain Loss: 0.500 \tTrain Accuracy: 74.00\n",
      "Epoch: 0/10 \tIteration: 480 \tTrain Loss: 0.504 \tTrain Accuracy: 74.00\n",
      "Epoch: 0/10 \tIteration: 490 \tTrain Loss: 0.489 \tTrain Accuracy: 78.00\n",
      "Epoch: 0/10 \tIteration: 500 \tTrain Loss: 0.390 \tTrain Accuracy: 84.00\n",
      "Epoch: 0/10 \tIteration: 510 \tTrain Loss: 0.457 \tTrain Accuracy: 72.00\n",
      "Epoch: 0/10 \tIteration: 520 \tTrain Loss: 0.456 \tTrain Accuracy: 80.00\n",
      "Epoch: 0/10 \tIteration: 530 \tTrain Loss: 0.558 \tTrain Accuracy: 76.00\n",
      "Epoch: 0/10 \tIteration: 540 \tTrain Loss: 0.465 \tTrain Accuracy: 76.00\n",
      "Epoch: 0/10 \tIteration: 550 \tTrain Loss: 0.335 \tTrain Accuracy: 88.00\n",
      "Epoch: 0/10 \tIteration: 560 \tTrain Loss: 0.452 \tTrain Accuracy: 80.00\n",
      "Epoch: 0/10 \tIteration: 570 \tTrain Loss: 0.305 \tTrain Accuracy: 88.00\n",
      "Epoch: 0/10 \tIteration: 580 \tTrain Loss: 0.424 \tTrain Accuracy: 80.00\n",
      "Epoch: 0/10 \tIteration: 590 \tTrain Loss: 0.530 \tTrain Accuracy: 80.00\n",
      "Val Loss: 0.423 \tVal Acc: 81.320\n",
      "Time to train epoch: 16.804113626480103 s\n",
      "Epoch: 1/10 \tIteration: 600 \tTrain Loss: 0.310 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 610 \tTrain Loss: 0.297 \tTrain Accuracy: 90.00\n",
      "Epoch: 1/10 \tIteration: 620 \tTrain Loss: 0.554 \tTrain Accuracy: 72.00\n",
      "Epoch: 1/10 \tIteration: 630 \tTrain Loss: 0.334 \tTrain Accuracy: 86.00\n",
      "Epoch: 1/10 \tIteration: 640 \tTrain Loss: 0.351 \tTrain Accuracy: 84.00\n",
      "Epoch: 1/10 \tIteration: 650 \tTrain Loss: 0.352 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 660 \tTrain Loss: 0.217 \tTrain Accuracy: 92.00\n",
      "Epoch: 1/10 \tIteration: 670 \tTrain Loss: 0.405 \tTrain Accuracy: 74.00\n",
      "Epoch: 1/10 \tIteration: 680 \tTrain Loss: 0.372 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 690 \tTrain Loss: 0.273 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 700 \tTrain Loss: 0.419 \tTrain Accuracy: 78.00\n",
      "Epoch: 1/10 \tIteration: 710 \tTrain Loss: 0.372 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 720 \tTrain Loss: 0.322 \tTrain Accuracy: 84.00\n",
      "Epoch: 1/10 \tIteration: 730 \tTrain Loss: 0.356 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 740 \tTrain Loss: 0.294 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 750 \tTrain Loss: 0.437 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 760 \tTrain Loss: 0.432 \tTrain Accuracy: 86.00\n",
      "Epoch: 1/10 \tIteration: 770 \tTrain Loss: 0.300 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 780 \tTrain Loss: 0.355 \tTrain Accuracy: 92.00\n",
      "Epoch: 1/10 \tIteration: 790 \tTrain Loss: 0.363 \tTrain Accuracy: 86.00\n",
      "Epoch: 1/10 \tIteration: 800 \tTrain Loss: 0.394 \tTrain Accuracy: 86.00\n",
      "Epoch: 1/10 \tIteration: 810 \tTrain Loss: 0.187 \tTrain Accuracy: 92.00\n",
      "Epoch: 1/10 \tIteration: 820 \tTrain Loss: 0.485 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 830 \tTrain Loss: 0.281 \tTrain Accuracy: 86.00\n",
      "Epoch: 1/10 \tIteration: 840 \tTrain Loss: 0.487 \tTrain Accuracy: 80.00\n",
      "Epoch: 1/10 \tIteration: 850 \tTrain Loss: 0.390 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 860 \tTrain Loss: 0.347 \tTrain Accuracy: 80.00\n",
      "Epoch: 1/10 \tIteration: 870 \tTrain Loss: 0.250 \tTrain Accuracy: 94.00\n",
      "Epoch: 1/10 \tIteration: 880 \tTrain Loss: 0.305 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 890 \tTrain Loss: 0.327 \tTrain Accuracy: 80.00\n",
      "Epoch: 1/10 \tIteration: 900 \tTrain Loss: 0.418 \tTrain Accuracy: 84.00\n",
      "Epoch: 1/10 \tIteration: 910 \tTrain Loss: 0.218 \tTrain Accuracy: 96.00\n",
      "Epoch: 1/10 \tIteration: 920 \tTrain Loss: 0.299 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 930 \tTrain Loss: 0.282 \tTrain Accuracy: 86.00\n",
      "Epoch: 1/10 \tIteration: 940 \tTrain Loss: 0.271 \tTrain Accuracy: 90.00\n",
      "Epoch: 1/10 \tIteration: 950 \tTrain Loss: 0.238 \tTrain Accuracy: 90.00\n",
      "Epoch: 1/10 \tIteration: 960 \tTrain Loss: 0.356 \tTrain Accuracy: 80.00\n",
      "Epoch: 1/10 \tIteration: 970 \tTrain Loss: 0.359 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 980 \tTrain Loss: 0.329 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 990 \tTrain Loss: 0.275 \tTrain Accuracy: 94.00\n",
      "Epoch: 1/10 \tIteration: 1000 \tTrain Loss: 0.340 \tTrain Accuracy: 84.00\n",
      "Epoch: 1/10 \tIteration: 1010 \tTrain Loss: 0.261 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 1020 \tTrain Loss: 0.276 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 1030 \tTrain Loss: 0.377 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 1040 \tTrain Loss: 0.208 \tTrain Accuracy: 92.00\n",
      "Epoch: 1/10 \tIteration: 1050 \tTrain Loss: 0.540 \tTrain Accuracy: 76.00\n",
      "Epoch: 1/10 \tIteration: 1060 \tTrain Loss: 0.235 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 1070 \tTrain Loss: 0.377 \tTrain Accuracy: 84.00\n",
      "Epoch: 1/10 \tIteration: 1080 \tTrain Loss: 0.274 \tTrain Accuracy: 90.00\n",
      "Epoch: 1/10 \tIteration: 1090 \tTrain Loss: 0.360 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 1100 \tTrain Loss: 0.251 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 1110 \tTrain Loss: 0.272 \tTrain Accuracy: 86.00\n",
      "Epoch: 1/10 \tIteration: 1120 \tTrain Loss: 0.316 \tTrain Accuracy: 86.00\n",
      "Epoch: 1/10 \tIteration: 1130 \tTrain Loss: 0.349 \tTrain Accuracy: 86.00\n",
      "Epoch: 1/10 \tIteration: 1140 \tTrain Loss: 0.356 \tTrain Accuracy: 82.00\n",
      "Epoch: 1/10 \tIteration: 1150 \tTrain Loss: 0.212 \tTrain Accuracy: 94.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 \tIteration: 1160 \tTrain Loss: 0.311 \tTrain Accuracy: 80.00\n",
      "Epoch: 1/10 \tIteration: 1170 \tTrain Loss: 0.207 \tTrain Accuracy: 96.00\n",
      "Epoch: 1/10 \tIteration: 1180 \tTrain Loss: 0.335 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 1190 \tTrain Loss: 0.498 \tTrain Accuracy: 84.00\n",
      "Val Loss: 0.377 \tVal Acc: 83.770\n",
      "Time to train epoch: 15.074833393096924 s\n",
      "Epoch: 2/10 \tIteration: 1200 \tTrain Loss: 0.165 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 1210 \tTrain Loss: 0.250 \tTrain Accuracy: 88.00\n",
      "Epoch: 2/10 \tIteration: 1220 \tTrain Loss: 0.323 \tTrain Accuracy: 80.00\n",
      "Epoch: 2/10 \tIteration: 1230 \tTrain Loss: 0.254 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 1240 \tTrain Loss: 0.266 \tTrain Accuracy: 90.00\n",
      "Epoch: 2/10 \tIteration: 1250 \tTrain Loss: 0.237 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 1260 \tTrain Loss: 0.142 \tTrain Accuracy: 96.00\n",
      "Epoch: 2/10 \tIteration: 1270 \tTrain Loss: 0.323 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 1280 \tTrain Loss: 0.250 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 1290 \tTrain Loss: 0.168 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1300 \tTrain Loss: 0.312 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 1310 \tTrain Loss: 0.290 \tTrain Accuracy: 88.00\n",
      "Epoch: 2/10 \tIteration: 1320 \tTrain Loss: 0.217 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 1330 \tTrain Loss: 0.237 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 1340 \tTrain Loss: 0.187 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1350 \tTrain Loss: 0.294 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 1360 \tTrain Loss: 0.243 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 1370 \tTrain Loss: 0.187 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1380 \tTrain Loss: 0.149 \tTrain Accuracy: 98.00\n",
      "Epoch: 2/10 \tIteration: 1390 \tTrain Loss: 0.257 \tTrain Accuracy: 90.00\n",
      "Epoch: 2/10 \tIteration: 1400 \tTrain Loss: 0.320 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1410 \tTrain Loss: 0.110 \tTrain Accuracy: 100.00\n",
      "Epoch: 2/10 \tIteration: 1420 \tTrain Loss: 0.313 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 1430 \tTrain Loss: 0.231 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1440 \tTrain Loss: 0.344 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1450 \tTrain Loss: 0.305 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 1460 \tTrain Loss: 0.369 \tTrain Accuracy: 82.00\n",
      "Epoch: 2/10 \tIteration: 1470 \tTrain Loss: 0.157 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 1480 \tTrain Loss: 0.219 \tTrain Accuracy: 96.00\n",
      "Epoch: 2/10 \tIteration: 1490 \tTrain Loss: 0.196 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1500 \tTrain Loss: 0.339 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 1510 \tTrain Loss: 0.138 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 1520 \tTrain Loss: 0.203 \tTrain Accuracy: 96.00\n",
      "Epoch: 2/10 \tIteration: 1530 \tTrain Loss: 0.210 \tTrain Accuracy: 90.00\n",
      "Epoch: 2/10 \tIteration: 1540 \tTrain Loss: 0.220 \tTrain Accuracy: 88.00\n",
      "Epoch: 2/10 \tIteration: 1550 \tTrain Loss: 0.160 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 1560 \tTrain Loss: 0.261 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 1570 \tTrain Loss: 0.330 \tTrain Accuracy: 84.00\n",
      "Epoch: 2/10 \tIteration: 1580 \tTrain Loss: 0.255 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 1590 \tTrain Loss: 0.195 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1600 \tTrain Loss: 0.214 \tTrain Accuracy: 88.00\n",
      "Epoch: 2/10 \tIteration: 1610 \tTrain Loss: 0.193 \tTrain Accuracy: 88.00\n",
      "Epoch: 2/10 \tIteration: 1620 \tTrain Loss: 0.205 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1630 \tTrain Loss: 0.273 \tTrain Accuracy: 90.00\n",
      "Epoch: 2/10 \tIteration: 1640 \tTrain Loss: 0.162 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1650 \tTrain Loss: 0.409 \tTrain Accuracy: 82.00\n",
      "Epoch: 2/10 \tIteration: 1660 \tTrain Loss: 0.160 \tTrain Accuracy: 96.00\n",
      "Epoch: 2/10 \tIteration: 1670 \tTrain Loss: 0.284 \tTrain Accuracy: 90.00\n",
      "Epoch: 2/10 \tIteration: 1680 \tTrain Loss: 0.175 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1690 \tTrain Loss: 0.223 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1700 \tTrain Loss: 0.136 \tTrain Accuracy: 98.00\n",
      "Epoch: 2/10 \tIteration: 1710 \tTrain Loss: 0.228 \tTrain Accuracy: 90.00\n",
      "Epoch: 2/10 \tIteration: 1720 \tTrain Loss: 0.213 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1730 \tTrain Loss: 0.325 \tTrain Accuracy: 84.00\n",
      "Epoch: 2/10 \tIteration: 1740 \tTrain Loss: 0.306 \tTrain Accuracy: 84.00\n",
      "Epoch: 2/10 \tIteration: 1750 \tTrain Loss: 0.119 \tTrain Accuracy: 98.00\n",
      "Epoch: 2/10 \tIteration: 1760 \tTrain Loss: 0.214 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 1770 \tTrain Loss: 0.200 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 1780 \tTrain Loss: 0.243 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 1790 \tTrain Loss: 0.341 \tTrain Accuracy: 86.00\n",
      "Val Loss: 0.387 \tVal Acc: 84.730\n",
      "Time to train epoch: 15.181388139724731 s\n",
      "Epoch: 3/10 \tIteration: 1800 \tTrain Loss: 0.113 \tTrain Accuracy: 98.00\n",
      "Epoch: 3/10 \tIteration: 1810 \tTrain Loss: 0.177 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 1820 \tTrain Loss: 0.172 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 1830 \tTrain Loss: 0.171 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tIteration: 1840 \tTrain Loss: 0.211 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tIteration: 1850 \tTrain Loss: 0.169 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 1860 \tTrain Loss: 0.086 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 1870 \tTrain Loss: 0.249 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 1880 \tTrain Loss: 0.160 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 1890 \tTrain Loss: 0.107 \tTrain Accuracy: 98.00\n",
      "Epoch: 3/10 \tIteration: 1900 \tTrain Loss: 0.163 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 1910 \tTrain Loss: 0.164 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 1920 \tTrain Loss: 0.106 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 1930 \tTrain Loss: 0.223 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 1940 \tTrain Loss: 0.123 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 1950 \tTrain Loss: 0.132 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 1960 \tTrain Loss: 0.146 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 1970 \tTrain Loss: 0.150 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 1980 \tTrain Loss: 0.148 \tTrain Accuracy: 98.00\n",
      "Epoch: 3/10 \tIteration: 1990 \tTrain Loss: 0.213 \tTrain Accuracy: 88.00\n",
      "Epoch: 3/10 \tIteration: 2000 \tTrain Loss: 0.211 \tTrain Accuracy: 88.00\n",
      "Epoch: 3/10 \tIteration: 2010 \tTrain Loss: 0.072 \tTrain Accuracy: 98.00\n",
      "Epoch: 3/10 \tIteration: 2020 \tTrain Loss: 0.231 \tTrain Accuracy: 88.00\n",
      "Epoch: 3/10 \tIteration: 2030 \tTrain Loss: 0.144 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 2040 \tTrain Loss: 0.260 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 2050 \tTrain Loss: 0.167 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 2060 \tTrain Loss: 0.229 \tTrain Accuracy: 88.00\n",
      "Epoch: 3/10 \tIteration: 2070 \tTrain Loss: 0.132 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 2080 \tTrain Loss: 0.151 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 2090 \tTrain Loss: 0.155 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tIteration: 2100 \tTrain Loss: 0.209 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 2110 \tTrain Loss: 0.104 \tTrain Accuracy: 98.00\n",
      "Epoch: 3/10 \tIteration: 2120 \tTrain Loss: 0.109 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 2130 \tTrain Loss: 0.179 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 2140 \tTrain Loss: 0.066 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 2150 \tTrain Loss: 0.162 \tTrain Accuracy: 88.00\n",
      "Epoch: 3/10 \tIteration: 2160 \tTrain Loss: 0.222 \tTrain Accuracy: 88.00\n",
      "Epoch: 3/10 \tIteration: 2170 \tTrain Loss: 0.220 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tIteration: 2180 \tTrain Loss: 0.144 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 2190 \tTrain Loss: 0.215 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tIteration: 2200 \tTrain Loss: 0.141 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 2210 \tTrain Loss: 0.155 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 2220 \tTrain Loss: 0.178 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tIteration: 2230 \tTrain Loss: 0.177 \tTrain Accuracy: 88.00\n",
      "Epoch: 3/10 \tIteration: 2240 \tTrain Loss: 0.057 \tTrain Accuracy: 98.00\n",
      "Epoch: 3/10 \tIteration: 2250 \tTrain Loss: 0.263 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 2260 \tTrain Loss: 0.073 \tTrain Accuracy: 98.00\n",
      "Epoch: 3/10 \tIteration: 2270 \tTrain Loss: 0.205 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 2280 \tTrain Loss: 0.188 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tIteration: 2290 \tTrain Loss: 0.289 \tTrain Accuracy: 88.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 \tIteration: 2300 \tTrain Loss: 0.100 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 2310 \tTrain Loss: 0.174 \tTrain Accuracy: 96.00\n",
      "Epoch: 3/10 \tIteration: 2320 \tTrain Loss: 0.233 \tTrain Accuracy: 88.00\n",
      "Epoch: 3/10 \tIteration: 2330 \tTrain Loss: 0.280 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tIteration: 2340 \tTrain Loss: 0.173 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 2350 \tTrain Loss: 0.050 \tTrain Accuracy: 100.00\n",
      "Epoch: 3/10 \tIteration: 2360 \tTrain Loss: 0.152 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 2370 \tTrain Loss: 0.161 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 2380 \tTrain Loss: 0.074 \tTrain Accuracy: 98.00\n",
      "Epoch: 3/10 \tIteration: 2390 \tTrain Loss: 0.205 \tTrain Accuracy: 90.00\n",
      "Val Loss: 0.440 \tVal Acc: 84.740\n",
      "Time to train epoch: 15.554868936538696 s\n",
      "Epoch: 4/10 \tIteration: 2400 \tTrain Loss: 0.076 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2410 \tTrain Loss: 0.131 \tTrain Accuracy: 94.00\n",
      "Epoch: 4/10 \tIteration: 2420 \tTrain Loss: 0.092 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2430 \tTrain Loss: 0.117 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2440 \tTrain Loss: 0.213 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 2450 \tTrain Loss: 0.100 \tTrain Accuracy: 94.00\n",
      "Epoch: 4/10 \tIteration: 2460 \tTrain Loss: 0.030 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2470 \tTrain Loss: 0.129 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2480 \tTrain Loss: 0.148 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2490 \tTrain Loss: 0.128 \tTrain Accuracy: 94.00\n",
      "Epoch: 4/10 \tIteration: 2500 \tTrain Loss: 0.105 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2510 \tTrain Loss: 0.108 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2520 \tTrain Loss: 0.106 \tTrain Accuracy: 94.00\n",
      "Epoch: 4/10 \tIteration: 2530 \tTrain Loss: 0.083 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2540 \tTrain Loss: 0.071 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2550 \tTrain Loss: 0.075 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2560 \tTrain Loss: 0.070 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2570 \tTrain Loss: 0.126 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 2580 \tTrain Loss: 0.116 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2590 \tTrain Loss: 0.175 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 2600 \tTrain Loss: 0.153 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2610 \tTrain Loss: 0.037 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2620 \tTrain Loss: 0.146 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2630 \tTrain Loss: 0.089 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2640 \tTrain Loss: 0.140 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2650 \tTrain Loss: 0.129 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2660 \tTrain Loss: 0.223 \tTrain Accuracy: 94.00\n",
      "Epoch: 4/10 \tIteration: 2670 \tTrain Loss: 0.122 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 2680 \tTrain Loss: 0.082 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2690 \tTrain Loss: 0.066 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2700 \tTrain Loss: 0.237 \tTrain Accuracy: 88.00\n",
      "Epoch: 4/10 \tIteration: 2710 \tTrain Loss: 0.086 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2720 \tTrain Loss: 0.078 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2730 \tTrain Loss: 0.121 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2740 \tTrain Loss: 0.030 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2750 \tTrain Loss: 0.117 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2760 \tTrain Loss: 0.124 \tTrain Accuracy: 94.00\n",
      "Epoch: 4/10 \tIteration: 2770 \tTrain Loss: 0.159 \tTrain Accuracy: 94.00\n",
      "Epoch: 4/10 \tIteration: 2780 \tTrain Loss: 0.149 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 2790 \tTrain Loss: 0.162 \tTrain Accuracy: 90.00\n",
      "Epoch: 4/10 \tIteration: 2800 \tTrain Loss: 0.073 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2810 \tTrain Loss: 0.201 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 2820 \tTrain Loss: 0.149 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2830 \tTrain Loss: 0.127 \tTrain Accuracy: 94.00\n",
      "Epoch: 4/10 \tIteration: 2840 \tTrain Loss: 0.034 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2850 \tTrain Loss: 0.119 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2860 \tTrain Loss: 0.087 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2870 \tTrain Loss: 0.136 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2880 \tTrain Loss: 0.027 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 2890 \tTrain Loss: 0.149 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 2900 \tTrain Loss: 0.052 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2910 \tTrain Loss: 0.144 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 2920 \tTrain Loss: 0.078 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2930 \tTrain Loss: 0.107 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2940 \tTrain Loss: 0.202 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 2950 \tTrain Loss: 0.052 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2960 \tTrain Loss: 0.101 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 2970 \tTrain Loss: 0.112 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2980 \tTrain Loss: 0.074 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 2990 \tTrain Loss: 0.079 \tTrain Accuracy: 100.00\n",
      "Val Loss: 0.508 \tVal Acc: 85.020\n",
      "Time to train epoch: 15.032347917556763 s\n",
      "Epoch: 5/10 \tIteration: 3000 \tTrain Loss: 0.035 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3010 \tTrain Loss: 0.073 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3020 \tTrain Loss: 0.125 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3030 \tTrain Loss: 0.131 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 3040 \tTrain Loss: 0.226 \tTrain Accuracy: 90.00\n",
      "Epoch: 5/10 \tIteration: 3050 \tTrain Loss: 0.060 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3060 \tTrain Loss: 0.027 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3070 \tTrain Loss: 0.080 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3080 \tTrain Loss: 0.136 \tTrain Accuracy: 92.00\n",
      "Epoch: 5/10 \tIteration: 3090 \tTrain Loss: 0.157 \tTrain Accuracy: 90.00\n",
      "Epoch: 5/10 \tIteration: 3100 \tTrain Loss: 0.082 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3110 \tTrain Loss: 0.036 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3120 \tTrain Loss: 0.181 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 3130 \tTrain Loss: 0.015 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3140 \tTrain Loss: 0.062 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3150 \tTrain Loss: 0.046 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3160 \tTrain Loss: 0.033 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3170 \tTrain Loss: 0.045 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3180 \tTrain Loss: 0.035 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3190 \tTrain Loss: 0.055 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3200 \tTrain Loss: 0.084 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3210 \tTrain Loss: 0.026 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3220 \tTrain Loss: 0.123 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3230 \tTrain Loss: 0.026 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3240 \tTrain Loss: 0.075 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3250 \tTrain Loss: 0.120 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 3260 \tTrain Loss: 0.126 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 3270 \tTrain Loss: 0.071 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3280 \tTrain Loss: 0.073 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3290 \tTrain Loss: 0.064 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3300 \tTrain Loss: 0.030 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3310 \tTrain Loss: 0.062 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3320 \tTrain Loss: 0.158 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3330 \tTrain Loss: 0.119 \tTrain Accuracy: 90.00\n",
      "Epoch: 5/10 \tIteration: 3340 \tTrain Loss: 0.026 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3350 \tTrain Loss: 0.048 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3360 \tTrain Loss: 0.058 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3370 \tTrain Loss: 0.142 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 3380 \tTrain Loss: 0.024 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3390 \tTrain Loss: 0.111 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3400 \tTrain Loss: 0.112 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3410 \tTrain Loss: 0.052 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3420 \tTrain Loss: 0.034 \tTrain Accuracy: 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10 \tIteration: 3430 \tTrain Loss: 0.040 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3440 \tTrain Loss: 0.036 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3450 \tTrain Loss: 0.171 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3460 \tTrain Loss: 0.062 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3470 \tTrain Loss: 0.088 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3480 \tTrain Loss: 0.025 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3490 \tTrain Loss: 0.115 \tTrain Accuracy: 92.00\n",
      "Epoch: 5/10 \tIteration: 3500 \tTrain Loss: 0.036 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3510 \tTrain Loss: 0.103 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 3520 \tTrain Loss: 0.100 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 3530 \tTrain Loss: 0.062 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3540 \tTrain Loss: 0.092 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3550 \tTrain Loss: 0.028 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3560 \tTrain Loss: 0.026 \tTrain Accuracy: 100.00\n",
      "Epoch: 5/10 \tIteration: 3570 \tTrain Loss: 0.126 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 3580 \tTrain Loss: 0.056 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 3590 \tTrain Loss: 0.166 \tTrain Accuracy: 94.00\n",
      "Val Loss: 0.603 \tVal Acc: 84.200\n",
      "Time to train epoch: 15.040513277053833 s\n",
      "Epoch: 6/10 \tIteration: 3600 \tTrain Loss: 0.019 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3610 \tTrain Loss: 0.051 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3620 \tTrain Loss: 0.092 \tTrain Accuracy: 94.00\n",
      "Epoch: 6/10 \tIteration: 3630 \tTrain Loss: 0.102 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 3640 \tTrain Loss: 0.030 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3650 \tTrain Loss: 0.109 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3660 \tTrain Loss: 0.030 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3670 \tTrain Loss: 0.054 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 3680 \tTrain Loss: 0.082 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 3690 \tTrain Loss: 0.025 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3700 \tTrain Loss: 0.037 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3710 \tTrain Loss: 0.110 \tTrain Accuracy: 94.00\n",
      "Epoch: 6/10 \tIteration: 3720 \tTrain Loss: 0.072 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3730 \tTrain Loss: 0.067 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3740 \tTrain Loss: 0.051 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3750 \tTrain Loss: 0.034 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3760 \tTrain Loss: 0.030 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3770 \tTrain Loss: 0.025 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3780 \tTrain Loss: 0.084 \tTrain Accuracy: 94.00\n",
      "Epoch: 6/10 \tIteration: 3790 \tTrain Loss: 0.033 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3800 \tTrain Loss: 0.078 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3810 \tTrain Loss: 0.015 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3820 \tTrain Loss: 0.064 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3830 \tTrain Loss: 0.118 \tTrain Accuracy: 94.00\n",
      "Epoch: 6/10 \tIteration: 3840 \tTrain Loss: 0.061 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3850 \tTrain Loss: 0.123 \tTrain Accuracy: 92.00\n",
      "Epoch: 6/10 \tIteration: 3860 \tTrain Loss: 0.107 \tTrain Accuracy: 94.00\n",
      "Epoch: 6/10 \tIteration: 3870 \tTrain Loss: 0.021 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3880 \tTrain Loss: 0.021 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3890 \tTrain Loss: 0.022 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3900 \tTrain Loss: 0.023 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3910 \tTrain Loss: 0.030 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3920 \tTrain Loss: 0.023 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3930 \tTrain Loss: 0.016 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 3940 \tTrain Loss: 0.104 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 3950 \tTrain Loss: 0.093 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 3960 \tTrain Loss: 0.091 \tTrain Accuracy: 94.00\n",
      "Epoch: 6/10 \tIteration: 3970 \tTrain Loss: 0.093 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 3980 \tTrain Loss: 0.054 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 3990 \tTrain Loss: 0.079 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 4000 \tTrain Loss: 0.081 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 4010 \tTrain Loss: 0.073 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 4020 \tTrain Loss: 0.028 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 4030 \tTrain Loss: 0.065 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 4040 \tTrain Loss: 0.009 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 4050 \tTrain Loss: 0.054 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 4060 \tTrain Loss: 0.032 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 4070 \tTrain Loss: 0.143 \tTrain Accuracy: 90.00\n",
      "Epoch: 6/10 \tIteration: 4080 \tTrain Loss: 0.062 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 4090 \tTrain Loss: 0.060 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 4100 \tTrain Loss: 0.067 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 4110 \tTrain Loss: 0.051 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 4120 \tTrain Loss: 0.029 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 4130 \tTrain Loss: 0.063 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 4140 \tTrain Loss: 0.037 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 4150 \tTrain Loss: 0.035 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 4160 \tTrain Loss: 0.123 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 4170 \tTrain Loss: 0.049 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 4180 \tTrain Loss: 0.016 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 4190 \tTrain Loss: 0.065 \tTrain Accuracy: 96.00\n",
      "Val Loss: 0.686 \tVal Acc: 85.480\n",
      "Time to train epoch: 15.04534912109375 s\n",
      "Epoch: 7/10 \tIteration: 4200 \tTrain Loss: 0.022 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4210 \tTrain Loss: 0.035 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4220 \tTrain Loss: 0.092 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 4230 \tTrain Loss: 0.023 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4240 \tTrain Loss: 0.050 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 4250 \tTrain Loss: 0.122 \tTrain Accuracy: 94.00\n",
      "Epoch: 7/10 \tIteration: 4260 \tTrain Loss: 0.026 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4270 \tTrain Loss: 0.023 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4280 \tTrain Loss: 0.039 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4290 \tTrain Loss: 0.006 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4300 \tTrain Loss: 0.043 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4310 \tTrain Loss: 0.035 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4320 \tTrain Loss: 0.022 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4330 \tTrain Loss: 0.102 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 4340 \tTrain Loss: 0.048 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4350 \tTrain Loss: 0.040 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4360 \tTrain Loss: 0.043 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4370 \tTrain Loss: 0.041 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4380 \tTrain Loss: 0.036 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4390 \tTrain Loss: 0.027 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4400 \tTrain Loss: 0.030 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4410 \tTrain Loss: 0.009 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4420 \tTrain Loss: 0.070 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4430 \tTrain Loss: 0.025 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4440 \tTrain Loss: 0.073 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 4450 \tTrain Loss: 0.088 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 4460 \tTrain Loss: 0.055 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4470 \tTrain Loss: 0.019 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4480 \tTrain Loss: 0.072 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4490 \tTrain Loss: 0.016 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4500 \tTrain Loss: 0.041 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4510 \tTrain Loss: 0.040 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4520 \tTrain Loss: 0.017 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4530 \tTrain Loss: 0.033 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4540 \tTrain Loss: 0.046 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4550 \tTrain Loss: 0.010 \tTrain Accuracy: 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10 \tIteration: 4560 \tTrain Loss: 0.048 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4570 \tTrain Loss: 0.073 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 4580 \tTrain Loss: 0.044 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4590 \tTrain Loss: 0.032 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4600 \tTrain Loss: 0.089 \tTrain Accuracy: 94.00\n",
      "Epoch: 7/10 \tIteration: 4610 \tTrain Loss: 0.061 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4620 \tTrain Loss: 0.070 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 4630 \tTrain Loss: 0.031 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4640 \tTrain Loss: 0.010 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4650 \tTrain Loss: 0.056 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4660 \tTrain Loss: 0.010 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4670 \tTrain Loss: 0.022 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4680 \tTrain Loss: 0.015 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4690 \tTrain Loss: 0.057 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4700 \tTrain Loss: 0.057 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4710 \tTrain Loss: 0.053 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4720 \tTrain Loss: 0.013 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4730 \tTrain Loss: 0.069 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 4740 \tTrain Loss: 0.176 \tTrain Accuracy: 94.00\n",
      "Epoch: 7/10 \tIteration: 4750 \tTrain Loss: 0.077 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 4760 \tTrain Loss: 0.020 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 4770 \tTrain Loss: 0.058 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4780 \tTrain Loss: 0.126 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 4790 \tTrain Loss: 0.023 \tTrain Accuracy: 98.00\n",
      "Val Loss: 0.823 \tVal Acc: 85.150\n",
      "Time to train epoch: 15.04243803024292 s\n",
      "Epoch: 8/10 \tIteration: 4800 \tTrain Loss: 0.016 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4810 \tTrain Loss: 0.047 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 4820 \tTrain Loss: 0.028 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4830 \tTrain Loss: 0.026 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4840 \tTrain Loss: 0.023 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4850 \tTrain Loss: 0.028 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4860 \tTrain Loss: 0.016 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4870 \tTrain Loss: 0.022 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4880 \tTrain Loss: 0.061 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 4890 \tTrain Loss: 0.027 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4900 \tTrain Loss: 0.080 \tTrain Accuracy: 94.00\n",
      "Epoch: 8/10 \tIteration: 4910 \tTrain Loss: 0.021 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 4920 \tTrain Loss: 0.013 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4930 \tTrain Loss: 0.016 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4940 \tTrain Loss: 0.031 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4950 \tTrain Loss: 0.081 \tTrain Accuracy: 96.00\n",
      "Epoch: 8/10 \tIteration: 4960 \tTrain Loss: 0.132 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 4970 \tTrain Loss: 0.013 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4980 \tTrain Loss: 0.021 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 4990 \tTrain Loss: 0.051 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5000 \tTrain Loss: 0.020 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5010 \tTrain Loss: 0.023 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5020 \tTrain Loss: 0.049 \tTrain Accuracy: 96.00\n",
      "Epoch: 8/10 \tIteration: 5030 \tTrain Loss: 0.073 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5040 \tTrain Loss: 0.007 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5050 \tTrain Loss: 0.017 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5060 \tTrain Loss: 0.056 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5070 \tTrain Loss: 0.034 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5080 \tTrain Loss: 0.048 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5090 \tTrain Loss: 0.011 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5100 \tTrain Loss: 0.011 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5110 \tTrain Loss: 0.001 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5120 \tTrain Loss: 0.029 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5130 \tTrain Loss: 0.025 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5140 \tTrain Loss: 0.023 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5150 \tTrain Loss: 0.082 \tTrain Accuracy: 96.00\n",
      "Epoch: 8/10 \tIteration: 5160 \tTrain Loss: 0.023 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5170 \tTrain Loss: 0.028 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5180 \tTrain Loss: 0.025 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5190 \tTrain Loss: 0.131 \tTrain Accuracy: 92.00\n",
      "Epoch: 8/10 \tIteration: 5200 \tTrain Loss: 0.058 \tTrain Accuracy: 96.00\n",
      "Epoch: 8/10 \tIteration: 5210 \tTrain Loss: 0.055 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5220 \tTrain Loss: 0.013 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5230 \tTrain Loss: 0.013 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5240 \tTrain Loss: 0.064 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5250 \tTrain Loss: 0.028 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5260 \tTrain Loss: 0.004 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5270 \tTrain Loss: 0.025 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5280 \tTrain Loss: 0.024 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5290 \tTrain Loss: 0.037 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5300 \tTrain Loss: 0.003 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5310 \tTrain Loss: 0.031 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5320 \tTrain Loss: 0.075 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5330 \tTrain Loss: 0.014 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5340 \tTrain Loss: 0.095 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5350 \tTrain Loss: 0.012 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5360 \tTrain Loss: 0.014 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5370 \tTrain Loss: 0.029 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 5380 \tTrain Loss: 0.007 \tTrain Accuracy: 100.00\n",
      "Epoch: 8/10 \tIteration: 5390 \tTrain Loss: 0.009 \tTrain Accuracy: 100.00\n",
      "Val Loss: 0.861 \tVal Acc: 85.120\n",
      "Time to train epoch: 15.0572669506073 s\n",
      "Epoch: 9/10 \tIteration: 5400 \tTrain Loss: 0.018 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5410 \tTrain Loss: 0.053 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5420 \tTrain Loss: 0.015 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5430 \tTrain Loss: 0.034 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5440 \tTrain Loss: 0.066 \tTrain Accuracy: 96.00\n",
      "Epoch: 9/10 \tIteration: 5450 \tTrain Loss: 0.035 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5460 \tTrain Loss: 0.002 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5470 \tTrain Loss: 0.129 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5480 \tTrain Loss: 0.031 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5490 \tTrain Loss: 0.039 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5500 \tTrain Loss: 0.055 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5510 \tTrain Loss: 0.002 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5520 \tTrain Loss: 0.034 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5530 \tTrain Loss: 0.003 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5540 \tTrain Loss: 0.004 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5550 \tTrain Loss: 0.025 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5560 \tTrain Loss: 0.007 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5570 \tTrain Loss: 0.004 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5580 \tTrain Loss: 0.038 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5590 \tTrain Loss: 0.009 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5600 \tTrain Loss: 0.008 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5610 \tTrain Loss: 0.031 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5620 \tTrain Loss: 0.032 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5630 \tTrain Loss: 0.013 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5640 \tTrain Loss: 0.007 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5650 \tTrain Loss: 0.042 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5660 \tTrain Loss: 0.055 \tTrain Accuracy: 96.00\n",
      "Epoch: 9/10 \tIteration: 5670 \tTrain Loss: 0.038 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5680 \tTrain Loss: 0.132 \tTrain Accuracy: 98.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10 \tIteration: 5690 \tTrain Loss: 0.053 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5700 \tTrain Loss: 0.015 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5710 \tTrain Loss: 0.001 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5720 \tTrain Loss: 0.010 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5730 \tTrain Loss: 0.006 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5740 \tTrain Loss: 0.010 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5750 \tTrain Loss: 0.011 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5760 \tTrain Loss: 0.020 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5770 \tTrain Loss: 0.008 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5780 \tTrain Loss: 0.008 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5790 \tTrain Loss: 0.005 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5800 \tTrain Loss: 0.010 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5810 \tTrain Loss: 0.034 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5820 \tTrain Loss: 0.016 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5830 \tTrain Loss: 0.011 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5840 \tTrain Loss: 0.004 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5850 \tTrain Loss: 0.085 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5860 \tTrain Loss: 0.010 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5870 \tTrain Loss: 0.027 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5880 \tTrain Loss: 0.002 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5890 \tTrain Loss: 0.015 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5900 \tTrain Loss: 0.011 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5910 \tTrain Loss: 0.028 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5920 \tTrain Loss: 0.041 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5930 \tTrain Loss: 0.022 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5940 \tTrain Loss: 0.014 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5950 \tTrain Loss: 0.016 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5960 \tTrain Loss: 0.020 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 5970 \tTrain Loss: 0.043 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5980 \tTrain Loss: 0.035 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 5990 \tTrain Loss: 0.052 \tTrain Accuracy: 96.00\n",
      "Val Loss: 1.023 \tVal Acc: 85.530\n",
      "Time to train epoch: 15.052777767181396 s\n",
      "Test Loss: 0.938 \tTest Acc: 85.340\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs = 10\n",
    "n_filters = 256\n",
    "kernel_size = 2\n",
    "layers= 2\n",
    "learning_rate = 0.001\n",
    "print(len(word_dict))\n",
    "vocab_size = 5000\n",
    "print(vocab_size)\n",
    "embed_dims = 32\n",
    "seq_len = 500\n",
    "dropout = 0.3\n",
    "batch_size=50\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = QRNN(vocab_size, embed_dims, n_filters, kernel_size, batch_size, seq_len, layers, device, dropout).to(device)\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "counter = 0\n",
    "QRNN_acc = []\n",
    "QRNN_valacc = []\n",
    "\n",
    "model.train()\n",
    "for e in range(epochs):\n",
    "    start_time = time.time()\n",
    "    for inputs, labels in train_dl:\n",
    "    \n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        model.zero_grad()\n",
    "        logits, accuracy = model(inputs,labels)\n",
    "        loss = criterion(logits,labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        if counter%10==0:\n",
    "            print(\"Epoch: {}/{}\".format(e,epochs),\n",
    "                         \"\\tIteration: {}\".format(counter),\n",
    "                         \"\\tTrain Loss: {:.3f}\".format(loss.item()),\n",
    "                         \"\\tTrain Accuracy: {:.2f}\".format(accuracy.item()*100/batch_size))\n",
    "            QRNN_acc.append(accuracy.item()*100/batch_size)\n",
    "        if counter%599==0:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    val_acc = []\n",
    "                    val_loss = []\n",
    "                    for inputs, labels in val_dl:\n",
    "                        inputs_val, labels_val = inputs.cuda(), labels.cuda()\n",
    "                        logits_val,accuracy_val = model(inputs_val,labels_val)\n",
    "                        loss_val = criterion(logits_val,labels_val.float())\n",
    "                        val_acc.append(accuracy_val.item()*100/batch_size)\n",
    "                        val_loss.append(loss_val.item())\n",
    "                    print(\"Val Loss: {:.3f}\".format(np.mean(val_loss)), \"\\tVal Acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "                    QRNN_valacc.append(np.mean(val_acc))\n",
    "                    model.train()\n",
    "        counter += 1\n",
    "    print(\"Time to train epoch: {0} s\".format(time.time()-start_time)) \n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_acc = []\n",
    "    test_loss = []\n",
    "    for inputs, labels in test_dl:\n",
    "        input_test, labels_test = inputs.cuda(), labels.cuda()\n",
    "        logits_test, accuracy_test = model(input_test, labels_test)\n",
    "        loss_test = criterion(logits_test, labels_test.float())\n",
    "        test_acc.append(accuracy_test.item()*100/batch_size)\n",
    "        test_loss.append(loss_test.item())\n",
    "    print(\"Test Loss: {:.3f}\".format(np.mean(test_loss)), \"\\tTest Acc: {:.3f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env2_gpu",
   "language": "python",
   "name": "my_env2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
