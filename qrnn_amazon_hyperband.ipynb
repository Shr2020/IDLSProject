{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qrnn-amazon-hyperband.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import sys\n",
        "import os\n",
        "prefix = '/content/gdrive/My Drive/'\n",
        "# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n",
        "customized_path_to_your_homework = 'IDLSProject-main'\n",
        "sys_path = os.path.join(prefix, customized_path_to_your_homework)\n",
        "sys.path.append(sys_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oajq_A9Wb1mQ",
        "outputId": "8c24f483-4250-4494-e1d5-cdb15a6f2624"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "%cd '/content/gdrive/My Drive/IDLSProject-main-2'"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/IDLSProject-main-2\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O36-vTu0b4Vq",
        "outputId": "7b53aeb1-5740-4f2b-9fb6-bf14a287e5b3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "data_dir = './data/pytorch'\n",
        "with open(os.path.join(data_dir, 'word_dict_amazon.pkl'), \"rb\") as f:\n",
        "    word_dict = pickle.load(f)\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "yBS_Cwn9bQOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "train = pd.read_csv(os.path.join(data_dir, 'train_amazon.csv'), header=None, names=None)\n",
        "test_sample = pd.read_csv(os.path.join(data_dir, 'test_amazon.csv'), header=None, names=None)\n",
        "print(train.shape, test_sample.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(83000, 502) (21975, 502)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMsjwRQ9KBwk",
        "outputId": "0d4be2ab-e70c-470e-ed44-d28eb9d2e93b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test, val = train_test_split(test_sample, test_size=0.5)\n",
        "train.shape, test.shape, val.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((83000, 502), (10987, 502), (10988, 502))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn509rQ2KFBX",
        "outputId": "6c263b5f-be07-41f2-8695-ecc144755b80"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "#drop rows\n",
        "test.drop(test.tail(37).index,inplace = True)\n",
        "val.drop(val.tail(38).index,inplace = True)\n",
        "test.shape, val.shape\n",
        "\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "train_y = torch.from_numpy(train[[0]].values).float()\n",
        "train_X = torch.from_numpy(train.drop([0, 1], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
        "# Build the dataloader\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
        "\n",
        "######val data\n",
        "# Turn the input pandas dataframe into tensors\n",
        "val_y = torch.from_numpy(val[[0]].values).float()\n",
        "val_X = torch.from_numpy(val.drop([0, 1], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "val_ds = torch.utils.data.TensorDataset(val_X, val_y)\n",
        "# Build the dataloader\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=50)\n",
        "\n",
        "\n",
        "#### Test data\n",
        "# Turn the input pandas dataframe into tensors\n",
        "test_y = torch.from_numpy(test[[0]].values).float()\n",
        "test_X = torch.from_numpy(test.drop([0, 1], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "test_ds = torch.utils.data.TensorDataset(test_X, test_y)\n",
        "# Build the dataloader\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=50)\n",
        "print(test_y.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10950, 1])\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkVwncNSKHsE",
        "outputId": "6fd09a5f-a6af-4ec3-b37e-1826186b0e6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class QRNNLayer(nn.Module):\n",
        "    def __init__(self,batch_size,input_size,n_filters,kernel_size,embed_size,device,dropout):\n",
        "        super(QRNNLayer,self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.input_size = input_size\n",
        "        self.n_filters = n_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.embed_size = embed_size\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.device = device\n",
        "        self.conv1 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
        "        self.conv2 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
        "        self.conv3 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
        "    \n",
        "    def forward(self,masked_input, h, c):\n",
        "        Z,F,O = self.masked_conv(masked_input)\n",
        "        h, c = self.pool(c,Z,F,O)\n",
        "        masked_input = h\n",
        "        return masked_input,h,c\n",
        "    \n",
        "    def masked_conv(self,x):\n",
        "        pad = torch.zeros([self.batch_size,1,self.input_size],device=self.device)\n",
        "        x = torch.cat([pad,x],1).permute(0,2,1)\n",
        "        Z = torch.tanh((self.conv1(x)))\n",
        "        F = torch.sigmoid((self.conv2(x)))\n",
        "        O = torch.sigmoid((self.conv3(x)))\n",
        "        one_mask = torch.ones_like(F,device=self.device) - F\n",
        "        F = 1 - self.dropout(one_mask)\n",
        "        return Z.permute(0,2,1), F.permute(0,2,1), O.permute(0,2,1)\n",
        "    \n",
        "    def pool(self, prev_c,Z,F,O):\n",
        "        c = torch.mul(F,prev_c) + torch.mul(1-F,Z)\n",
        "        h = torch.mul(O,c)\n",
        "        return h,c\n",
        "\n",
        "class QRNN(nn.Module):\n",
        "    def __init__(self,trial,vocab_size,embed_size,n_filters,kernel_size,batch_size,seq_len,layers,device,dropout):\n",
        "        super(QRNN,self).__init__()\n",
        "        dropout = trial.suggest_uniform(\"dropout\",0.1, 0.6)\n",
        "        self.num_layer = trial.suggest_int(\"num_layer\",1,4)\n",
        "        self.embed_size = trial.suggest_int(\"embed_size\",16,128)\n",
        "        self.n_filters = trial.suggest_int(\"n_filters\",50,200)\n",
        "        # self.kernel_size = trial.suggest_int(\"kernel_size\",2,5)\n",
        "        # self.embed_size = embed_size\n",
        "        # self.n_filters = n_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_len = seq_len\n",
        "        # self.num_layer = layers\n",
        "        self.device = device\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, self.embed_size)\n",
        "        self.dense = torch.nn.Linear(self.seq_len*self.n_filters,1)\n",
        "        self.QRNN_layers = torch.nn.ModuleList([QRNNLayer(self.batch_size,self.embed_size if l==0 else self.n_filters,\n",
        "                                                         self.n_filters,self.kernel_size,self.embed_size,self.device,\n",
        "                                                         dropout,) for l in range(self.num_layer)])\n",
        "        \n",
        "        \n",
        "    def forward(self, x, target):\n",
        "        x = self.embedding(x)\n",
        "        h = torch.zeros([self.batch_size,self.seq_len,self.n_filters],device=self.device)\n",
        "        c = torch.zeros_like(h,device=self.device)\n",
        "        \n",
        "        masked_input = x\n",
        "        for l,layer in enumerate(self.QRNN_layers):\n",
        "            masked_input,h,c = layer(masked_input,h,c)\n",
        "        dense_input = h.reshape([self.batch_size,-1])\n",
        "        logits = self.dense(dense_input)\n",
        "        prediction = torch.sigmoid(logits)\n",
        "        target = target.view([-1,1])\n",
        "        correct_pred = torch.eq(torch.round(prediction).type(target.type()),target)\n",
        "        accuracy = torch.sum(correct_pred)\n",
        "        return prediction, accuracy"
      ],
      "metadata": {
        "id": "jDvo2PsZtLpB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "data_dir = './qrnn-amazon-hyperband-trails/' # The folder we will use for storing data\n",
        "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "filename = \"\"\n",
        "def write_to_csv(trail_num, epochs, train_loss, train_acc, val_loss, val_acc, time_train):\n",
        "    global filename\n",
        "    filename = \"./qrnn-amazon-hyperband-trails/\"+str(trail_num)+\".csv\"\n",
        "    epoch = [i for i in range(epochs)]\n",
        "    df_metrics = pd.DataFrame(list(zip(epoch, train_loss, train_acc, val_loss, val_acc, time_train)), columns =['Epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'train_time'])\n",
        "    df_metrics.to_csv(filename, index=False)    \n",
        "    \n",
        "def append_to_csv(epochs, accuracy):\n",
        "    acc = [accuracy for i in range(epochs)]\n",
        "    df_csv = pd.read_csv(filename)\n",
        "    df_csv['Test_Accuracy']  = acc\n",
        "    df_csv.to_csv(filename, index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mT8XRhwXKPVg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "!pip install optuna"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.1)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.9.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxD0Pj_xrTLF",
        "outputId": "05aae491-cf52-4fc9-8d91-4f609748d729"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "epochs = 10\n",
        "n_filters = 64\n",
        "kernel_size = 2\n",
        "layers= 2\n",
        "learning_rate = 0.001\n",
        "print(len(word_dict))\n",
        "vocab_size = 5000\n",
        "print(vocab_size)\n",
        "embed_dims = 32\n",
        "seq_len = 500\n",
        "dropout = 0.3\n",
        "batch_size=50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAuhnuf8xFNR",
        "outputId": "b0d0703f-f5f8-4f48-dbfa-6fb33c0ed5bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9998\n",
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "import time\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.optim as optim\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Define an objective function to be minimized.\n",
        "def objective(trial):\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "  #epochs = trial.suggest_int(\"epochs\",5,15)\n",
        "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-0)\n",
        "  #momentum = trial.suggest_uniform(\"momentum\", 0.0, 1.0)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = QRNN(trial,vocab_size, embed_dims, n_filters, kernel_size, batch_size, seq_len, layers, device, dropout).to(device)\n",
        "  trial.set_user_attr(key=\"best_model\", value=model)\n",
        "  optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "  loss_fn = torch.nn.BCELoss()\n",
        "  counter = 0\n",
        "  QRNN_acc = []\n",
        "  QRNN_valacc = []\n",
        "  train_loss_epoch = []\n",
        "  train_acc_epoch = []\n",
        "  val_loss_epoch = []\n",
        "  val_acc_epoch = []\n",
        "  time_epoch = []\n",
        "  final_val_acc = 0\n",
        "  model.train()\n",
        "  for e in range(epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    for inputs, labels in train_dl:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        model.zero_grad()\n",
        "        logits, accuracy = model(inputs,labels)\n",
        "        loss = criterion(logits,labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.item())\n",
        "        train_acc.append(accuracy.item()*100/batch_size)\n",
        "        if counter%100==0:\n",
        "            print(\"Epoch: {}/{}\".format(e,epochs),\n",
        "                         \"\\tIteration: {}\".format(counter),\n",
        "                         \"\\tTrain Loss: {:.3f}\".format(loss.item()),\n",
        "                         \"\\tTrain Accuracy: {:.2f}\".format(accuracy.item()*100/batch_size))\n",
        "            QRNN_acc.append(accuracy.item()*100/batch_size)\n",
        "        counter += 1\n",
        "    train_loss_epoch.append(np.round(np.mean(train_loss), 3))\n",
        "    train_acc_epoch.append(np.round(np.mean(train_acc), 3))\n",
        "    print(\"\\tTrain Loss: {:.3f}\".format(np.mean(train_loss)), \"\\tTrain Acc: {:.3f}\".format(np.mean(train_acc)))\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_acc = []\n",
        "        val_loss = []\n",
        "        for inputs, labels in val_dl:\n",
        "            inputs_val, labels_val = inputs.cuda(), labels.cuda()\n",
        "            logits_val,accuracy_val = model(inputs_val,labels_val)\n",
        "            loss_val = criterion(logits_val,labels_val.float())\n",
        "            val_acc.append(accuracy_val.item()*100/batch_size)\n",
        "            val_loss.append(loss_val.item())\n",
        "        print(\"Val Loss: {:.3f}\".format(np.mean(val_loss)), \"\\tVal Acc: {:.3f}\".format(np.mean(val_acc)))\n",
        "        val_loss_epoch.append(np.round(np.mean(val_loss), 3))\n",
        "        val_acc_epoch.append(np.round(np.mean(val_acc), 3))\n",
        "        QRNN_valacc.append(np.mean(val_acc))\n",
        "        model.train()\n",
        "        final_val_acc = np.mean(val_acc)\n",
        "    end_time = time.time()-start_time\n",
        "    print(\"Time to train epoch: {0} s\".format(end_time))\n",
        "    time_epoch.append(np.round(end_time, 3))\n",
        "  write_to_csv(epochs, train_loss_epoch, train_acc_epoch, val_loss_epoch, val_acc_epoch, time_epoch)\n",
        "  return final_val_acc\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "OasEM6YFKTBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "def callback(study, trial):\n",
        "    if study.best_trial.number == trial.number:\n",
        "        study.set_user_attr(key=\"best_model\", value=trial.user_attrs[\"best_model\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "yM6NlQlNqA4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "study = optuna.create_study(direction=\"maximize\",pruner=optuna.pruners.HyperbandPruner(\n",
        "        min_resource=1, max_resource=epochs, reduction_factor=3\n",
        "    ),)\n",
        "study.optimize(objective, n_trials=5,callbacks=[callback])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "best_model=study.user_attrs[\"best_model\"]\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\"    {}: {}\".format(key, value))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-05-14 18:38:09,841]\u001b[0m A new study created in memory with name: no-name-0441cda1-e091-4fe8-9bc8-333d01a29d1a\u001b[0m\n",
            "\u001b[33m[W 2022-05-14 18:38:17,730]\u001b[0m Trial 0 failed because of the following error: RuntimeError('CUDA error: device-side assert triggered\\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.')\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-11-bf2c44b7c861>\", line 36, in objective\n",
            "    logits, accuracy = model(inputs,labels)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"<ipython-input-7-9c45b7a661ad>\", line 70, in forward\n",
            "    masked_input,h,c = layer(masked_input,h,c)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"<ipython-input-7-9c45b7a661ad>\", line 21, in forward\n",
            "    Z,F,O = self.masked_conv(masked_input)\n",
            "  File \"<ipython-input-7-9c45b7a661ad>\", line 29, in masked_conv\n",
            "    Z = torch.tanh((self.conv1(x)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 302, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 299, in _conv_forward\n",
            "    self.padding, self.dilation, self.groups)\n",
            "RuntimeError: CUDA error: device-side assert triggered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f9c34e2fdf74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmin_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     ),)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Study statistics: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-bf2c44b7c861>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-9c45b7a661ad>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mmasked_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQRNN_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mmasked_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mdense_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-9c45b7a661ad>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, masked_input, h, c)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasked_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmasked_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-9c45b7a661ad>\u001b[0m in \u001b[0;36mmasked_conv\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    297\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    298\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 299\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "id": "QQ7svJFbqH5J",
        "outputId": "0e20e42d-2d9b-4879-99d8-20652a169feb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './qrnn-amazon-hyperband/' # The folder we will use for storing data\n",
        "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
        "    os.makedirs(data_dir)\n",
        "    \n",
        "torch.save(best_model.state_dict(),\"./qrnn-amazon-hyperband/qrnn-imdb-hyperband.pth\")"
      ],
      "metadata": {
        "id": "Njic3VLTwSPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def test(model, test_dl, epochs):\n",
        "    with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_acc = []\n",
        "    test_loss = []\n",
        "    for inputs, labels in test_dl:\n",
        "        input_test, labels_test = inputs.cuda(), labels.cuda()\n",
        "        logits_test, accuracy_test = model(input_test, labels_test)\n",
        "        loss_test = criterion(logits_test, labels_test.float())\n",
        "        test_acc.append(accuracy_test.item()*100/batch_size)\n",
        "        test_loss.append(loss_test.item())\n",
        "    print(\"Test Loss: {:.3f}\".format(np.mean(test_loss)), \"\\tTest Acc: {:.3f}\".format(np.mean(test_acc)))"
      ],
      "outputs": [],
      "metadata": {
        "id": "2D2JfLBeKjQ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test(best_model, test_dl, epochs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "vR_FTuLSby1Y"
      }
    }
  ]
}