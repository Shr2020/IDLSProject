{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If Files present start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "data_dir = './data/pytorch'\n",
    "with open(os.path.join(data_dir, 'word_dict_amazon.pkl'), \"rb\") as f:\n",
    "    word_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83000, 502) (21975, 502)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "train = pd.read_csv(os.path.join(data_dir, 'train_amazon.csv'), header=None, names=None)\n",
    "test_sample = pd.read_csv(os.path.join(data_dir, 'test_amazon.csv'), header=None, names=None)\n",
    "print(train.shape, test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83000, 502), (10987, 502), (10988, 502))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test, val = train_test_split(test_sample, test_size=0.5)\n",
    "train.shape, test.shape, val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10950, 502), (10950, 502))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop rows\n",
    "test.drop(test.tail(37).index,inplace = True)\n",
    "val.drop(val.tail(38).index,inplace = True)\n",
    "test.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10950, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_y = torch.from_numpy(train[[0]].values).float()\n",
    "train_X = torch.from_numpy(train.drop([0, 1], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
    "# Build the dataloader\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
    "\n",
    "######val data\n",
    "# Turn the input pandas dataframe into tensors\n",
    "val_y = torch.from_numpy(val[[0]].values).float()\n",
    "val_X = torch.from_numpy(val.drop([0, 1], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "val_ds = torch.utils.data.TensorDataset(val_X, val_y)\n",
    "# Build the dataloader\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=50)\n",
    "\n",
    "\n",
    "#### Test data\n",
    "# Turn the input pandas dataframe into tensors\n",
    "test_y = torch.from_numpy(test[[0]].values).float()\n",
    "test_X = torch.from_numpy(test.drop([0, 1], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "test_ds = torch.utils.data.TensorDataset(test_X, test_y)\n",
    "# Build the dataloader\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=50)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class QRNNLayer(nn.Module):\n",
    "    def __init__(self,batch_size,input_size,n_filters,kernel_size,embed_size,device,dropout):\n",
    "        super(QRNNLayer,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.embed_size = embed_size\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.device = device\n",
    "        self.conv1 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
    "        self.conv2 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
    "        self.conv3 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
    "    \n",
    "    def forward(self,masked_input, h, c):\n",
    "        Z,F,O = self.masked_conv(masked_input)\n",
    "        h, c = self.pool(c,Z,F,O)\n",
    "        masked_input = h\n",
    "        return masked_input,h,c\n",
    "    \n",
    "    def masked_conv(self,x):\n",
    "        pad = torch.zeros([self.batch_size,1,self.input_size],device=self.device)\n",
    "        x = torch.cat([pad,x],1).permute(0,2,1)\n",
    "        Z = torch.tanh((self.conv1(x)))\n",
    "        F = torch.sigmoid((self.conv2(x)))\n",
    "        O = torch.sigmoid((self.conv3(x)))\n",
    "        one_mask = torch.ones_like(F,device=self.device) - F\n",
    "        F = 1 - self.dropout(one_mask)\n",
    "        return Z.permute(0,2,1), F.permute(0,2,1), O.permute(0,2,1)\n",
    "    \n",
    "    def pool(self, prev_c,Z,F,O):\n",
    "        c = torch.mul(F,prev_c) + torch.mul(1-F,Z)\n",
    "        h = torch.mul(O,c)\n",
    "        return h,c\n",
    "\n",
    "class QRNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,n_filters,kernel_size,batch_size,seq_len,layers,device,dropout):\n",
    "        super(QRNN,self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.num_layer = layers\n",
    "        self.device = device\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_size)\n",
    "        self.dense = torch.nn.Linear(self.seq_len*self.n_filters,1)\n",
    "        self.QRNN_layers = torch.nn.ModuleList([QRNNLayer(self.batch_size,embed_size if l==0 else n_filters,\n",
    "                                                         self.n_filters,self.kernel_size,self.embed_size,self.device,\n",
    "                                                         dropout,) for l in range(self.num_layer)])\n",
    "        \n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        x = self.embedding(x)\n",
    "        h = torch.zeros([self.batch_size,self.seq_len,self.n_filters],device=self.device)\n",
    "        c = torch.zeros_like(h,device=self.device)\n",
    "        \n",
    "        masked_input = x\n",
    "        for l,layer in enumerate(self.QRNN_layers):\n",
    "            masked_input,h,c = layer(masked_input,h,c)\n",
    "        dense_input = h.reshape([self.batch_size,-1])\n",
    "        logits = self.dense(dense_input)\n",
    "        prediction = torch.sigmoid(logits)\n",
    "        target = target.view([-1,1])\n",
    "        correct_pred = torch.eq(torch.round(prediction).type(target.type()),target)\n",
    "        accuracy = torch.sum(correct_pred)\n",
    "        return prediction, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file.\n",
    "filename = \"QRNN_amazon.csv\"\n",
    "def write_to_csv(epochs, train_loss, val_loss, val_acc, end):\n",
    "    epoch = [i for i in range(10)]\n",
    "    df_metrics = pd.DataFrame(list(zip(epoch, train_loss, val_loss, val_acc, end)), columns =['Epoch', 'train_loss', 'val_loss', 'val_acc', 'train_time'])\n",
    "    df_metrics.to_csv(filename)\n",
    "    \n",
    "def append_to_csv(epochs, accuracy):\n",
    "    acc = [accuracy for i in range(epochs)]\n",
    "    df_csv = pd.read_csv(file_name)\n",
    "    df_csv['Test_Accuracy']  = accuracy\n",
    "    df_metrics.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998\n",
      "10000\n",
      "Epoch: 0/10 \tIteration: 0 \tTrain Loss: 0.683 \tTrain Accuracy: 66.00\n",
      "Epoch: 0/10 \tIteration: 100 \tTrain Loss: 0.571 \tTrain Accuracy: 74.00\n",
      "Epoch: 0/10 \tIteration: 200 \tTrain Loss: 0.441 \tTrain Accuracy: 80.00\n",
      "Epoch: 0/10 \tIteration: 300 \tTrain Loss: 0.357 \tTrain Accuracy: 78.00\n",
      "Epoch: 0/10 \tIteration: 400 \tTrain Loss: 0.333 \tTrain Accuracy: 86.00\n",
      "Epoch: 0/10 \tIteration: 500 \tTrain Loss: 0.273 \tTrain Accuracy: 88.00\n",
      "Epoch: 0/10 \tIteration: 600 \tTrain Loss: 0.268 \tTrain Accuracy: 90.00\n",
      "Epoch: 0/10 \tIteration: 700 \tTrain Loss: 0.483 \tTrain Accuracy: 80.00\n",
      "Epoch: 0/10 \tIteration: 800 \tTrain Loss: 0.304 \tTrain Accuracy: 82.00\n",
      "Epoch: 0/10 \tIteration: 900 \tTrain Loss: 0.202 \tTrain Accuracy: 88.00\n",
      "Epoch: 0/10 \tIteration: 1000 \tTrain Loss: 0.311 \tTrain Accuracy: 88.00\n",
      "Epoch: 0/10 \tIteration: 1100 \tTrain Loss: 0.304 \tTrain Accuracy: 82.00\n",
      "Epoch: 0/10 \tIteration: 1200 \tTrain Loss: 0.220 \tTrain Accuracy: 96.00\n",
      "Epoch: 0/10 \tIteration: 1300 \tTrain Loss: 0.185 \tTrain Accuracy: 94.00\n",
      "Epoch: 0/10 \tIteration: 1400 \tTrain Loss: 0.288 \tTrain Accuracy: 80.00\n",
      "Epoch: 0/10 \tIteration: 1500 \tTrain Loss: 0.279 \tTrain Accuracy: 88.00\n",
      "Epoch: 0/10 \tIteration: 1600 \tTrain Loss: 0.286 \tTrain Accuracy: 94.00\n",
      "Epoch: 0/10 \tTrain Loss: 0.372 \tTrain Acc: 83.682\n",
      "Val Loss: 0.301 \tVal Acc: 87.151\n",
      "Time to train epoch: 25.109562635421753 s\n",
      "Epoch: 1/10 \tIteration: 1700 \tTrain Loss: 0.144 \tTrain Accuracy: 96.00\n",
      "Epoch: 1/10 \tIteration: 1800 \tTrain Loss: 0.290 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 1900 \tTrain Loss: 0.353 \tTrain Accuracy: 84.00\n",
      "Epoch: 1/10 \tIteration: 2000 \tTrain Loss: 0.274 \tTrain Accuracy: 90.00\n",
      "Epoch: 1/10 \tIteration: 2100 \tTrain Loss: 0.232 \tTrain Accuracy: 90.00\n",
      "Epoch: 1/10 \tIteration: 2200 \tTrain Loss: 0.330 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 2300 \tTrain Loss: 0.221 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 2400 \tTrain Loss: 0.272 \tTrain Accuracy: 84.00\n",
      "Epoch: 1/10 \tIteration: 2500 \tTrain Loss: 0.509 \tTrain Accuracy: 80.00\n",
      "Epoch: 1/10 \tIteration: 2600 \tTrain Loss: 0.251 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 2700 \tTrain Loss: 0.352 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 2800 \tTrain Loss: 0.313 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 2900 \tTrain Loss: 0.346 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 3000 \tTrain Loss: 0.210 \tTrain Accuracy: 88.00\n",
      "Epoch: 1/10 \tIteration: 3100 \tTrain Loss: 0.138 \tTrain Accuracy: 94.00\n",
      "Epoch: 1/10 \tIteration: 3200 \tTrain Loss: 0.403 \tTrain Accuracy: 84.00\n",
      "Epoch: 1/10 \tIteration: 3300 \tTrain Loss: 0.260 \tTrain Accuracy: 92.00\n",
      "Epoch: 1/10 \tTrain Loss: 0.277 \tTrain Acc: 88.460\n",
      "Val Loss: 0.285 \tVal Acc: 88.064\n",
      "Time to train epoch: 24.104764699935913 s\n",
      "Epoch: 2/10 \tIteration: 3400 \tTrain Loss: 0.253 \tTrain Accuracy: 88.00\n",
      "Epoch: 2/10 \tIteration: 3500 \tTrain Loss: 0.227 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 3600 \tTrain Loss: 0.143 \tTrain Accuracy: 98.00\n",
      "Epoch: 2/10 \tIteration: 3700 \tTrain Loss: 0.171 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 3800 \tTrain Loss: 0.195 \tTrain Accuracy: 92.00\n",
      "Epoch: 2/10 \tIteration: 3900 \tTrain Loss: 0.342 \tTrain Accuracy: 84.00\n",
      "Epoch: 2/10 \tIteration: 4000 \tTrain Loss: 0.207 \tTrain Accuracy: 90.00\n",
      "Epoch: 2/10 \tIteration: 4100 \tTrain Loss: 0.224 \tTrain Accuracy: 90.00\n",
      "Epoch: 2/10 \tIteration: 4200 \tTrain Loss: 0.294 \tTrain Accuracy: 84.00\n",
      "Epoch: 2/10 \tIteration: 4300 \tTrain Loss: 0.128 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 4400 \tTrain Loss: 0.202 \tTrain Accuracy: 94.00\n",
      "Epoch: 2/10 \tIteration: 4500 \tTrain Loss: 0.230 \tTrain Accuracy: 90.00\n",
      "Epoch: 2/10 \tIteration: 4600 \tTrain Loss: 0.236 \tTrain Accuracy: 90.00\n",
      "Epoch: 2/10 \tIteration: 4700 \tTrain Loss: 0.277 \tTrain Accuracy: 86.00\n",
      "Epoch: 2/10 \tIteration: 4800 \tTrain Loss: 0.441 \tTrain Accuracy: 80.00\n",
      "Epoch: 2/10 \tIteration: 4900 \tTrain Loss: 0.284 \tTrain Accuracy: 88.00\n",
      "Epoch: 2/10 \tTrain Loss: 0.242 \tTrain Acc: 89.995\n",
      "Val Loss: 0.286 \tVal Acc: 88.447\n",
      "Time to train epoch: 24.03311276435852 s\n",
      "Epoch: 3/10 \tIteration: 5000 \tTrain Loss: 0.244 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 5100 \tTrain Loss: 0.349 \tTrain Accuracy: 84.00\n",
      "Epoch: 3/10 \tIteration: 5200 \tTrain Loss: 0.110 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 5300 \tTrain Loss: 0.226 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 5400 \tTrain Loss: 0.304 \tTrain Accuracy: 86.00\n",
      "Epoch: 3/10 \tIteration: 5500 \tTrain Loss: 0.143 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 5600 \tTrain Loss: 0.219 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tIteration: 5700 \tTrain Loss: 0.251 \tTrain Accuracy: 86.00\n",
      "Epoch: 3/10 \tIteration: 5800 \tTrain Loss: 0.190 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 5900 \tTrain Loss: 0.217 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tIteration: 6000 \tTrain Loss: 0.501 \tTrain Accuracy: 80.00\n",
      "Epoch: 3/10 \tIteration: 6100 \tTrain Loss: 0.184 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 6200 \tTrain Loss: 0.207 \tTrain Accuracy: 88.00\n",
      "Epoch: 3/10 \tIteration: 6300 \tTrain Loss: 0.151 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 6400 \tTrain Loss: 0.293 \tTrain Accuracy: 92.00\n",
      "Epoch: 3/10 \tIteration: 6500 \tTrain Loss: 0.167 \tTrain Accuracy: 94.00\n",
      "Epoch: 3/10 \tIteration: 6600 \tTrain Loss: 0.203 \tTrain Accuracy: 90.00\n",
      "Epoch: 3/10 \tTrain Loss: 0.214 \tTrain Acc: 91.205\n",
      "Val Loss: 0.299 \tVal Acc: 88.557\n",
      "Time to train epoch: 32.860424518585205 s\n",
      "Epoch: 4/10 \tIteration: 6700 \tTrain Loss: 0.099 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 6800 \tTrain Loss: 0.238 \tTrain Accuracy: 90.00\n",
      "Epoch: 4/10 \tIteration: 6900 \tTrain Loss: 0.095 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 7000 \tTrain Loss: 0.149 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 7100 \tTrain Loss: 0.319 \tTrain Accuracy: 88.00\n",
      "Epoch: 4/10 \tIteration: 7200 \tTrain Loss: 0.069 \tTrain Accuracy: 100.00\n",
      "Epoch: 4/10 \tIteration: 7300 \tTrain Loss: 0.253 \tTrain Accuracy: 86.00\n",
      "Epoch: 4/10 \tIteration: 7400 \tTrain Loss: 0.095 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 7500 \tTrain Loss: 0.287 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 7600 \tTrain Loss: 0.110 \tTrain Accuracy: 96.00\n",
      "Epoch: 4/10 \tIteration: 7700 \tTrain Loss: 0.237 \tTrain Accuracy: 90.00\n",
      "Epoch: 4/10 \tIteration: 7800 \tTrain Loss: 0.348 \tTrain Accuracy: 88.00\n",
      "Epoch: 4/10 \tIteration: 7900 \tTrain Loss: 0.187 \tTrain Accuracy: 92.00\n",
      "Epoch: 4/10 \tIteration: 8000 \tTrain Loss: 0.222 \tTrain Accuracy: 94.00\n",
      "Epoch: 4/10 \tIteration: 8100 \tTrain Loss: 0.100 \tTrain Accuracy: 98.00\n",
      "Epoch: 4/10 \tIteration: 8200 \tTrain Loss: 0.269 \tTrain Accuracy: 86.00\n",
      "Epoch: 4/10 \tTrain Loss: 0.192 \tTrain Acc: 92.198\n",
      "Val Loss: 0.310 \tVal Acc: 88.749\n",
      "Time to train epoch: 52.172213554382324 s\n",
      "Epoch: 5/10 \tIteration: 8300 \tTrain Loss: 0.208 \tTrain Accuracy: 90.00\n",
      "Epoch: 5/10 \tIteration: 8400 \tTrain Loss: 0.293 \tTrain Accuracy: 90.00\n",
      "Epoch: 5/10 \tIteration: 8500 \tTrain Loss: 0.232 \tTrain Accuracy: 88.00\n",
      "Epoch: 5/10 \tIteration: 8600 \tTrain Loss: 0.166 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 8700 \tTrain Loss: 0.120 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 8800 \tTrain Loss: 0.114 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 8900 \tTrain Loss: 0.152 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 9000 \tTrain Loss: 0.171 \tTrain Accuracy: 92.00\n",
      "Epoch: 5/10 \tIteration: 9100 \tTrain Loss: 0.137 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 9200 \tTrain Loss: 0.064 \tTrain Accuracy: 98.00\n",
      "Epoch: 5/10 \tIteration: 9300 \tTrain Loss: 0.336 \tTrain Accuracy: 88.00\n",
      "Epoch: 5/10 \tIteration: 9400 \tTrain Loss: 0.182 \tTrain Accuracy: 92.00\n",
      "Epoch: 5/10 \tIteration: 9500 \tTrain Loss: 0.214 \tTrain Accuracy: 92.00\n",
      "Epoch: 5/10 \tIteration: 9600 \tTrain Loss: 0.149 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tIteration: 9700 \tTrain Loss: 0.147 \tTrain Accuracy: 96.00\n",
      "Epoch: 5/10 \tIteration: 9800 \tTrain Loss: 0.219 \tTrain Accuracy: 92.00\n",
      "Epoch: 5/10 \tIteration: 9900 \tTrain Loss: 0.179 \tTrain Accuracy: 94.00\n",
      "Epoch: 5/10 \tTrain Loss: 0.171 \tTrain Acc: 93.123\n",
      "Val Loss: 0.332 \tVal Acc: 88.292\n",
      "Time to train epoch: 52.123711585998535 s\n",
      "Epoch: 6/10 \tIteration: 10000 \tTrain Loss: 0.057 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 10100 \tTrain Loss: 0.118 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 10200 \tTrain Loss: 0.218 \tTrain Accuracy: 88.00\n",
      "Epoch: 6/10 \tIteration: 10300 \tTrain Loss: 0.191 \tTrain Accuracy: 92.00\n",
      "Epoch: 6/10 \tIteration: 10400 \tTrain Loss: 0.106 \tTrain Accuracy: 94.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10 \tIteration: 10500 \tTrain Loss: 0.164 \tTrain Accuracy: 94.00\n",
      "Epoch: 6/10 \tIteration: 10600 \tTrain Loss: 0.157 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 10700 \tTrain Loss: 0.086 \tTrain Accuracy: 100.00\n",
      "Epoch: 6/10 \tIteration: 10800 \tTrain Loss: 0.204 \tTrain Accuracy: 92.00\n",
      "Epoch: 6/10 \tIteration: 10900 \tTrain Loss: 0.099 \tTrain Accuracy: 98.00\n",
      "Epoch: 6/10 \tIteration: 11000 \tTrain Loss: 0.204 \tTrain Accuracy: 90.00\n",
      "Epoch: 6/10 \tIteration: 11100 \tTrain Loss: 0.188 \tTrain Accuracy: 94.00\n",
      "Epoch: 6/10 \tIteration: 11200 \tTrain Loss: 0.219 \tTrain Accuracy: 92.00\n",
      "Epoch: 6/10 \tIteration: 11300 \tTrain Loss: 0.134 \tTrain Accuracy: 94.00\n",
      "Epoch: 6/10 \tIteration: 11400 \tTrain Loss: 0.135 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tIteration: 11500 \tTrain Loss: 0.235 \tTrain Accuracy: 88.00\n",
      "Epoch: 6/10 \tIteration: 11600 \tTrain Loss: 0.111 \tTrain Accuracy: 96.00\n",
      "Epoch: 6/10 \tTrain Loss: 0.154 \tTrain Acc: 93.817\n",
      "Val Loss: 0.363 \tVal Acc: 88.274\n",
      "Time to train epoch: 52.1463840007782 s\n",
      "Epoch: 7/10 \tIteration: 11700 \tTrain Loss: 0.141 \tTrain Accuracy: 92.00\n",
      "Epoch: 7/10 \tIteration: 11800 \tTrain Loss: 0.084 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 11900 \tTrain Loss: 0.049 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 12000 \tTrain Loss: 0.060 \tTrain Accuracy: 98.00\n",
      "Epoch: 7/10 \tIteration: 12100 \tTrain Loss: 0.153 \tTrain Accuracy: 92.00\n",
      "Epoch: 7/10 \tIteration: 12200 \tTrain Loss: 0.101 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 12300 \tTrain Loss: 0.071 \tTrain Accuracy: 100.00\n",
      "Epoch: 7/10 \tIteration: 12400 \tTrain Loss: 0.083 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 12500 \tTrain Loss: 0.221 \tTrain Accuracy: 92.00\n",
      "Epoch: 7/10 \tIteration: 12600 \tTrain Loss: 0.074 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 12700 \tTrain Loss: 0.107 \tTrain Accuracy: 94.00\n",
      "Epoch: 7/10 \tIteration: 12800 \tTrain Loss: 0.157 \tTrain Accuracy: 92.00\n",
      "Epoch: 7/10 \tIteration: 12900 \tTrain Loss: 0.105 \tTrain Accuracy: 96.00\n",
      "Epoch: 7/10 \tIteration: 13000 \tTrain Loss: 0.167 \tTrain Accuracy: 92.00\n",
      "Epoch: 7/10 \tIteration: 13100 \tTrain Loss: 0.271 \tTrain Accuracy: 86.00\n",
      "Epoch: 7/10 \tIteration: 13200 \tTrain Loss: 0.096 \tTrain Accuracy: 94.00\n",
      "Epoch: 7/10 \tTrain Loss: 0.137 \tTrain Acc: 94.557\n",
      "Val Loss: 0.384 \tVal Acc: 88.174\n",
      "Time to train epoch: 52.24835705757141 s\n",
      "Epoch: 8/10 \tIteration: 13300 \tTrain Loss: 0.136 \tTrain Accuracy: 94.00\n",
      "Epoch: 8/10 \tIteration: 13400 \tTrain Loss: 0.202 \tTrain Accuracy: 90.00\n",
      "Epoch: 8/10 \tIteration: 13500 \tTrain Loss: 0.104 \tTrain Accuracy: 96.00\n",
      "Epoch: 8/10 \tIteration: 13600 \tTrain Loss: 0.172 \tTrain Accuracy: 92.00\n",
      "Epoch: 8/10 \tIteration: 13700 \tTrain Loss: 0.180 \tTrain Accuracy: 92.00\n",
      "Epoch: 8/10 \tIteration: 13800 \tTrain Loss: 0.114 \tTrain Accuracy: 94.00\n",
      "Epoch: 8/10 \tIteration: 13900 \tTrain Loss: 0.164 \tTrain Accuracy: 94.00\n",
      "Epoch: 8/10 \tIteration: 14000 \tTrain Loss: 0.218 \tTrain Accuracy: 86.00\n",
      "Epoch: 8/10 \tIteration: 14100 \tTrain Loss: 0.159 \tTrain Accuracy: 96.00\n",
      "Epoch: 8/10 \tIteration: 14200 \tTrain Loss: 0.151 \tTrain Accuracy: 92.00\n",
      "Epoch: 8/10 \tIteration: 14300 \tTrain Loss: 0.254 \tTrain Accuracy: 86.00\n",
      "Epoch: 8/10 \tIteration: 14400 \tTrain Loss: 0.096 \tTrain Accuracy: 96.00\n",
      "Epoch: 8/10 \tIteration: 14500 \tTrain Loss: 0.097 \tTrain Accuracy: 94.00\n",
      "Epoch: 8/10 \tIteration: 14600 \tTrain Loss: 0.130 \tTrain Accuracy: 90.00\n",
      "Epoch: 8/10 \tIteration: 14700 \tTrain Loss: 0.223 \tTrain Accuracy: 96.00\n",
      "Epoch: 8/10 \tIteration: 14800 \tTrain Loss: 0.072 \tTrain Accuracy: 98.00\n",
      "Epoch: 8/10 \tIteration: 14900 \tTrain Loss: 0.091 \tTrain Accuracy: 96.00\n",
      "Epoch: 8/10 \tTrain Loss: 0.122 \tTrain Acc: 95.157\n",
      "Val Loss: 0.409 \tVal Acc: 88.265\n",
      "Time to train epoch: 52.21641564369202 s\n",
      "Epoch: 9/10 \tIteration: 15000 \tTrain Loss: 0.056 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 15100 \tTrain Loss: 0.119 \tTrain Accuracy: 94.00\n",
      "Epoch: 9/10 \tIteration: 15200 \tTrain Loss: 0.042 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 15300 \tTrain Loss: 0.192 \tTrain Accuracy: 92.00\n",
      "Epoch: 9/10 \tIteration: 15400 \tTrain Loss: 0.082 \tTrain Accuracy: 96.00\n",
      "Epoch: 9/10 \tIteration: 15500 \tTrain Loss: 0.100 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 15600 \tTrain Loss: 0.174 \tTrain Accuracy: 90.00\n",
      "Epoch: 9/10 \tIteration: 15700 \tTrain Loss: 0.036 \tTrain Accuracy: 100.00\n",
      "Epoch: 9/10 \tIteration: 15800 \tTrain Loss: 0.151 \tTrain Accuracy: 96.00\n",
      "Epoch: 9/10 \tIteration: 15900 \tTrain Loss: 0.082 \tTrain Accuracy: 96.00\n",
      "Epoch: 9/10 \tIteration: 16000 \tTrain Loss: 0.103 \tTrain Accuracy: 96.00\n",
      "Epoch: 9/10 \tIteration: 16100 \tTrain Loss: 0.233 \tTrain Accuracy: 96.00\n",
      "Epoch: 9/10 \tIteration: 16200 \tTrain Loss: 0.058 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 16300 \tTrain Loss: 0.054 \tTrain Accuracy: 98.00\n",
      "Epoch: 9/10 \tIteration: 16400 \tTrain Loss: 0.107 \tTrain Accuracy: 96.00\n",
      "Epoch: 9/10 \tIteration: 16500 \tTrain Loss: 0.143 \tTrain Accuracy: 92.00\n",
      "Epoch: 9/10 \tTrain Loss: 0.113 \tTrain Acc: 95.506\n",
      "Val Loss: 0.479 \tVal Acc: 88.073\n",
      "Time to train epoch: 52.17619299888611 s\n",
      "Test Loss: 0.558 \tTest Acc: 87.799\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m     test_loss\u001b[38;5;241m.\u001b[39mappend(loss_test\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39mmean(test_loss)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTest Acc: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39mmean(test_acc)))\n\u001b[0;32m---> 88\u001b[0m \u001b[43mappend_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_acc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mappend_to_csv\u001b[0;34m(epochs, accuracy)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend_to_csv\u001b[39m(epochs, accuracy):\n\u001b[0;32m----> 9\u001b[0m     acc \u001b[38;5;241m=\u001b[39m [accuracy \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m epochs]\n\u001b[1;32m     10\u001b[0m     df_csv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_name)\n\u001b[1;32m     11\u001b[0m     df_csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest_Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m=\u001b[39m accuracy\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs = 10\n",
    "n_filters = 128\n",
    "kernel_size = 2\n",
    "layers= 2\n",
    "learning_rate = 0.001\n",
    "print(len(word_dict))\n",
    "vocab_size = 10000\n",
    "print(vocab_size)\n",
    "embed_dims = 32\n",
    "seq_len = 500\n",
    "dropout = 0.3\n",
    "batch_size=50\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = QRNN(vocab_size, embed_dims, n_filters, kernel_size, batch_size, seq_len, layers, device, dropout).to(device)\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "counter = 0\n",
    "QRNN_acc = []\n",
    "QRNN_valacc = []\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "val_acc_epoch = []\n",
    "time_epoch = []\n",
    "model.train()\n",
    "for e in range(epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    for inputs, labels in train_dl:\n",
    "        \n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        model.zero_grad()\n",
    "        logits, accuracy = model(inputs,labels)\n",
    "        loss = criterion(logits,labels.float())\n",
    "        loss.backward()\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(accuracy.item()*100/batch_size)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        if counter%100==0:\n",
    "            print(\"Epoch: {}/{}\".format(e,epochs),\n",
    "                         \"\\tIteration: {}\".format(counter),\n",
    "                         \"\\tTrain Loss: {:.3f}\".format(loss.item()),\n",
    "                         \"\\tTrain Accuracy: {:.2f}\".format(accuracy.item()*100/batch_size))\n",
    "            QRNN_acc.append(accuracy.item()*100/batch_size)\n",
    "        counter += 1\n",
    "    train_loss_epoch.append(np.mean(train_loss))     \n",
    "    print(\"Epoch: {}/{}\".format(e,epochs), \"\\tTrain Loss: {:.3f}\".format(np.mean(train_loss)), \"\\tTrain Acc: {:.3f}\".format(np.mean(train_acc)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_acc = []\n",
    "        val_loss = []\n",
    "        for inputs, labels in val_dl:\n",
    "            inputs_val, labels_val = inputs.cuda(), labels.cuda()\n",
    "            logits_val,accuracy_val = model(inputs_val,labels_val)\n",
    "            loss_val = criterion(logits_val,labels_val.float())\n",
    "            batch_size = labels.size(0)\n",
    "            val_acc.append(accuracy_val.item()*100/batch_size)\n",
    "            val_loss.append(loss_val.item())\n",
    "        val_loss_epoch.append(np.mean(val_loss))\n",
    "        val_acc_epoch.append(np.mean(val_acc))\n",
    "        print(\"Val Loss: {:.3f}\".format(np.mean(val_loss)), \"\\tVal Acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "        QRNN_valacc.append(np.mean(val_acc))\n",
    "        model.train()\n",
    "    \n",
    "    end_time = time.time()-start_time\n",
    "    print(\"Time to train epoch: {0} s\".format(end_time))\n",
    "    time_epoch.append(end_time)\n",
    "    \n",
    "write_to_csv(epochs, train_loss_epoch, val_loss_epoch, val_acc_epoch, time_epoch)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_acc = []\n",
    "    test_loss = []\n",
    "    for inputs, labels in test_dl:\n",
    "        input_test, labels_test = inputs.cuda(), labels.cuda()\n",
    "        logits_test, accuracy_test = model(input_test, labels_test)\n",
    "        loss_test = criterion(logits_test, labels_test.float())\n",
    "        batch_size = labels.size(0)\n",
    "        test_acc.append(accuracy_test.item()*100/batch_size)\n",
    "        test_loss.append(loss_test.item())\n",
    "    print(\"Test Loss: {:.3f}\".format(np.mean(test_loss)), \"\\tTest Acc: {:.3f}\".format(np.mean(test_acc)))\n",
    "    append_to_csv(epochs, np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env2_gpu",
   "language": "python",
   "name": "my_env2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
