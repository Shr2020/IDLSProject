{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-imdb-hyperband.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import sys\n",
        "import os\n",
        "prefix = '/content/gdrive/My Drive/'\n",
        "# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n",
        "customized_path_to_your_homework = 'IDLSProject-main'\n",
        "sys_path = os.path.join(prefix, customized_path_to_your_homework)\n",
        "sys.path.append(sys_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oajq_A9Wb1mQ",
        "outputId": "13d4a779-c0bb-4743-f832-af1dca5602ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/IDLSProject-main'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O36-vTu0b4Vq",
        "outputId": "5f03ee35-d7c6-447e-f79b-2eea00be7f5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/IDLSProject-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './data/pytorch' # The folder we will use for storing data\n",
        "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
        "    os.makedirs(data_dir)"
      ],
      "metadata": {
        "id": "yBS_Cwn9bQOa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "import pandas as pd\n",
        "\n",
        "# Read in only the first 250 rows\n",
        "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None)\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "train_y = torch.from_numpy(train_sample[[0]].values).float().squeeze()\n",
        "train_X = torch.from_numpy(train_sample.drop([0], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
        "# Build the dataloader\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
        "\n",
        "#### Test data\n",
        "\n",
        "# Read in only the first 250 rows\n",
        "test_sample = pd.read_csv(os.path.join(data_dir, 'test.csv'), header=None, names=None)\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "test_y = torch.from_numpy(test_sample[[0]].values).float().squeeze()\n",
        "test_X = torch.from_numpy(test_sample.drop([0], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "test_ds = torch.utils.data.TensorDataset(test_X, test_y)\n",
        "# Build the dataloader\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=50)"
      ],
      "metadata": {
        "id": "ZmOPG383bk35"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    This is the simple RNN model we will be using to perform Sentiment Analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,trial,vocab_size):\n",
        "        \"\"\"\n",
        "        Initialize the model by settingg up the various layers.\n",
        "        \"\"\"\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        dropout = trial.suggest_uniform(\"dropout\",0.1, 0.6)\n",
        "        hidden_dim = trial.suggest_int(\"hidden_dim\",16,256)\n",
        "        embedding_dim = trial.suggest_int(\"embedding_dim\",16,128)\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "        self.word_dict = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input.\n",
        "        \"\"\"\n",
        "        x = x.t()\n",
        "        lengths = x[0,:]\n",
        "        reviews = x[1:,:]\n",
        "        embeds = self.embedding(reviews)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        out = self.dense(lstm_out)\n",
        "        out = out[lengths - 1, range(len(lengths))]\n",
        "        return self.sig(out.squeeze())"
      ],
      "metadata": {
        "id": "sfCjO0npbn98"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "mHViaSCPmv_Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7NF2tFZmyKu",
        "outputId": "fdbd5f7c-5950-4826-929b-5c9aa97854af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.9 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.8)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 67.4 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 54.3 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=975327c02eaeccaec1c76be2ae072830551b9cd79de05a2a672f24c92e8d3e0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define an objective function to be minimized.\n",
        "def objective(trial):\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "  #epochs = trial.suggest_int(\"epochs\",5,15)\n",
        "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-0)\n",
        "  #momentum = trial.suggest_uniform(\"momentum\", 0.0, 1.0)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = LSTMClassifier(trial,5000).to(device)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  loss_fn = torch.nn.BCELoss()\n",
        "  for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        hidden = None\n",
        "        for batch in train_dl:         \n",
        "            batch_X, batch_y = batch\n",
        "            batch_X = batch_X.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            prediction = model(batch_X)\n",
        "            loss = loss_fn(prediction, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.data.item()\n",
        "        print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_dl)))\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "          for batch in test_dl:         \n",
        "            batch_X, batch_y = batch\n",
        "            batch_X = batch_X.to(device)\n",
        "            prediction = model(batch_X)\n",
        "            result = np.round(prediction.cpu())\n",
        "#             results.extend(list(result.numpy()))\n",
        "#             labels.extend(list(batch_y.numpy()))\n",
        "            total += batch_y.size(0)\n",
        "            correct += (result == batch_y).sum().item()\n",
        "        print(\"Accuracy:\", correct/total)\n",
        "        accuracy = correct/total\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "wMfr55LTeimO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\",pruner=optuna.pruners.HyperbandPruner(\n",
        "        min_resource=1, max_resource=epochs, reduction_factor=3\n",
        "    ),)\n",
        "study.optimize(objective, n_trials=1)\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47KgAKz3egP8",
        "outputId": "967d1c59-218e-4674-d906-b7e6be6d86a8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-05-14 03:30:17,593]\u001b[0m A new study created in memory with name: no-name-8425937f-fae6-4fc5-b48b-249eb8fd7b9a\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, BCELoss: 0.537729003727436\n",
            "Accuracy: 0.8084\n",
            "Epoch: 2, BCELoss: 0.4268411916792393\n",
            "Accuracy: 0.81716\n",
            "Epoch: 3, BCELoss: 0.32878619214892385\n",
            "Accuracy: 0.85288\n",
            "Epoch: 4, BCELoss: 0.27829288572072985\n",
            "Accuracy: 0.85052\n",
            "Epoch: 5, BCELoss: 0.24631216710060835\n",
            "Accuracy: 0.86356\n",
            "Epoch: 6, BCELoss: 0.21278584172576667\n",
            "Accuracy: 0.86096\n",
            "Epoch: 7, BCELoss: 0.18907082679867745\n",
            "Accuracy: 0.86292\n",
            "Epoch: 8, BCELoss: 0.17643479952961205\n",
            "Accuracy: 0.85864\n",
            "Epoch: 9, BCELoss: 0.14761430918052793\n",
            "Accuracy: 0.86512\n",
            "Epoch: 10, BCELoss: 0.1323443582057953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-05-14 03:32:17,532]\u001b[0m Trial 0 finished with value: 0.86368 and parameters: {'optimizer': 'SGD', 'lr': 0.00044017280457261005, 'dropout': 0.33277629679500353, 'hidden_dim': 86, 'embedding_dim': 69}. Best is trial 0 with value: 0.86368.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86368\n",
            "Study statistics: \n",
            "  Number of finished trials:  1\n",
            "  Number of complete trials:  1\n",
            "Best trial:\n",
            "  Value:  0.86368\n",
            "  Params: \n",
            "    optimizer: SGD\n",
            "    lr: 0.00044017280457261005\n",
            "    dropout: 0.33277629679500353\n",
            "    hidden_dim: 86\n",
            "    embedding_dim: 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "#     results = []\n",
        "#     labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dl:         \n",
        "            batch_X, batch_y = batch\n",
        "            batch_X = batch_X.to(device)\n",
        "            prediction = model(batch_X)\n",
        "            result = np.round(prediction.cpu())\n",
        "#             results.extend(list(result.numpy()))\n",
        "#             labels.extend(list(batch_y.numpy()))\n",
        "            total += batch_y.size(0)\n",
        "            correct += (result == batch_y).sum().item()\n",
        "    print(\"Accuracy:\", correct/total)"
      ],
      "metadata": {
        "id": "1E1r2mZbbwZO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "K9FStLpAdrrj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, test_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR_FTuLSby1Y",
        "outputId": "ae3e4b77-ac6c-4d73-fe7c-f69895bf57c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.85292\n"
          ]
        }
      ]
    }
  ]
}