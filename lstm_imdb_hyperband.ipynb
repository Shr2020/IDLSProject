{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oajq_A9Wb1mQ",
    "outputId": "39c7edee-8a99-4174-fead-e32e1346fb02"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')\n",
    "import sys\n",
    "import os\n",
    "prefix = '/content/gdrive/My Drive/'\n",
    "# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n",
    "customized_path_to_your_homework = 'IDLSProject-main'\n",
    "sys_path = os.path.join(prefix, customized_path_to_your_homework)\n",
    "sys.path.append(sys_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O36-vTu0b4Vq",
    "outputId": "6ecf9361-eb15-48bf-91a0-4138310adb7a"
   },
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/My Drive/IDLSProject-main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yBS_Cwn9bQOa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "data_dir = './data/pytorch'\n",
    "with open(os.path.join(data_dir, 'word_dict_qrnn.pkl'), \"rb\") as f:\n",
    "    word_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMsjwRQ9KBwk",
    "outputId": "6f9757b3-4693-492b-f76e-8e0c1f4bda29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 502) (20000, 502)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "train = pd.read_csv(os.path.join(data_dir, 'train_qrnn.csv'), header=None, names=None)\n",
    "test_sample = pd.read_csv(os.path.join(data_dir, 'test_qrnn.csv'), header=None, names=None)\n",
    "print(train.shape, test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sn509rQ2KFBX",
    "outputId": "ae259769-1bd7-4e94-93ee-74e33aec2ccc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 502), (10000, 502), (10000, 502))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test, val = train_test_split(test_sample, test_size=0.5)\n",
    "train.shape, test.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkVwncNSKHsE",
    "outputId": "3eaf6395-49a9-4ba7-e651-065fde3ada39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_y = torch.from_numpy(train[[0]].values).float().squeeze()\n",
    "train_X = torch.from_numpy(train.drop([0], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
    "# Build the dataloader\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
    "\n",
    "######val data\n",
    "# Turn the input pandas dataframe into tensors\n",
    "val_y = torch.from_numpy(val[[0]].values).float().squeeze()\n",
    "val_X = torch.from_numpy(val.drop([0], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "val_ds = torch.utils.data.TensorDataset(val_X, val_y)\n",
    "# Build the dataloader\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=50)\n",
    "\n",
    "\n",
    "#### Test data\n",
    "# Turn the input pandas dataframe into tensors\n",
    "test_y = torch.from_numpy(test[[0]].values).float().squeeze()\n",
    "test_X = torch.from_numpy(test.drop([0], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "test_ds = torch.utils.data.TensorDataset(test_X, test_y)\n",
    "# Build the dataloader\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=50)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1f_CNpgsKKrW"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the simple RNN model we will be using to perform Sentiment Analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, trial,vocab_size):\n",
    "        \"\"\"\n",
    "        Initialize the model by settingg up the various layers.\n",
    "        \"\"\"\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        dropout = trial.suggest_uniform(\"dropout\",0.1, 0.6)\n",
    "        hidden_dim = trial.suggest_int(\"hidden_dim\",16,256)\n",
    "        embedding_dim = trial.suggest_int(\"embedding_dim\",16,128)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        self.word_dict = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input.\n",
    "        \"\"\"\n",
    "        x = x.t()\n",
    "        lengths = x[0,:]\n",
    "        reviews = x[1:,:]\n",
    "        embeds = self.embedding(reviews)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        out = self.dense(lstm_out)\n",
    "        out = out[lengths - 1, range(len(lengths))]\n",
    "        return self.sig(out.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mT8XRhwXKPVg"
   },
   "outputs": [],
   "source": [
    "data_dir = './lstm-imdb-hyperband-trails_6/' # The folder we will use for storing data\n",
    "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "filename = \"\"\n",
    "def write_to_csv(trail_num, epochs, train_loss, train_acc, val_loss, val_acc, time_train):\n",
    "    global filename\n",
    "    filename = \"./lstm-imdb-hyperband-trails_6/\"+str(trail_num)+\".csv\"\n",
    "    epoch = [i for i in range(epochs)]\n",
    "    df_metrics = pd.DataFrame(list(zip(epoch, train_loss, train_acc, val_loss, val_acc, time_train)), columns =['Epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'train_time'])\n",
    "    df_metrics.to_csv(filename, index=False)    \n",
    "    \n",
    "def append_to_csv(epochs, accuracy):\n",
    "    acc = [accuracy for i in range(epochs)]\n",
    "    df_csv = pd.read_csv(filename)\n",
    "    df_csv['Test_Accuracy']  = acc\n",
    "    df_csv.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OasEM6YFKTBw"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "epochs = 10\n",
    "vocab_size=5000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define an objective function to be minimized.\n",
    "def objective(trial):\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    #epochs = trial.suggest_int(\"epochs\",5,15)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-0)\n",
    "    #momentum = trial.suggest_uniform(\"momentum\", 0.0, 1.0)\n",
    "    model = LSTMClassifier(trial, vocab_size).to(device)\n",
    "    trial.set_user_attr(key=\"best_model\", value=model)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    train_loss_epoch = []\n",
    "    train_acc_epoch = []\n",
    "    val_loss_epoch = []\n",
    "    val_accuracy_epoch = []\n",
    "    time_train = []\n",
    "    final_val_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        start = time.time()\n",
    "        total_loss = 0\n",
    "        train_acc = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for batch in train_dl:         \n",
    "            batch_X, batch_y = batch\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(batch_X)\n",
    "            loss = loss_fn(prediction, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            result = np.round(prediction.detach().cpu())\n",
    "            total_loss += loss.data.item()\n",
    "            total += batch_y.size(0)\n",
    "            correct += (result == batch_y.cpu()).sum().item()\n",
    "            train_acc = correct/total\n",
    "        train_loss_epoch.append(np.round(total_loss / len(train_dl), 3))\n",
    "        train_acc_epoch.append(np.round(train_acc*100,3))\n",
    "        print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_dl)))\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            val_loss = []\n",
    "            for inputs, labels in val_dl:\n",
    "                inputs_val, labels_val = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(inputs_val)\n",
    "                loss = loss_fn(prediction, labels_val)\n",
    "                val_loss.append(np.round(loss.item(),3))\n",
    "                result = np.round(prediction.cpu())\n",
    "                total += labels_val.size(0)\n",
    "                correct += (result == labels_val.cpu()).sum().item()\n",
    "            val_accuracy_epoch.append(np.round((correct/total)*100, 3))\n",
    "            val_loss_epoch.append(np.round(np.mean(val_loss),3))\n",
    "            end = time.time() - start\n",
    "            final_val_acc = np.round((correct/total)*100, 3)\n",
    "            print(\"Val Loss: {:.3f}\".format(np.mean(val_loss)), \"\\tVal Acc: {:.3f}\".format(correct/total))\n",
    "            time_train.append(np.round(end,3))\n",
    "    write_to_csv(trial.number, epochs, train_loss_epoch, train_acc_epoch, val_loss_epoch, val_accuracy_epoch, time_train)\n",
    "    return final_val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yM6NlQlNqA4h"
   },
   "outputs": [],
   "source": [
    "def callback(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        study.set_user_attr(key=\"best_model\", value=trial.user_attrs[\"best_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQ7svJFbqH5J",
    "outputId": "dd2b34de-5b0f-429d-be6f-31130956f6d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 14:05:34,762]\u001b[0m A new study created in memory with name: no-name-bae07840-4620-4efd-9f06-4b9646c6623a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, BCELoss: 0.41769512213766574\n",
      "Val Loss: 0.308 \tVal Acc: 0.869\n",
      "Epoch: 1, BCELoss: 0.27510410668949287\n",
      "Val Loss: 0.292 \tVal Acc: 0.880\n",
      "Epoch: 2, BCELoss: 0.2502126902962724\n",
      "Val Loss: 0.310 \tVal Acc: 0.874\n",
      "Epoch: 3, BCELoss: 0.3075947742909193\n",
      "Val Loss: 0.650 \tVal Acc: 0.637\n",
      "Epoch: 4, BCELoss: 0.6259882539014021\n",
      "Val Loss: 0.636 \tVal Acc: 0.633\n",
      "Epoch: 5, BCELoss: 0.6253706437349319\n",
      "Val Loss: 0.636 \tVal Acc: 0.631\n",
      "Epoch: 6, BCELoss: 0.6232606396575768\n",
      "Val Loss: 0.634 \tVal Acc: 0.629\n",
      "Epoch: 7, BCELoss: 0.6226270253956318\n",
      "Val Loss: 0.640 \tVal Acc: 0.629\n",
      "Epoch: 8, BCELoss: 0.623735518703858\n",
      "Val Loss: 0.639 \tVal Acc: 0.629\n",
      "Epoch: 9, BCELoss: 0.6222674574454625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 14:08:26,946]\u001b[0m Trial 0 finished with value: 63.0 and parameters: {'optimizer': 'Adam', 'lr': 0.009550602064809175, 'dropout': 0.5705425114414746, 'hidden_dim': 217, 'embedding_dim': 125}. Best is trial 0 with value: 63.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.637 \tVal Acc: 0.630\n",
      "Epoch: 0, BCELoss: 0.5164170065273841\n",
      "Val Loss: 0.427 \tVal Acc: 0.810\n",
      "Epoch: 1, BCELoss: 0.35355854195853076\n",
      "Val Loss: 0.632 \tVal Acc: 0.740\n",
      "Epoch: 2, BCELoss: 0.2864521169414123\n",
      "Val Loss: 0.334 \tVal Acc: 0.863\n",
      "Epoch: 3, BCELoss: 0.25326452701042096\n",
      "Val Loss: 0.299 \tVal Acc: 0.878\n",
      "Epoch: 4, BCELoss: 0.21164309836924075\n",
      "Val Loss: 0.308 \tVal Acc: 0.880\n",
      "Epoch: 5, BCELoss: 0.17744684979319572\n",
      "Val Loss: 0.325 \tVal Acc: 0.879\n",
      "Epoch: 6, BCELoss: 0.13770583737952014\n",
      "Val Loss: 0.374 \tVal Acc: 0.876\n",
      "Epoch: 7, BCELoss: 0.1042228236158068\n",
      "Val Loss: 0.411 \tVal Acc: 0.876\n",
      "Epoch: 8, BCELoss: 0.06828997010442739\n",
      "Val Loss: 0.475 \tVal Acc: 0.873\n",
      "Epoch: 9, BCELoss: 0.047025494617410006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 14:10:35,936]\u001b[0m Trial 1 finished with value: 87.04 and parameters: {'optimizer': 'RMSprop', 'lr': 0.002058043533075509, 'dropout': 0.35916214323504625, 'hidden_dim': 151, 'embedding_dim': 71}. Best is trial 1 with value: 87.04.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.537 \tVal Acc: 0.870\n",
      "Epoch: 0, BCELoss: 0.45469005540013313\n",
      "Val Loss: 0.309 \tVal Acc: 0.872\n",
      "Epoch: 1, BCELoss: 0.2686989753320813\n",
      "Val Loss: 0.289 \tVal Acc: 0.880\n",
      "Epoch: 2, BCELoss: 0.19125078657642006\n",
      "Val Loss: 0.320 \tVal Acc: 0.879\n",
      "Epoch: 3, BCELoss: 0.11747622947829466\n",
      "Val Loss: 0.391 \tVal Acc: 0.875\n",
      "Epoch: 4, BCELoss: 0.06617927370360122\n",
      "Val Loss: 0.454 \tVal Acc: 0.871\n",
      "Epoch: 5, BCELoss: 0.04244120547780767\n",
      "Val Loss: 0.499 \tVal Acc: 0.869\n",
      "Epoch: 6, BCELoss: 0.03654622590576764\n",
      "Val Loss: 0.531 \tVal Acc: 0.867\n",
      "Epoch: 7, BCELoss: 0.029947943179674138\n",
      "Val Loss: 0.575 \tVal Acc: 0.867\n",
      "Epoch: 8, BCELoss: 0.02593796321055076\n",
      "Val Loss: 0.656 \tVal Acc: 0.874\n",
      "Epoch: 9, BCELoss: 0.02532199548673816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 14:13:14,408]\u001b[0m Trial 2 finished with value: 87.12 and parameters: {'optimizer': 'RMSprop', 'lr': 0.003846672585823485, 'dropout': 0.3015654025341833, 'hidden_dim': 215, 'embedding_dim': 112}. Best is trial 2 with value: 87.12.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.683 \tVal Acc: 0.871\n",
      "Epoch: 0, BCELoss: 0.6945499871174494\n",
      "Val Loss: 0.693 \tVal Acc: 0.505\n",
      "Epoch: 1, BCELoss: 0.692309149603049\n",
      "Val Loss: 0.692 \tVal Acc: 0.518\n",
      "Epoch: 2, BCELoss: 0.6903085910280545\n",
      "Val Loss: 0.690 \tVal Acc: 0.530\n",
      "Epoch: 3, BCELoss: 0.6883299295107523\n",
      "Val Loss: 0.688 \tVal Acc: 0.540\n",
      "Epoch: 4, BCELoss: 0.6862239050865173\n",
      "Val Loss: 0.686 \tVal Acc: 0.547\n",
      "Epoch: 5, BCELoss: 0.6838550706704457\n",
      "Val Loss: 0.684 \tVal Acc: 0.556\n",
      "Epoch: 6, BCELoss: 0.6810690166552862\n",
      "Val Loss: 0.681 \tVal Acc: 0.568\n",
      "Epoch: 7, BCELoss: 0.6776581848661105\n",
      "Val Loss: 0.677 \tVal Acc: 0.581\n",
      "Epoch: 8, BCELoss: 0.673298727273941\n",
      "Val Loss: 0.672 \tVal Acc: 0.593\n",
      "Epoch: 9, BCELoss: 0.667371907333533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 14:14:47,120]\u001b[0m Trial 3 finished with value: 61.12 and parameters: {'optimizer': 'Adam', 'lr': 2.3588441725992195e-05, 'dropout': 0.37484497157315655, 'hidden_dim': 43, 'embedding_dim': 39}. Best is trial 2 with value: 87.12.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.665 \tVal Acc: 0.611\n",
      "Epoch: 0, BCELoss: 0.6721845672527949\n",
      "Val Loss: 0.643 \tVal Acc: 0.623\n",
      "Epoch: 1, BCELoss: 0.5927084389328957\n",
      "Val Loss: 0.523 \tVal Acc: 0.739\n",
      "Epoch: 2, BCELoss: 0.5066125642259915\n",
      "Val Loss: 0.499 \tVal Acc: 0.760\n",
      "Epoch: 3, BCELoss: 0.4425988132258256\n",
      "Val Loss: 0.401 \tVal Acc: 0.825\n",
      "Epoch: 4, BCELoss: 0.39577228665351866\n",
      "Val Loss: 0.377 \tVal Acc: 0.838\n",
      "Epoch: 5, BCELoss: 0.36124255329370497\n",
      "Val Loss: 0.361 \tVal Acc: 0.844\n",
      "Epoch: 6, BCELoss: 0.34195550411939624\n",
      "Val Loss: 0.354 \tVal Acc: 0.846\n",
      "Epoch: 7, BCELoss: 0.31293261736631395\n",
      "Val Loss: 0.348 \tVal Acc: 0.853\n",
      "Epoch: 8, BCELoss: 0.29036299165338275\n",
      "Val Loss: 0.339 \tVal Acc: 0.857\n",
      "Epoch: 9, BCELoss: 0.27100382807354134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 14:17:11,474]\u001b[0m Trial 4 finished with value: 85.68 and parameters: {'optimizer': 'SGD', 'lr': 0.15871486187790268, 'dropout': 0.582539890978334, 'hidden_dim': 181, 'embedding_dim': 90}. Best is trial 2 with value: 87.12.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.341 \tVal Acc: 0.857\n",
      "Epoch: 0, BCELoss: 0.692031569381555\n",
      "Val Loss: 0.691 \tVal Acc: 0.524\n",
      "Epoch: 1, BCELoss: 0.6887138007084529\n",
      "Val Loss: 0.688 \tVal Acc: 0.542\n",
      "Epoch: 2, BCELoss: 0.6843544314304988\n",
      "Val Loss: 0.683 \tVal Acc: 0.560\n",
      "Epoch: 3, BCELoss: 0.6719852420687675\n",
      "Val Loss: 0.662 \tVal Acc: 0.599\n",
      "Epoch: 4, BCELoss: 0.6441376140713692\n",
      "Val Loss: 0.640 \tVal Acc: 0.627\n",
      "Epoch: 5, BCELoss: 0.6206267277896405\n",
      "Val Loss: 0.622 \tVal Acc: 0.657\n",
      "Epoch: 6, BCELoss: 0.6011030146976312\n",
      "Val Loss: 0.604 \tVal Acc: 0.674\n",
      "Epoch: 7, BCELoss: 0.5828266031543414\n",
      "Val Loss: 0.587 \tVal Acc: 0.692\n",
      "Epoch: 8, BCELoss: 0.5651109232008458\n",
      "Val Loss: 0.571 \tVal Acc: 0.707\n",
      "Epoch: 9, BCELoss: 0.548620665470759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 14:18:50,564]\u001b[0m Trial 5 finished with value: 72.17 and parameters: {'optimizer': 'Adam', 'lr': 4.943560870046532e-05, 'dropout': 0.5408280910085019, 'hidden_dim': 65, 'embedding_dim': 20}. Best is trial 2 with value: 87.12.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.556 \tVal Acc: 0.722\n",
      "Study statistics: \n",
      "  Number of finished trials:  6\n",
      "  Number of complete trials:  6\n",
      "Best trial:\n",
      "  Value:  87.12\n",
      "  Params: \n",
      "    optimizer: RMSprop\n",
      "    lr: 0.003846672585823485\n",
      "    dropout: 0.3015654025341833\n",
      "    hidden_dim: 215\n",
      "    embedding_dim: 112\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "study = optuna.create_study(direction=\"maximize\",pruner=optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1, max_resource=epochs, reduction_factor=3\n",
    "    ),)\n",
    "study.optimize(objective, n_trials=6,callbacks=[callback])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "best_model=study.user_attrs[\"best_model\"]\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './lstm-imdb-hyperband/' # The folder we will use for storing data\n",
    "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "torch.save(best_model.state_dict(),\"./lstm-imdb-hyperband/lstm-imdb-hyperband.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2D2JfLBeKjQ0"
   },
   "outputs": [],
   "source": [
    "def test(model, test_dl, epochs):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "#     results = []\n",
    "#     labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dl:         \n",
    "            batch_X, batch_y = batch\n",
    "            batch_X = batch_X.to(device)\n",
    "            prediction = model(batch_X)\n",
    "            result = np.round(prediction.cpu())\n",
    "#             results.extend(list(result.numpy()))\n",
    "#             labels.extend(list(batch_y.numpy()))\n",
    "            total += batch_y.size(0)\n",
    "            correct += (result == batch_y).sum().item()\n",
    "    print(\"Accuracy:\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vR_FTuLSby1Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:691: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:925.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8694\n"
     ]
    }
   ],
   "source": [
    "test(best_model, test_dl, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lstm-imdb-hyperband.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_env2_gpu",
   "language": "python",
   "name": "my_env2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
