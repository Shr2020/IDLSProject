{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXRRPjTk5gv1",
    "outputId": "160d602d-a80c-4c37-ac88-8861c425a687"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')\n",
    "import sys\n",
    "import os\n",
    "prefix = '/content/gdrive/My Drive/'\n",
    "# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n",
    "customized_path_to_your_homework = 'IDLSProject-main'\n",
    "sys_path = os.path.join(prefix, customized_path_to_your_homework)\n",
    "sys.path.append(sys_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8m8aQCL5pFJ",
    "outputId": "99d5e616-3b14-4f05-87e8-dc0952a76a19"
   },
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/My Drive/IDLSProject-main-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0h8gAUJ_5q-2",
    "outputId": "69b1a58d-cee0-4c2a-c702-237b741b9dd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83000, 502) (21975, 502)\n",
      "torch.Size([10760, 1]) torch.Size([10760, 1])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = './data/pytorch'\n",
    "with open(os.path.join(data_dir, 'word_dict_amazon.pkl'), \"rb\") as f:\n",
    "    word_dict = pickle.load(f)\n",
    "    \n",
    "train = pd.read_csv(os.path.join(data_dir, 'train_amazon.csv'), header=None, names=None)\n",
    "test_sample = pd.read_csv(os.path.join(data_dir, 'test_amazon.csv'), header=None, names=None)\n",
    "print(train.shape, test_sample.shape)\n",
    "\n",
    "\n",
    "test, val = train_test_split(test_sample, test_size=0.5)\n",
    "train.shape, test.shape, val.shape\n",
    "\n",
    "#drop rows\n",
    "test.drop(test.tail(227).index,inplace = True)\n",
    "val.drop(val.tail(228).index,inplace = True)\n",
    "test.shape, val.shape\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_y = torch.from_numpy(train[[0]].values).float()\n",
    "train_X = torch.from_numpy(train.drop([0, 1], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
    "# Build the dataloader\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
    "\n",
    "######val data\n",
    "# Turn the input pandas dataframe into tensors\n",
    "val_y = torch.from_numpy(val[[0]].values).float()\n",
    "val_X = torch.from_numpy(val.drop([0, 1], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "val_ds = torch.utils.data.TensorDataset(val_X, val_y)\n",
    "# Build the dataloader\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=50)\n",
    "\n",
    "\n",
    "#### Test data\n",
    "# Turn the input pandas dataframe into tensors\n",
    "test_y = torch.from_numpy(test[[0]].values).float()\n",
    "test_X = torch.from_numpy(test.drop([0, 1], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "test_ds = torch.utils.data.TensorDataset(test_X, test_y)\n",
    "# Build the dataloader\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=50)\n",
    "print(test_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DT-bPvic542j"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "seq_len = 500\n",
    "dropout = 0.5\n",
    "filter_size = 100\n",
    "vocab_size = 10000\n",
    "embed_dims = 32\n",
    "hidden_size = 100\n",
    "kernel_size = [3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OtBMgWdy58jp"
   },
   "outputs": [],
   "source": [
    "data_dir = './cnn-lstm-amazon-hyperband-trails_10/' # The folder we will use for storing data\n",
    "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "filename = \"\"\n",
    "def write_to_csv(trail_num, epochs, train_loss, train_acc, val_loss, val_acc, time_train):\n",
    "    global filename\n",
    "    filename = \"./cnn-lstm-amazon-hyperband-trails_10/\"+str(trail_num)+\".csv\"\n",
    "    epoch = [i for i in range(epochs)]\n",
    "    df_metrics = pd.DataFrame(list(zip(epoch, train_loss, train_acc, val_loss, val_acc, time_train)), columns =['Epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'train_time'])\n",
    "    df_metrics.to_csv(filename, index=False)    \n",
    "    \n",
    "def append_to_csv(epochs, accuracy):\n",
    "    acc = [accuracy for i in range(epochs)]\n",
    "    df_csv = pd.read_csv(filename)\n",
    "    df_csv['Test_Accuracy']  = acc\n",
    "    df_csv.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lOi5VnD-6Afi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "class Combine(nn.Module):\n",
    "    def __init__(self,trial,vocab_size, embed_size, filter_size, kernel_size, dropout, seq_len,hidden_size):\n",
    "        super(Combine, self).__init__()\n",
    "        dropout = trial.suggest_uniform(\"dropout\",0.1, 0.6)\n",
    "        hidden_size = trial.suggest_int(\"hidden_size\",32,256)\n",
    "        embed_size = trial.suggest_int(\"embed_size\",16,128)\n",
    "        n_filters = trial.suggest_int(\"n_filters\",50,200)\n",
    "        self.embedding = torch.nn.Embedding(vocab_size,embed_size)\n",
    "        self.conv1 = torch.nn.Conv2d(1,filter_size,kernel_size=[kernel_size[0],embed_size])\n",
    "        self.conv2 = torch.nn.Conv2d(1,filter_size,kernel_size=[kernel_size[1],embed_size])\n",
    "        self.conv3 = torch.nn.Conv2d(1,filter_size,kernel_size=[kernel_size[2],embed_size])\n",
    "        self.mp1 = torch.nn.MaxPool1d(seq_len+1-kernel_size[0])\n",
    "        self.mp2 = torch.nn.MaxPool1d(seq_len+1-kernel_size[1])\n",
    "        self.mp3 = torch.nn.MaxPool1d(seq_len+1-kernel_size[2])\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        #self.cnn = CNN(vocab_size, embed_size, filter_size, kernel_size, dropout, seq_len)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=3*filter_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=1,\n",
    "            batch_first=True)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.word_dict = None\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        #print(batch_size)\n",
    "        embed_input = self.embedding(x)\n",
    "        embed_input.unsqueeze_(1)\n",
    "        x1 = torch.tanh(self.dropout(self.conv1(embed_input))).squeeze(3)\n",
    "        x2 = torch.tanh(self.dropout(self.conv2(embed_input))).squeeze(3)\n",
    "        x3 = torch.tanh(self.dropout(self.conv3(embed_input))).squeeze(3)\n",
    "        f1 = self.mp1(x1).squeeze(2)\n",
    "        f2 = self.mp2(x2).squeeze(2)\n",
    "        f3 = self.mp3(x3).squeeze(2)\n",
    "        c_out = torch.cat([f1,f2,f3],dim=1)\n",
    "        r_in = c_out.view(batch_size, 1, -1)\n",
    "        lstm_out, _ = self.lstm(r_in)\n",
    "        out = self.dense(lstm_out[:, -1, :])\n",
    "        return self.sig(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yhUhQgON6Ft4"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np \n",
    "def objective(trial):\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-0)\n",
    "    #momentum = trial.suggest_uniform(\"momentum\", 0.0, 1.0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Combine(trial,vocab_size, embed_dims, filter_size, kernel_size, dropout, seq_len,hidden_size).to(device).to(device)\n",
    "    trial.set_user_attr(key=\"best_model\", value=model)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    train_loss_epoch = []\n",
    "    train_acc_epoch = []\n",
    "    val_loss_epoch = []\n",
    "    val_accuracy_epoch = []\n",
    "    time_train = []\n",
    "    val_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_acc = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for batch in train_dl:         \n",
    "                batch_X, batch_y = batch\n",
    "                batch_X = batch_X.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(batch_X)\n",
    "                loss = loss_fn(prediction, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                result = np.round(prediction.detach().cpu())\n",
    "                total_loss += loss.data.item()\n",
    "                total += batch_y.size(0)\n",
    "                correct += (result == batch_y.cpu()).sum().item()\n",
    "                train_acc = correct/total\n",
    "        train_loss_epoch.append(np.round(total_loss / len(train_dl), 3))\n",
    "        train_acc_epoch.append(np.round(train_acc*100,3))\n",
    "        print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_dl)))\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            val_loss = []\n",
    "            for inputs, labels in val_dl:\n",
    "                inputs_val, labels_val = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(inputs_val)\n",
    "                loss = loss_fn(prediction, labels_val)\n",
    "                val_loss.append(loss.item())\n",
    "                result = np.round(prediction.cpu())\n",
    "                total += labels_val.size(0)\n",
    "                correct += (result == labels_val.cpu()).sum().item()\n",
    "            val_accuracy_epoch.append(np.round((correct/total)*100, 3))\n",
    "            val_loss_epoch.append(np.round(np.mean(val_loss),3))\n",
    "            end = time.time() - start\n",
    "            print(\"Val Loss: {:.3f}\".format(np.mean(val_loss)), \"\\tVal Acc: {:.3f}\".format(correct/total))\n",
    "            time_train.append(np.round(end,3))\n",
    "            val_acc = np.round((correct/total)*100, 3)\n",
    "    write_to_csv(trial.number,epochs, train_loss_epoch, train_acc_epoch, val_loss_epoch, val_accuracy_epoch, time_train)\n",
    "    return val_acc\n",
    "\n",
    "\n",
    "def test(model, test_dl, epochs):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "#     results = []\n",
    "#     labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dl:         \n",
    "            batch_X, batch_y = batch\n",
    "            batch_X = batch_X.to(device)\n",
    "            prediction = model(batch_X)\n",
    "            result = np.round(prediction.cpu())\n",
    "#             results.extend(list(result.numpy()))\n",
    "#             labels.extend(list(batch_y.numpy()))\n",
    "            total += batch_y.size(0)\n",
    "            correct += (result == batch_y).sum().item()\n",
    "    acc = correct/total\n",
    "    print(\"Accuracy:\", (correct/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "P1THPr2-9CNZ"
   },
   "outputs": [],
   "source": [
    "def callback(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        study.set_user_attr(key=\"best_model\", value=trial.user_attrs[\"best_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SMRMuN_C_5lR"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlVqr1IX9FJn",
    "outputId": "9903ebce-5547-4ed1-9790-e78025695e9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:10:38,163]\u001b[0m A new study created in memory with name: no-name-e9ca4c3b-ce23-4215-b2bf-bdd3b83f36dd\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, BCELoss: 0.3770347839917045\n",
      "Val Loss: 0.319 \tVal Acc: 0.870\n",
      "Epoch: 1, BCELoss: 0.2815688351057021\n",
      "Val Loss: 0.304 \tVal Acc: 0.878\n",
      "Epoch: 2, BCELoss: 0.2549089605774147\n",
      "Val Loss: 0.296 \tVal Acc: 0.880\n",
      "Epoch: 3, BCELoss: 0.23835654782288404\n",
      "Val Loss: 0.295 \tVal Acc: 0.883\n",
      "Epoch: 4, BCELoss: 0.22433867019612386\n",
      "Val Loss: 0.302 \tVal Acc: 0.880\n",
      "Epoch: 5, BCELoss: 0.21244155917182025\n",
      "Val Loss: 0.311 \tVal Acc: 0.876\n",
      "Epoch: 6, BCELoss: 0.19989259494805192\n",
      "Val Loss: 0.317 \tVal Acc: 0.881\n",
      "Epoch: 7, BCELoss: 0.1887115005269108\n",
      "Val Loss: 0.321 \tVal Acc: 0.880\n",
      "Epoch: 8, BCELoss: 0.17722200953390405\n",
      "Val Loss: 0.336 \tVal Acc: 0.878\n",
      "Epoch: 9, BCELoss: 0.1679893698363778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:12:57,827]\u001b[0m Trial 0 finished with value: 87.593 and parameters: {'optimizer': 'RMSprop', 'lr': 0.04621239626939598, 'dropout': 0.3529977073347015, 'hidden_size': 159, 'embed_size': 46, 'n_filters': 130}. Best is trial 0 with value: 87.593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.359 \tVal Acc: 0.876\n",
      "Epoch: 0, BCELoss: 0.3919129880975528\n",
      "Val Loss: 0.318 \tVal Acc: 0.864\n",
      "Epoch: 1, BCELoss: 0.290038298698793\n",
      "Val Loss: 0.300 \tVal Acc: 0.876\n",
      "Epoch: 2, BCELoss: 0.2621110653841352\n",
      "Val Loss: 0.290 \tVal Acc: 0.880\n",
      "Epoch: 3, BCELoss: 0.24385104807744543\n",
      "Val Loss: 0.287 \tVal Acc: 0.882\n",
      "Epoch: 4, BCELoss: 0.23104813721883727\n",
      "Val Loss: 0.293 \tVal Acc: 0.880\n",
      "Epoch: 5, BCELoss: 0.22007579272725136\n",
      "Val Loss: 0.305 \tVal Acc: 0.878\n",
      "Epoch: 6, BCELoss: 0.209229436014072\n",
      "Val Loss: 0.306 \tVal Acc: 0.879\n",
      "Epoch: 7, BCELoss: 0.19905318606824401\n",
      "Val Loss: 0.312 \tVal Acc: 0.876\n",
      "Epoch: 8, BCELoss: 0.19020626887858633\n",
      "Val Loss: 0.330 \tVal Acc: 0.863\n",
      "Epoch: 9, BCELoss: 0.18178701833429106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:20:16,863]\u001b[0m Trial 1 finished with value: 84.907 and parameters: {'optimizer': 'Adam', 'lr': 0.0026868749584991517, 'dropout': 0.2792089653207933, 'hidden_size': 160, 'embed_size': 20, 'n_filters': 96}. Best is trial 0 with value: 87.593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.362 \tVal Acc: 0.849\n",
      "Epoch: 0, BCELoss: 0.3733948386756771\n",
      "Val Loss: 0.326 \tVal Acc: 0.867\n",
      "Epoch: 1, BCELoss: 0.27966169519686557\n",
      "Val Loss: 0.315 \tVal Acc: 0.875\n",
      "Epoch: 2, BCELoss: 0.25054578589926285\n",
      "Val Loss: 0.316 \tVal Acc: 0.878\n",
      "Epoch: 3, BCELoss: 0.23081985597824117\n",
      "Val Loss: 0.326 \tVal Acc: 0.881\n",
      "Epoch: 4, BCELoss: 0.2157478134181485\n",
      "Val Loss: 0.354 \tVal Acc: 0.880\n",
      "Epoch: 5, BCELoss: 0.20205749290804548\n",
      "Val Loss: 0.341 \tVal Acc: 0.880\n",
      "Epoch: 6, BCELoss: 0.18694723049986614\n",
      "Val Loss: 0.371 \tVal Acc: 0.881\n",
      "Epoch: 7, BCELoss: 0.17522600031940333\n",
      "Val Loss: 0.395 \tVal Acc: 0.878\n",
      "Epoch: 8, BCELoss: 0.16412997066480928\n",
      "Val Loss: 0.404 \tVal Acc: 0.880\n",
      "Epoch: 9, BCELoss: 0.15345850471541825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:23:13,139]\u001b[0m Trial 2 finished with value: 86.45 and parameters: {'optimizer': 'SGD', 'lr': 0.0023610508051774225, 'dropout': 0.37620509874983166, 'hidden_size': 171, 'embed_size': 92, 'n_filters': 59}. Best is trial 0 with value: 87.593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.418 \tVal Acc: 0.864\n",
      "Epoch: 0, BCELoss: 0.3628478369439941\n",
      "Val Loss: 0.324 \tVal Acc: 0.865\n",
      "Epoch: 1, BCELoss: 0.27341392036662043\n",
      "Val Loss: 0.312 \tVal Acc: 0.875\n",
      "Epoch: 2, BCELoss: 0.2457472316337278\n",
      "Val Loss: 0.339 \tVal Acc: 0.875\n",
      "Epoch: 3, BCELoss: 0.22550494302153948\n",
      "Val Loss: 0.336 \tVal Acc: 0.879\n",
      "Epoch: 4, BCELoss: 0.20976693114737072\n",
      "Val Loss: 0.340 \tVal Acc: 0.882\n",
      "Epoch: 5, BCELoss: 0.19608711753803562\n",
      "Val Loss: 0.350 \tVal Acc: 0.879\n",
      "Epoch: 6, BCELoss: 0.18079866055982657\n",
      "Val Loss: 0.383 \tVal Acc: 0.881\n",
      "Epoch: 7, BCELoss: 0.16741579545280302\n",
      "Val Loss: 0.382 \tVal Acc: 0.879\n",
      "Epoch: 8, BCELoss: 0.1560503642512373\n",
      "Val Loss: 0.418 \tVal Acc: 0.878\n",
      "Epoch: 9, BCELoss: 0.1482557955007237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:25:33,226]\u001b[0m Trial 3 finished with value: 87.621 and parameters: {'optimizer': 'Adam', 'lr': 2.1024519469138112e-05, 'dropout': 0.33013441053789405, 'hidden_size': 65, 'embed_size': 125, 'n_filters': 90}. Best is trial 3 with value: 87.621.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.428 \tVal Acc: 0.876\n",
      "Epoch: 0, BCELoss: 0.37895598260753127\n",
      "Val Loss: 0.313 \tVal Acc: 0.870\n",
      "Epoch: 1, BCELoss: 0.2814187838954021\n",
      "Val Loss: 0.294 \tVal Acc: 0.882\n",
      "Epoch: 2, BCELoss: 0.25466935981558747\n",
      "Val Loss: 0.295 \tVal Acc: 0.880\n",
      "Epoch: 3, BCELoss: 0.23817077830254313\n",
      "Val Loss: 0.297 \tVal Acc: 0.883\n",
      "Epoch: 4, BCELoss: 0.22252125466264874\n",
      "Val Loss: 0.312 \tVal Acc: 0.883\n",
      "Epoch: 5, BCELoss: 0.20939754401389735\n",
      "Val Loss: 0.315 \tVal Acc: 0.880\n",
      "Epoch: 6, BCELoss: 0.19454610245638942\n",
      "Val Loss: 0.330 \tVal Acc: 0.878\n",
      "Epoch: 7, BCELoss: 0.18291021900992077\n",
      "Val Loss: 0.336 \tVal Acc: 0.882\n",
      "Epoch: 8, BCELoss: 0.16941460273172482\n",
      "Val Loss: 0.363 \tVal Acc: 0.877\n",
      "Epoch: 9, BCELoss: 0.15937334838020334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:27:25,145]\u001b[0m Trial 4 finished with value: 87.528 and parameters: {'optimizer': 'SGD', 'lr': 0.008147180086419315, 'dropout': 0.27629589754353123, 'hidden_size': 86, 'embed_size': 44, 'n_filters': 157}. Best is trial 3 with value: 87.621.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.368 \tVal Acc: 0.875\n",
      "Epoch: 0, BCELoss: 0.3697334610105279\n",
      "Val Loss: 0.315 \tVal Acc: 0.867\n",
      "Epoch: 1, BCELoss: 0.280235829280622\n",
      "Val Loss: 0.299 \tVal Acc: 0.878\n",
      "Epoch: 2, BCELoss: 0.2524791117892208\n",
      "Val Loss: 0.296 \tVal Acc: 0.882\n",
      "Epoch: 3, BCELoss: 0.23371710174054985\n",
      "Val Loss: 0.303 \tVal Acc: 0.882\n",
      "Epoch: 4, BCELoss: 0.21821390049958445\n",
      "Val Loss: 0.309 \tVal Acc: 0.882\n",
      "Epoch: 5, BCELoss: 0.20385556027113674\n",
      "Val Loss: 0.326 \tVal Acc: 0.878\n",
      "Epoch: 6, BCELoss: 0.19133137749530466\n",
      "Val Loss: 0.337 \tVal Acc: 0.875\n",
      "Epoch: 7, BCELoss: 0.17686582291274366\n",
      "Val Loss: 0.357 \tVal Acc: 0.879\n",
      "Epoch: 8, BCELoss: 0.16469766734033284\n",
      "Val Loss: 0.357 \tVal Acc: 0.875\n",
      "Epoch: 9, BCELoss: 0.15654733698500925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:30:07,830]\u001b[0m Trial 5 finished with value: 87.23 and parameters: {'optimizer': 'RMSprop', 'lr': 9.70675941106051e-05, 'dropout': 0.35671984936752676, 'hidden_size': 196, 'embed_size': 70, 'n_filters': 118}. Best is trial 3 with value: 87.621.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.376 \tVal Acc: 0.872\n",
      "Epoch: 0, BCELoss: 0.37630481890526163\n",
      "Val Loss: 0.315 \tVal Acc: 0.868\n",
      "Epoch: 1, BCELoss: 0.2830547652555158\n",
      "Val Loss: 0.297 \tVal Acc: 0.879\n",
      "Epoch: 2, BCELoss: 0.25529761735619194\n",
      "Val Loss: 0.286 \tVal Acc: 0.883\n",
      "Epoch: 3, BCELoss: 0.2373669006424137\n",
      "Val Loss: 0.290 \tVal Acc: 0.882\n",
      "Epoch: 4, BCELoss: 0.22263448851025966\n",
      "Val Loss: 0.291 \tVal Acc: 0.881\n",
      "Epoch: 5, BCELoss: 0.20673798391573042\n",
      "Val Loss: 0.307 \tVal Acc: 0.879\n",
      "Epoch: 6, BCELoss: 0.19442888520972199\n",
      "Val Loss: 0.323 \tVal Acc: 0.875\n",
      "Epoch: 7, BCELoss: 0.18201568543866098\n",
      "Val Loss: 0.345 \tVal Acc: 0.859\n",
      "Epoch: 8, BCELoss: 0.17053841546918433\n",
      "Val Loss: 0.401 \tVal Acc: 0.847\n",
      "Epoch: 9, BCELoss: 0.1591627644588161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:31:57,358]\u001b[0m Trial 6 finished with value: 83.522 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00015203069208595738, 'dropout': 0.30600266389499386, 'hidden_size': 233, 'embed_size': 42, 'n_filters': 156}. Best is trial 3 with value: 87.621.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.456 \tVal Acc: 0.835\n",
      "Epoch: 0, BCELoss: 0.3931329218513635\n",
      "Val Loss: 0.329 \tVal Acc: 0.863\n",
      "Epoch: 1, BCELoss: 0.29101372098168693\n",
      "Val Loss: 0.311 \tVal Acc: 0.877\n",
      "Epoch: 2, BCELoss: 0.26391101043267423\n",
      "Val Loss: 0.310 \tVal Acc: 0.882\n",
      "Epoch: 3, BCELoss: 0.25005780857909155\n",
      "Val Loss: 0.310 \tVal Acc: 0.884\n",
      "Epoch: 4, BCELoss: 0.24048223146742367\n",
      "Val Loss: 0.307 \tVal Acc: 0.884\n",
      "Epoch: 5, BCELoss: 0.2303998669856284\n",
      "Val Loss: 0.315 \tVal Acc: 0.883\n",
      "Epoch: 6, BCELoss: 0.22375257624066378\n",
      "Val Loss: 0.322 \tVal Acc: 0.881\n",
      "Epoch: 7, BCELoss: 0.21530597520296474\n",
      "Val Loss: 0.328 \tVal Acc: 0.880\n",
      "Epoch: 8, BCELoss: 0.20862985500415046\n",
      "Val Loss: 0.330 \tVal Acc: 0.881\n",
      "Epoch: 9, BCELoss: 0.20397982545960022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:33:52,235]\u001b[0m Trial 7 finished with value: 88.067 and parameters: {'optimizer': 'RMSprop', 'lr': 4.690148740626518e-05, 'dropout': 0.5353777735745225, 'hidden_size': 159, 'embed_size': 45, 'n_filters': 93}. Best is trial 7 with value: 88.067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.342 \tVal Acc: 0.881\n",
      "Epoch: 0, BCELoss: 0.36946415249931525\n",
      "Val Loss: 0.322 \tVal Acc: 0.865\n",
      "Epoch: 1, BCELoss: 0.27638752920979476\n",
      "Val Loss: 0.311 \tVal Acc: 0.875\n",
      "Epoch: 2, BCELoss: 0.24461975919015436\n",
      "Val Loss: 0.303 \tVal Acc: 0.877\n",
      "Epoch: 3, BCELoss: 0.2214996799871505\n",
      "Val Loss: 0.320 \tVal Acc: 0.873\n",
      "Epoch: 4, BCELoss: 0.19970717419342823\n",
      "Val Loss: 0.366 \tVal Acc: 0.848\n",
      "Epoch: 5, BCELoss: 0.17699500286211092\n",
      "Val Loss: 0.384 \tVal Acc: 0.852\n",
      "Epoch: 6, BCELoss: 0.15810062834678823\n",
      "Val Loss: 0.468 \tVal Acc: 0.825\n",
      "Epoch: 7, BCELoss: 0.142795665460044\n",
      "Val Loss: 0.524 \tVal Acc: 0.816\n",
      "Epoch: 8, BCELoss: 0.12894764377354048\n",
      "Val Loss: 0.570 \tVal Acc: 0.807\n",
      "Epoch: 9, BCELoss: 0.11561710736686251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:35:51,933]\u001b[0m Trial 8 finished with value: 81.32 and parameters: {'optimizer': 'SGD', 'lr': 0.021228249017562446, 'dropout': 0.1878523376435325, 'hidden_size': 235, 'embed_size': 58, 'n_filters': 152}. Best is trial 7 with value: 88.067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.557 \tVal Acc: 0.813\n",
      "Epoch: 0, BCELoss: 0.36304088333644063\n",
      "Val Loss: 0.312 \tVal Acc: 0.867\n",
      "Epoch: 1, BCELoss: 0.27607109266142527\n",
      "Val Loss: 0.298 \tVal Acc: 0.878\n",
      "Epoch: 2, BCELoss: 0.24766615581620172\n",
      "Val Loss: 0.300 \tVal Acc: 0.878\n",
      "Epoch: 3, BCELoss: 0.2256126889891653\n",
      "Val Loss: 0.303 \tVal Acc: 0.878\n",
      "Epoch: 4, BCELoss: 0.20532431264733333\n",
      "Val Loss: 0.338 \tVal Acc: 0.860\n",
      "Epoch: 5, BCELoss: 0.18676989924790988\n",
      "Val Loss: 0.364 \tVal Acc: 0.841\n",
      "Epoch: 6, BCELoss: 0.1666274321557258\n",
      "Val Loss: 0.482 \tVal Acc: 0.817\n",
      "Epoch: 7, BCELoss: 0.15320602351664958\n",
      "Val Loss: 0.541 \tVal Acc: 0.805\n",
      "Epoch: 8, BCELoss: 0.1377664949228785\n",
      "Val Loss: 0.597 \tVal Acc: 0.794\n",
      "Epoch: 9, BCELoss: 0.1254673491708979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 22:38:17,564]\u001b[0m Trial 9 finished with value: 78.188 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0001454835719085333, 'dropout': 0.20972925817715501, 'hidden_size': 226, 'embed_size': 59, 'n_filters': 197}. Best is trial 7 with value: 88.067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.702 \tVal Acc: 0.782\n",
      "Study statistics: \n",
      "  Number of finished trials:  10\n",
      "  Number of complete trials:  10\n",
      "Best trial:\n",
      "  Value:  88.067\n",
      "  Params: \n",
      "    optimizer: RMSprop\n",
      "    lr: 4.690148740626518e-05\n",
      "    dropout: 0.5353777735745225\n",
      "    hidden_size: 159\n",
      "    embed_size: 45\n",
      "    n_filters: 93\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "study = optuna.create_study(direction=\"maximize\",pruner=optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1, max_resource=epochs, reduction_factor=3\n",
    "    ),)\n",
    "study.optimize(objective, n_trials=10,callbacks=[callback])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "best_model=study.user_attrs[\"best_model\"]\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SczpZ5Ab6Kb_"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(),\"./cnn-lstm-amazon-hyperband_10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSg_6YND9Jus",
    "outputId": "7533102f-8bf3-4977-e6a4-9c2fe4977cfc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:691: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:925.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.21561338289963\n"
     ]
    }
   ],
   "source": [
    "test(best_model, test_dl, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cnn-lstm-amazon-hyperband.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_env2_gpu",
   "language": "python",
   "name": "my_env2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
