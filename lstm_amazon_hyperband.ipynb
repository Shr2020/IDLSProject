{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "lstm-amazon-hyperband.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import sys\n",
        "import os\n",
        "prefix = '/content/gdrive/My Drive/'\n",
        "# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n",
        "customized_path_to_your_homework = 'IDLSProject-main'\n",
        "sys_path = os.path.join(prefix, customized_path_to_your_homework)\n",
        "sys.path.append(sys_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oajq_A9Wb1mQ",
        "outputId": "39c7edee-8a99-4174-fead-e32e1346fb02"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "%cd '/content/gdrive/My Drive/IDLSProject-main'"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/IDLSProject-main\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O36-vTu0b4Vq",
        "outputId": "6ecf9361-eb15-48bf-91a0-4138310adb7a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "data_dir = './data/pytorch'\n",
        "with open(os.path.join(data_dir, 'word_dict_amazon.pkl'), \"rb\") as f:\n",
        "    word_dict = pickle.load(f)"
      ],
      "outputs": [],
      "metadata": {
        "id": "yBS_Cwn9bQOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "train = pd.read_csv(os.path.join(data_dir, 'train_amazon.csv'), header=None, names=None)\n",
        "test_sample = pd.read_csv(os.path.join(data_dir, 'test_amazon.csv'), header=None, names=None)\n",
        "print(train.shape, test_sample.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 502) (20000, 502)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMsjwRQ9KBwk",
        "outputId": "6f9757b3-4693-492b-f76e-8e0c1f4bda29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test, val = train_test_split(test_sample, test_size=0.5)\n",
        "train.shape, test.shape, val.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30000, 502), (10000, 502), (10000, 502))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn509rQ2KFBX",
        "outputId": "ae259769-1bd7-4e94-93ee-74e33aec2ccc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "train_y = torch.from_numpy(train[[0]].values).float().squeeze()\n",
        "train_X = torch.from_numpy(train.drop([0], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
        "# Build the dataloader\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
        "\n",
        "######val data\n",
        "# Turn the input pandas dataframe into tensors\n",
        "val_y = torch.from_numpy(val[[0]].values).float().squeeze()\n",
        "val_X = torch.from_numpy(val.drop([0], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "val_ds = torch.utils.data.TensorDataset(val_X, val_y)\n",
        "# Build the dataloader\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=50)\n",
        "\n",
        "\n",
        "#### Test data\n",
        "# Turn the input pandas dataframe into tensors\n",
        "test_y = torch.from_numpy(test[[0]].values).float().squeeze()\n",
        "test_X = torch.from_numpy(test.drop([0], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "test_ds = torch.utils.data.TensorDataset(test_X, test_y)\n",
        "# Build the dataloader\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=50)\n",
        "print(test_y.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000])\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkVwncNSKHsE",
        "outputId": "3eaf6395-49a9-4ba7-e651-065fde3ada39"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    This is the simple RNN model we will be using to perform Sentiment Analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, trial,vocab_size):\n",
        "        \"\"\"\n",
        "        Initialize the model by settingg up the various layers.\n",
        "        \"\"\"\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        dropout = trial.suggest_uniform(\"dropout\",0.1, 0.6)\n",
        "        hidden_dim = trial.suggest_int(\"hidden_dim\",16,256)\n",
        "        embedding_dim = trial.suggest_int(\"embedding_dim\",16,128)\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "        self.word_dict = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input.\n",
        "        \"\"\"\n",
        "        x = x.t()\n",
        "        lengths = x[0,:]\n",
        "        reviews = x[1:,:]\n",
        "        embeds = self.embedding(reviews)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        out = self.dense(lstm_out)\n",
        "        out = out[lengths - 1, range(len(lengths))]\n",
        "        return self.sig(out.squeeze())"
      ],
      "outputs": [],
      "metadata": {
        "id": "1f_CNpgsKKrW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def write_to_csv(trail_num,epochs, train_loss, val_loss, val_acc, time_train):\n",
        "    epoch = [i for i in range(epochs)]\n",
        "    df_metrics = pd.DataFrame(list(zip(epoch, train_loss, val_loss, val_acc, time_train)), columns =['Epoch', 'train_loss', 'val_loss', 'val_acc', 'train_time'])\n",
        "    df_metrics.to_csv(\"./lstm-amazon-hyperband-trails/\"+str(trail_num)+\".csv\")\n",
        "    \n",
        "# def append_to_csv(epochs, accuracy):\n",
        "#     acc = [accuracy for i in range(epochs)]\n",
        "#     df_csv = pd.read_csv(file_name)\n",
        "#     df_csv['Test_Accuracy']  = accuracy\n",
        "#     df_metrics.to_csv(filename)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mT8XRhwXKPVg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "!pip install optuna"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 43.5 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 43.1 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=085e573195c00c0993a5073111f5aa277e41ec89803a799ac75c54e6baa99561\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxD0Pj_xrTLF",
        "outputId": "710fbcae-498e-484c-9199-f97bc7698911"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "import time\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.optim as optim\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "epochs = 10\n",
        "\n",
        "# Define an objective function to be minimized.\n",
        "def objective(trial):\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "  #epochs = trial.suggest_int(\"epochs\",5,15)\n",
        "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-0)\n",
        "  #momentum = trial.suggest_uniform(\"momentum\", 0.0, 1.0)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = LSTMClassifier(trial,5000).to(device)\n",
        "  trial.set_user_attr(key=\"best_model\", value=model)\n",
        "  optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "  loss_fn = torch.nn.BCELoss()\n",
        "  train_loss_epoch = []\n",
        "  train_acc_epoch = []\n",
        "  val_loss_epoch = []\n",
        "  val_accuracy_epoch = []\n",
        "  time_train = []\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "    train_acc = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch in train_dl:         \n",
        "      batch_X, batch_y = batch\n",
        "      batch_X = batch_X.to(device)\n",
        "      batch_y = batch_y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      prediction = model(batch_X)\n",
        "      loss = loss_fn(prediction, batch_y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      result = np.round(prediction.detach().cpu())\n",
        "      total_loss += loss.data.item()\n",
        "      total += batch_y.size(0)\n",
        "      correct += (result == batch_y.cpu()).sum().item()\n",
        "      train_acc = correct/total\n",
        "    train_loss_epoch.append(np.round(total_loss / len(train_dl), 3))\n",
        "    train_acc_epoch.append(np.round(train_acc*100,3))\n",
        "    print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_dl)))\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      val_loss = []\n",
        "      for inputs, labels in val_dl:\n",
        "        inputs_val, labels_val = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(inputs_val)\n",
        "        loss = loss_fn(prediction, labels_val)\n",
        "        val_loss.append(np.round(loss.item(),3))\n",
        "        result = np.round(prediction.cpu())\n",
        "        total += labels_val.size(0)\n",
        "        correct += (result == labels_val.cpu()).sum().item()\n",
        "      val_accuracy_epoch.append(np.round((correct/total)*100, 3))\n",
        "      val_loss_epoch.append(np.round(np.mean(val_loss),3))\n",
        "      end = time.time() - start\n",
        "      print(\"Val Loss: {:.3f}\".format(np.mean(val_loss)), \"\\tVal Acc: {:.3f}\".format(correct/total))\n",
        "      time_train.append(np.round(end,3))\n",
        "      val_acc = correct/total\n",
        "  write_to_csv(epochs, train_loss_epoch, train_acc_epoch, val_loss_epoch, val_accuracy_epoch, time_train)\n",
        "  return val_acc\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "OasEM6YFKTBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "def callback(study, trial):\n",
        "    if study.best_trial.number == trial.number:\n",
        "        study.set_user_attr(key=\"best_model\", value=trial.user_attrs[\"best_model\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "yM6NlQlNqA4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "study = optuna.create_study(direction=\"maximize\",pruner=optuna.pruners.HyperbandPruner(\n",
        "        min_resource=1, max_resource=epochs, reduction_factor=3\n",
        "    ),)\n",
        "study.optimize(objective, n_trials=10,callbacks=[callback])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "best_model=study.user_attrs[\"best_model\"]\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\"    {}: {}\".format(key, value))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-05-14 08:26:57,382]\u001b[0m A new study created in memory with name: no-name-7ca76f20-d121-4586-85d7-223972657c3a\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, BCELoss: 0.49429892693956695\n",
            "Val Loss: 0.349 \tVal Acc: 0.847\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ7svJFbqH5J",
        "outputId": "dd2b34de-5b0f-429d-be6f-31130956f6d4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def test(model, test_dl, epochs):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "#     results = []\n",
        "#     labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dl:         \n",
        "            batch_X, batch_y = batch\n",
        "            batch_X = batch_X.to(device)\n",
        "            prediction = model(batch_X)\n",
        "            result = np.round(prediction.cpu())\n",
        "#             results.extend(list(result.numpy()))\n",
        "#             labels.extend(list(batch_y.numpy()))\n",
        "            total += batch_y.size(0)\n",
        "            correct += (result == batch_y).sum().item()\n",
        "    print(\"Accuracy:\", correct/total)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2D2JfLBeKjQ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test(best_model, test_dl, epochs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "vR_FTuLSby1Y"
      }
    }
  ]
}