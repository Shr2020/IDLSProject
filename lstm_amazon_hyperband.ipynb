{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oajq_A9Wb1mQ",
    "outputId": "39c7edee-8a99-4174-fead-e32e1346fb02"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')\n",
    "import sys\n",
    "import os\n",
    "prefix = '/content/gdrive/My Drive/'\n",
    "# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n",
    "customized_path_to_your_homework = 'IDLSProject-main'\n",
    "sys_path = os.path.join(prefix, customized_path_to_your_homework)\n",
    "sys.path.append(sys_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O36-vTu0b4Vq",
    "outputId": "6ecf9361-eb15-48bf-91a0-4138310adb7a"
   },
   "outputs": [],
   "source": [
    "%cd '/content/gdrive/My Drive/IDLSProject-main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yBS_Cwn9bQOa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "data_dir = './data/pytorch'\n",
    "with open(os.path.join(data_dir, 'word_dict_amazon.pkl'), \"rb\") as f:\n",
    "    word_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMsjwRQ9KBwk",
    "outputId": "6f9757b3-4693-492b-f76e-8e0c1f4bda29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83000, 502) (21975, 502)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "train = pd.read_csv(os.path.join(data_dir, 'train_amazon.csv'), header=None, names=None)\n",
    "test_sample = pd.read_csv(os.path.join(data_dir, 'test_amazon.csv'), header=None, names=None)\n",
    "print(train.shape, test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sn509rQ2KFBX",
    "outputId": "ae259769-1bd7-4e94-93ee-74e33aec2ccc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83000, 502), (10987, 502), (10988, 502))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test, val = train_test_split(test_sample, test_size=0.5)\n",
    "train.shape, test.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkVwncNSKHsE",
    "outputId": "3eaf6395-49a9-4ba7-e651-065fde3ada39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10987])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_y = torch.from_numpy(train[[0]].values).float().squeeze()\n",
    "train_X = torch.from_numpy(train.drop([0], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
    "# Build the dataloader\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
    "\n",
    "######val data\n",
    "# Turn the input pandas dataframe into tensors\n",
    "val_y = torch.from_numpy(val[[0]].values).float().squeeze()\n",
    "val_X = torch.from_numpy(val.drop([0], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "val_ds = torch.utils.data.TensorDataset(val_X, val_y)\n",
    "# Build the dataloader\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=50)\n",
    "\n",
    "\n",
    "#### Test data\n",
    "# Turn the input pandas dataframe into tensors\n",
    "test_y = torch.from_numpy(test[[0]].values).float().squeeze()\n",
    "test_X = torch.from_numpy(test.drop([0], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "test_ds = torch.utils.data.TensorDataset(test_X, test_y)\n",
    "# Build the dataloader\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=50)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1f_CNpgsKKrW"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the simple RNN model we will be using to perform Sentiment Analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, trial,vocab_size):\n",
    "        \"\"\"\n",
    "        Initialize the model by settingg up the various layers.\n",
    "        \"\"\"\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        dropout = trial.suggest_uniform(\"dropout\",0.1, 0.6)\n",
    "        hidden_dim = trial.suggest_int(\"hidden_dim\",16,256)\n",
    "        embedding_dim = trial.suggest_int(\"embedding_dim\",16,128)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        self.word_dict = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input.\n",
    "        \"\"\"\n",
    "        x = x.t()\n",
    "        lengths = x[0,:]\n",
    "        reviews = x[1:,:]\n",
    "        embeds = self.embedding(reviews)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        out = self.dense(lstm_out)\n",
    "        out = out[lengths - 1, range(len(lengths))]\n",
    "        return self.sig(out.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mT8XRhwXKPVg"
   },
   "outputs": [],
   "source": [
    "filename = \"\"\n",
    "def write_to_csv(trail_num, epochs, train_loss, train_acc, val_loss, val_acc, time_train):\n",
    "    global filename\n",
    "    filename = \"./lstm-amazon-hyperband-trails/\"+str(trail_num)+\".csv\"\n",
    "    epoch = [i for i in range(epochs)]\n",
    "    df_metrics = pd.DataFrame(list(zip(epoch, train_loss, train_acc, val_loss, val_acc, time_train)), columns =['Epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'train_time'])\n",
    "    df_metrics.to_csv(filename, index=False)    \n",
    "    \n",
    "def append_to_csv(epochs, accuracy):\n",
    "    acc = [accuracy for i in range(epochs)]\n",
    "    df_csv = pd.read_csv(filename)\n",
    "    df_csv['Test_Accuracy']  = acc\n",
    "    df_csv.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OasEM6YFKTBw"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "epochs = 10\n",
    "vocab_size=10000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define an objective function to be minimized.\n",
    "def objective(trial):\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    #epochs = trial.suggest_int(\"epochs\",5,15)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-0)\n",
    "    #momentum = trial.suggest_uniform(\"momentum\", 0.0, 1.0)\n",
    "    model = LSTMClassifier(trial, vocab_size).to(device)\n",
    "    trial.set_user_attr(key=\"best_model\", value=model)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    train_loss_epoch = []\n",
    "    train_acc_epoch = []\n",
    "    val_loss_epoch = []\n",
    "    val_accuracy_epoch = []\n",
    "    time_train = []\n",
    "    final_val_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        start = time.time()\n",
    "        total_loss = 0\n",
    "        train_acc = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for batch in train_dl:         \n",
    "            batch_X, batch_y = batch\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(batch_X)\n",
    "            loss = loss_fn(prediction, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            result = np.round(prediction.detach().cpu())\n",
    "            total_loss += loss.data.item()\n",
    "            total += batch_y.size(0)\n",
    "            correct += (result == batch_y.cpu()).sum().item()\n",
    "            train_acc = correct/total\n",
    "        train_loss_epoch.append(np.round(total_loss / len(train_dl), 3))\n",
    "        train_acc_epoch.append(np.round(train_acc*100,3))\n",
    "        print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_dl)))\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            val_loss = []\n",
    "            for inputs, labels in val_dl:\n",
    "                inputs_val, labels_val = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(inputs_val)\n",
    "                loss = loss_fn(prediction, labels_val)\n",
    "                val_loss.append(np.round(loss.item(),3))\n",
    "                result = np.round(prediction.cpu())\n",
    "                total += labels_val.size(0)\n",
    "                correct += (result == labels_val.cpu()).sum().item()\n",
    "            val_accuracy_epoch.append(np.round((correct/total)*100, 3))\n",
    "            val_loss_epoch.append(np.round(np.mean(val_loss),3))\n",
    "            end = time.time() - start\n",
    "            final_val_acc = np.round((correct/total)*100, 3)\n",
    "            print(\"Val Loss: {:.3f}\".format(np.mean(val_loss)), \"\\tVal Acc: {:.3f}\".format(correct/total))\n",
    "            time_train.append(np.round(end,3))\n",
    "    write_to_csv(trial.number, epochs, train_loss_epoch, train_acc_epoch, val_loss_epoch, val_accuracy_epoch, time_train)\n",
    "    return final_val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yM6NlQlNqA4h"
   },
   "outputs": [],
   "source": [
    "def callback(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        study.set_user_attr(key=\"best_model\", value=trial.user_attrs[\"best_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQ7svJFbqH5J",
    "outputId": "dd2b34de-5b0f-429d-be6f-31130956f6d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 13:09:34,436]\u001b[0m A new study created in memory with name: no-name-c83de7c0-2522-4c8e-9c5e-b7327c12c223\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, BCELoss: 0.6929224205304341\n",
      "Val Loss: 0.671 \tVal Acc: 0.732\n",
      "Epoch: 1, BCELoss: 0.6525878422590623\n",
      "Val Loss: 0.637 \tVal Acc: 0.759\n",
      "Epoch: 2, BCELoss: 0.6233946706157133\n",
      "Val Loss: 0.613 \tVal Acc: 0.759\n",
      "Epoch: 3, BCELoss: 0.602245904954083\n",
      "Val Loss: 0.596 \tVal Acc: 0.759\n",
      "Epoch: 4, BCELoss: 0.5868950699467257\n",
      "Val Loss: 0.583 \tVal Acc: 0.759\n",
      "Epoch: 5, BCELoss: 0.5757226680955255\n",
      "Val Loss: 0.574 \tVal Acc: 0.759\n",
      "Epoch: 6, BCELoss: 0.5675644679959998\n",
      "Val Loss: 0.568 \tVal Acc: 0.759\n",
      "Epoch: 7, BCELoss: 0.5615839402359653\n",
      "Val Loss: 0.563 \tVal Acc: 0.759\n",
      "Epoch: 8, BCELoss: 0.5571794847587505\n",
      "Val Loss: 0.559 \tVal Acc: 0.759\n",
      "Epoch: 9, BCELoss: 0.5539178863706359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 13:13:09,073]\u001b[0m Trial 0 finished with value: 75.937 and parameters: {'optimizer': 'SGD', 'lr': 0.0003415487497045099, 'dropout': 0.279376290360106, 'hidden_dim': 31, 'embedding_dim': 22}. Best is trial 0 with value: 75.937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.557 \tVal Acc: 0.759\n",
      "Epoch: 0, BCELoss: 0.6698176515389638\n",
      "Val Loss: 0.646 \tVal Acc: 0.756\n",
      "Epoch: 1, BCELoss: 0.6269680845091142\n",
      "Val Loss: 0.613 \tVal Acc: 0.759\n",
      "Epoch: 2, BCELoss: 0.5995481013892645\n",
      "Val Loss: 0.591 \tVal Acc: 0.759\n",
      "Epoch: 3, BCELoss: 0.5816590683467416\n",
      "Val Loss: 0.578 \tVal Acc: 0.759\n",
      "Epoch: 4, BCELoss: 0.5697563487363149\n",
      "Val Loss: 0.568 \tVal Acc: 0.759\n",
      "Epoch: 5, BCELoss: 0.5616765279008682\n",
      "Val Loss: 0.562 \tVal Acc: 0.759\n",
      "Epoch: 6, BCELoss: 0.5560757879571743\n",
      "Val Loss: 0.558 \tVal Acc: 0.759\n",
      "Epoch: 7, BCELoss: 0.5521045908511403\n",
      "Val Loss: 0.554 \tVal Acc: 0.759\n",
      "Epoch: 8, BCELoss: 0.5492171682327627\n",
      "Val Loss: 0.552 \tVal Acc: 0.759\n",
      "Epoch: 9, BCELoss: 0.5470576025635363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 13:17:04,704]\u001b[0m Trial 1 finished with value: 75.937 and parameters: {'optimizer': 'SGD', 'lr': 0.0004810573495938472, 'dropout': 0.23857225819264763, 'hidden_dim': 62, 'embedding_dim': 105}. Best is trial 0 with value: 75.937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.550 \tVal Acc: 0.759\n",
      "Epoch: 0, BCELoss: 0.5183078902672572\n",
      "Val Loss: 0.487 \tVal Acc: 0.780\n",
      "Epoch: 1, BCELoss: 0.4338261433933155\n",
      "Val Loss: 0.386 \tVal Acc: 0.830\n",
      "Epoch: 2, BCELoss: 0.350779517246298\n",
      "Val Loss: 0.323 \tVal Acc: 0.857\n",
      "Epoch: 3, BCELoss: 0.31663718474019004\n",
      "Val Loss: 0.306 \tVal Acc: 0.865\n",
      "Epoch: 4, BCELoss: 0.2992575271391725\n",
      "Val Loss: 0.298 \tVal Acc: 0.871\n",
      "Epoch: 5, BCELoss: 0.28754115886088594\n",
      "Val Loss: 0.294 \tVal Acc: 0.874\n",
      "Epoch: 6, BCELoss: 0.27856551845479444\n",
      "Val Loss: 0.291 \tVal Acc: 0.876\n",
      "Epoch: 7, BCELoss: 0.271065446132996\n",
      "Val Loss: 0.290 \tVal Acc: 0.877\n",
      "Epoch: 8, BCELoss: 0.26465294501822756\n",
      "Val Loss: 0.288 \tVal Acc: 0.876\n",
      "Epoch: 9, BCELoss: 0.25838830298239207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 13:24:16,293]\u001b[0m Trial 2 finished with value: 87.768 and parameters: {'optimizer': 'SGD', 'lr': 0.040631229687963684, 'dropout': 0.34534667192710367, 'hidden_dim': 225, 'embedding_dim': 86}. Best is trial 2 with value: 87.768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.288 \tVal Acc: 0.878\n",
      "Epoch: 0, BCELoss: 23.417496029188833\n",
      "Val Loss: 23.917 \tVal Acc: 0.759\n",
      "Epoch: 1, BCELoss: 23.521950323610422\n",
      "Val Loss: 24.009 \tVal Acc: 0.759\n",
      "Epoch: 2, BCELoss: 23.57173172766904\n",
      "Val Loss: 24.055 \tVal Acc: 0.759\n",
      "Epoch: 3, BCELoss: 23.569122630429554\n",
      "Val Loss: 24.062 \tVal Acc: 0.759\n",
      "Epoch: 4, BCELoss: 23.56867469879518\n",
      "Val Loss: 24.062 \tVal Acc: 0.759\n",
      "Epoch: 5, BCELoss: 23.56867469879518\n",
      "Val Loss: 24.062 \tVal Acc: 0.759\n",
      "Epoch: 6, BCELoss: 23.56867469879518\n",
      "Val Loss: 24.062 \tVal Acc: 0.759\n",
      "Epoch: 7, BCELoss: 23.56867469879518\n",
      "Val Loss: 24.062 \tVal Acc: 0.759\n",
      "Epoch: 8, BCELoss: 23.56867469879518\n",
      "Val Loss: 24.062 \tVal Acc: 0.759\n",
      "Epoch: 9, BCELoss: 23.56867469879518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 13:29:13,925]\u001b[0m Trial 3 finished with value: 75.937 and parameters: {'optimizer': 'RMSprop', 'lr': 0.9774651686043574, 'dropout': 0.10488608806979502, 'hidden_dim': 101, 'embedding_dim': 36}. Best is trial 2 with value: 87.768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 24.062 \tVal Acc: 0.759\n",
      "Epoch: 0, BCELoss: 0.688773082501917\n",
      "Val Loss: 0.685 \tVal Acc: 0.571\n",
      "Epoch: 1, BCELoss: 0.6811577063008963\n",
      "Val Loss: 0.678 \tVal Acc: 0.614\n",
      "Epoch: 2, BCELoss: 0.6739817524171737\n",
      "Val Loss: 0.671 \tVal Acc: 0.651\n",
      "Epoch: 3, BCELoss: 0.6672177744917123\n",
      "Val Loss: 0.665 \tVal Acc: 0.686\n",
      "Epoch: 4, BCELoss: 0.6608400853642498\n",
      "Val Loss: 0.659 \tVal Acc: 0.711\n",
      "Epoch: 5, BCELoss: 0.6548248460852956\n",
      "Val Loss: 0.653 \tVal Acc: 0.732\n",
      "Epoch: 6, BCELoss: 0.6491496205329895\n",
      "Val Loss: 0.648 \tVal Acc: 0.743\n",
      "Epoch: 7, BCELoss: 0.643793596596603\n",
      "Val Loss: 0.643 \tVal Acc: 0.748\n",
      "Epoch: 8, BCELoss: 0.6387373020131903\n",
      "Val Loss: 0.638 \tVal Acc: 0.753\n",
      "Epoch: 9, BCELoss: 0.6339623708681887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-14 13:32:48,834]\u001b[0m Trial 4 finished with value: 75.564 and parameters: {'optimizer': 'SGD', 'lr': 5.929332656984242e-05, 'dropout': 0.2734163696086287, 'hidden_dim': 31, 'embedding_dim': 48}. Best is trial 2 with value: 87.768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.633 \tVal Acc: 0.756\n",
      "Epoch: 0, BCELoss: 0.43107607761420397\n",
      "Val Loss: 0.343 \tVal Acc: 0.854\n",
      "Epoch: 1, BCELoss: 0.33209891272147735\n",
      "Val Loss: 0.313 \tVal Acc: 0.864\n",
      "Epoch: 2, BCELoss: 0.3027145309306412\n",
      "Val Loss: 0.310 \tVal Acc: 0.870\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "study = optuna.create_study(direction=\"maximize\",pruner=optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1, max_resource=epochs, reduction_factor=3\n",
    "    ),)\n",
    "study.optimize(objective, n_trials=10,callbacks=[callback])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "best_model=study.user_attrs[\"best_model\"]\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(),\"./lstm-amazon-hyperband/lstm_amazon_hyperband.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2D2JfLBeKjQ0"
   },
   "outputs": [],
   "source": [
    "def test(model, test_dl, epochs):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "#     results = []\n",
    "#     labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dl:         \n",
    "            batch_X, batch_y = batch\n",
    "            batch_X = batch_X.to(device)\n",
    "            prediction = model(batch_X)\n",
    "            result = np.round(prediction.cpu())\n",
    "#             results.extend(list(result.numpy()))\n",
    "#             labels.extend(list(batch_y.numpy()))\n",
    "            total += batch_y.size(0)\n",
    "            correct += (result == batch_y).sum().item()\n",
    "    print(\"Accuracy:\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vR_FTuLSby1Y"
   },
   "outputs": [],
   "source": [
    "test(best_model, test_dl, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lstm-amazon-hyperband.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_env2_gpu",
   "language": "python",
   "name": "my_env2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
