{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qrnn-imdb-hyperband.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import sys\n",
        "import os\n",
        "prefix = '/content/gdrive/My Drive/'\n",
        "# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n",
        "customized_path_to_your_homework = 'IDLSProject-main'\n",
        "sys_path = os.path.join(prefix, customized_path_to_your_homework)\n",
        "sys.path.append(sys_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oajq_A9Wb1mQ",
        "outputId": "a7f6939a-42f3-432a-db56-3fba005da0ea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "source": [
        "%cd '/content/gdrive/My Drive/IDLSProject-main-2'"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/IDLSProject-main-2\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O36-vTu0b4Vq",
        "outputId": "f8ea5416-815c-4d08-b623-d33d28826499"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "data_dir = './data/pytorch'\n",
        "with open(os.path.join(data_dir, 'word_dict_qrnn.pkl'), \"rb\") as f:\n",
        "    word_dict = pickle.load(f)"
      ],
      "outputs": [],
      "metadata": {
        "id": "yBS_Cwn9bQOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "train = pd.read_csv(os.path.join(data_dir, 'train_qrnn.csv'), header=None, names=None)\n",
        "test_sample = pd.read_csv(os.path.join(data_dir, 'test_qrnn.csv'), header=None, names=None)\n",
        "print(train.shape, test_sample.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 502) (20000, 502)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMsjwRQ9KBwk",
        "outputId": "b76e367b-487a-483a-e765-de850ca234a6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test, val = train_test_split(test_sample, test_size=0.5)\n",
        "train.shape, test.shape, val.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30000, 502), (10000, 502), (10000, 502))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn509rQ2KFBX",
        "outputId": "2ed29b11-4999-42a0-e65e-118495c07956"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "# Turn the input pandas dataframe into tensors\n",
        "train_y = torch.from_numpy(train[[0]].values).float()\n",
        "train_X = torch.from_numpy(train.drop([0, 1], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
        "# Build the dataloader\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
        "\n",
        "######val data\n",
        "# Turn the input pandas dataframe into tensors\n",
        "val_y = torch.from_numpy(val[[0]].values).float()\n",
        "val_X = torch.from_numpy(val.drop([0, 1], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "val_ds = torch.utils.data.TensorDataset(val_X, val_y)\n",
        "# Build the dataloader\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=50)\n",
        "\n",
        "\n",
        "#### Test data\n",
        "# Turn the input pandas dataframe into tensors\n",
        "test_y = torch.from_numpy(test[[0]].values).float()\n",
        "test_X = torch.from_numpy(test.drop([0, 1], axis=1).values).long()\n",
        "\n",
        "# Build the dataset\n",
        "test_ds = torch.utils.data.TensorDataset(test_X, test_y)\n",
        "# Build the dataloader\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=50)\n",
        "print(test_y.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 1])\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkVwncNSKHsE",
        "outputId": "96eb5fed-ad4a-43eb-aada-4be526513957"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class QRNNLayer(nn.Module):\n",
        "    def __init__(self,batch_size,input_size,n_filters,kernel_size,embed_size,device,dropout):\n",
        "        super(QRNNLayer,self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.input_size = input_size\n",
        "        self.n_filters = n_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.embed_size = embed_size\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.device = device\n",
        "        self.conv1 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
        "        self.conv2 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
        "        self.conv3 = torch.nn.Conv1d(self.input_size,self.n_filters,self.kernel_size)\n",
        "    \n",
        "    def forward(self,masked_input, h, c):\n",
        "        Z,F,O = self.masked_conv(masked_input)\n",
        "        h, c = self.pool(c,Z,F,O)\n",
        "        masked_input = h\n",
        "        return masked_input,h,c\n",
        "    \n",
        "    def masked_conv(self,x):\n",
        "        pad = torch.zeros([self.batch_size,1,self.input_size],device=self.device)\n",
        "        x = torch.cat([pad,x],1).permute(0,2,1)\n",
        "        Z = torch.tanh((self.conv1(x)))\n",
        "        F = torch.sigmoid((self.conv2(x)))\n",
        "        O = torch.sigmoid((self.conv3(x)))\n",
        "        one_mask = torch.ones_like(F,device=self.device) - F\n",
        "        F = 1 - self.dropout(one_mask)\n",
        "        return Z.permute(0,2,1), F.permute(0,2,1), O.permute(0,2,1)\n",
        "    \n",
        "    def pool(self, prev_c,Z,F,O):\n",
        "        c = torch.mul(F,prev_c) + torch.mul(1-F,Z)\n",
        "        h = torch.mul(O,c)\n",
        "        return h,c\n",
        "\n",
        "class QRNN(nn.Module):\n",
        "    def __init__(self,trial,vocab_size,embed_size,n_filters,kernel_size,batch_size,seq_len,layers,device,dropout):\n",
        "        super(QRNN,self).__init__()\n",
        "        dropout = trial.suggest_uniform(\"dropout\",0.1, 0.6)\n",
        "        self.num_layer = trial.suggest_int(\"num_layer\",1,4)\n",
        "        self.embed_size = trial.suggest_int(\"embed_size\",16,128)\n",
        "        self.n_filters = trial.suggest_int(\"n_filters\",50,200)\n",
        "        # self.kernel_size = trial.suggest_int(\"kernel_size\",2,5)\n",
        "        # self.embed_size = embed_size\n",
        "        # self.n_filters = n_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_len = seq_len\n",
        "        # self.num_layer = layers\n",
        "        self.device = device\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, self.embed_size)\n",
        "        self.dense = torch.nn.Linear(self.seq_len*self.n_filters,1)\n",
        "        self.QRNN_layers = torch.nn.ModuleList([QRNNLayer(self.batch_size,self.embed_size if l==0 else self.n_filters,\n",
        "                                                         self.n_filters,self.kernel_size,self.embed_size,self.device,\n",
        "                                                         dropout,) for l in range(self.num_layer)])\n",
        "        \n",
        "        \n",
        "    def forward(self, x, target):\n",
        "        x = self.embedding(x)\n",
        "        h = torch.zeros([self.batch_size,self.seq_len,self.n_filters],device=self.device)\n",
        "        c = torch.zeros_like(h,device=self.device)\n",
        "        \n",
        "        masked_input = x\n",
        "        for l,layer in enumerate(self.QRNN_layers):\n",
        "            masked_input,h,c = layer(masked_input,h,c)\n",
        "        dense_input = h.reshape([self.batch_size,-1])\n",
        "        logits = self.dense(dense_input)\n",
        "        prediction = torch.sigmoid(logits)\n",
        "        target = target.view([-1,1])\n",
        "        correct_pred = torch.eq(torch.round(prediction).type(target.type()),target)\n",
        "        accuracy = torch.sum(correct_pred)\n",
        "        return prediction, accuracy"
      ],
      "metadata": {
        "id": "jDvo2PsZtLpB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "source": [
        "data_dir = './qrnn-imdb-hyperband-trails/' # The folder we will use for storing data\n",
        "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "filename = \"\"\n",
        "def write_to_csv(trail_num, epochs, train_loss, train_acc, val_loss, val_acc, time_train):\n",
        "    global filename\n",
        "    filename = \"./qrnn-imdb-hyperband-trails/\"+str(trail_num)+\".csv\"\n",
        "    epoch = [i for i in range(epochs)]\n",
        "    df_metrics = pd.DataFrame(list(zip(epoch, train_loss, train_acc, val_loss, val_acc, time_train)), columns =['Epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'train_time'])\n",
        "    df_metrics.to_csv(filename, index=False)    \n",
        "    \n",
        "def append_to_csv(epochs, accuracy):\n",
        "    acc = [accuracy for i in range(epochs)]\n",
        "    df_csv = pd.read_csv(filename)\n",
        "    df_csv['Test_Accuracy']  = acc\n",
        "    df_csv.to_csv(filename, index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mT8XRhwXKPVg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "!pip install optuna"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.36)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.2.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.9.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxD0Pj_xrTLF",
        "outputId": "5689ab94-e5ea-4374-b37e-8951887d86e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "epochs = 10\n",
        "n_filters = 64\n",
        "kernel_size = 2\n",
        "layers= 2\n",
        "learning_rate = 0.001\n",
        "print(len(word_dict))\n",
        "vocab_size = 5000\n",
        "print(vocab_size)\n",
        "embed_dims = 32\n",
        "seq_len = 500\n",
        "dropout = 0.3\n",
        "batch_size=50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAuhnuf8xFNR",
        "outputId": "917669e7-4006-48cd-90bc-ef34f948defc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4998\n",
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gKatN9l8yHrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "source": [
        "import time\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.optim as optim\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Define an objective function to be minimized.\n",
        "def objective(trial):\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "  #epochs = trial.suggest_int(\"epochs\",5,15)\n",
        "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-0)\n",
        "  #momentum = trial.suggest_uniform(\"momentum\", 0.0, 1.0)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = QRNN(trial,vocab_size, embed_dims, n_filters, kernel_size, batch_size, seq_len, layers, device, dropout).to(device)\n",
        "  trial.set_user_attr(key=\"best_model\", value=model)\n",
        "  optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "  loss_fn = torch.nn.BCELoss()\n",
        "  counter = 0\n",
        "  QRNN_acc = []\n",
        "  QRNN_valacc = []\n",
        "  train_loss_epoch = []\n",
        "  train_acc_epoch = []\n",
        "  val_loss_epoch = []\n",
        "  val_acc_epoch = []\n",
        "  time_epoch = []\n",
        "  final_val_acc = 0\n",
        "  model.train()\n",
        "  for e in range(epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    for inputs, labels in train_dl:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        model.zero_grad()\n",
        "        logits, accuracy = model(inputs,labels)\n",
        "        loss = criterion(logits,labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.item())\n",
        "        train_acc.append(accuracy.item()*100/batch_size)\n",
        "        if counter%100==0:\n",
        "            print(\"Epoch: {}/{}\".format(e,epochs),\n",
        "                         \"\\tIteration: {}\".format(counter),\n",
        "                         \"\\tTrain Loss: {:.3f}\".format(loss.item()),\n",
        "                         \"\\tTrain Accuracy: {:.2f}\".format(accuracy.item()*100/batch_size))\n",
        "            QRNN_acc.append(accuracy.item()*100/batch_size)\n",
        "        counter += 1\n",
        "    train_loss_epoch.append(np.round(np.mean(train_loss), 3))\n",
        "    train_acc_epoch.append(np.round(np.mean(train_acc), 3))\n",
        "    print(\"\\tTrain Loss: {:.3f}\".format(np.mean(train_loss)), \"\\tTrain Acc: {:.3f}\".format(np.mean(train_acc)))\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_acc = []\n",
        "        val_loss = []\n",
        "        for inputs, labels in val_dl:\n",
        "            inputs_val, labels_val = inputs.cuda(), labels.cuda()\n",
        "            logits_val,accuracy_val = model(inputs_val,labels_val)\n",
        "            loss_val = criterion(logits_val,labels_val.float())\n",
        "            val_acc.append(accuracy_val.item()*100/batch_size)\n",
        "            val_loss.append(loss_val.item())\n",
        "        print(\"Val Loss: {:.3f}\".format(np.mean(val_loss)), \"\\tVal Acc: {:.3f}\".format(np.mean(val_acc)))\n",
        "        val_loss_epoch.append(np.round(np.mean(val_loss), 3))\n",
        "        val_acc_epoch.append(np.round(np.mean(val_acc), 3))\n",
        "        QRNN_valacc.append(np.mean(val_acc))\n",
        "        model.train()\n",
        "        final_val_acc = np.mean(val_acc)\n",
        "    end_time = time.time()-start_time\n",
        "    print(\"Time to train epoch: {0} s\".format(end_time))\n",
        "    time_epoch.append(np.round(end_time, 3))\n",
        "  write_to_csv(epochs, train_loss_epoch, train_acc_epoch, val_loss_epoch, val_acc_epoch, time_epoch)\n",
        "  return final_val_acc\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "OasEM6YFKTBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "source": [
        "def callback(study, trial):\n",
        "    if study.best_trial.number == trial.number:\n",
        "        study.set_user_attr(key=\"best_model\", value=trial.user_attrs[\"best_model\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "yM6NlQlNqA4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "study = optuna.create_study(direction=\"maximize\",pruner=optuna.pruners.HyperbandPruner(\n",
        "        min_resource=1, max_resource=epochs, reduction_factor=3\n",
        "    ),)\n",
        "study.optimize(objective, n_trials=5,callbacks=[callback])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "best_model=study.user_attrs[\"best_model\"]\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\"    {}: {}\".format(key, value))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-05-14 18:24:34,881]\u001b[0m A new study created in memory with name: no-name-eb775b16-9626-49c4-b8e5-17c211db844e\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/10 \tIteration: 0 \tTrain Loss: 0.693 \tTrain Accuracy: 52.00\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-0bb9a6d4bff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmin_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     ),)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Study statistics: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-bf2c44b7c861>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "QQ7svJFbqH5J",
        "outputId": "1d0f72f5-3712-4161-8c83-eb8e938fd588"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './qrnn-imdb-hyperband/' # The folder we will use for storing data\n",
        "if not os.path.exists(data_dir): # Make sure that the folder exists\n",
        "    os.makedirs(data_dir)\n",
        "    \n",
        "torch.save(best_model.state_dict(),\"./qrnn-imdb-hyperband/cnn-imdb-hyperband.pth\")"
      ],
      "metadata": {
        "id": "Njic3VLTwSPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def test(model, test_dl, epochs):\n",
        "    with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_acc = []\n",
        "    test_loss = []\n",
        "    for inputs, labels in test_dl:\n",
        "        input_test, labels_test = inputs.cuda(), labels.cuda()\n",
        "        logits_test, accuracy_test = model(input_test, labels_test)\n",
        "        loss_test = criterion(logits_test, labels_test.float())\n",
        "        test_acc.append(accuracy_test.item()*100/batch_size)\n",
        "        test_loss.append(loss_test.item())\n",
        "    print(\"Test Loss: {:.3f}\".format(np.mean(test_loss)), \"\\tTest Acc: {:.3f}\".format(np.mean(test_acc)))"
      ],
      "outputs": [],
      "metadata": {
        "id": "2D2JfLBeKjQ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test(best_model, test_dl, epochs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "vR_FTuLSby1Y"
      }
    }
  ]
}